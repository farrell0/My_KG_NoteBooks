{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data sets ..\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Exception reporting mode: Minimal\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "#  **  You must run this cell to do much of anything in this NoteBook\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "#  l_history.clear()\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "#  l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909c6ac-eef4-42ea-af33-cfda0b6d5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries are imported below, but ..\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+-----------------+\n",
      "|   sl |   sw |   pl |   pw |   class_encoded |\n",
      "|------+------+------+------+-----------------|\n",
      "|  6   |  3.4 |  4.5 |  1.6 |               1 |\n",
      "|  6.9 |  3.2 |  5.7 |  2.3 |               2 |\n",
      "|  6.2 |  3.4 |  5.4 |  2.3 |               2 |\n",
      "|  5.7 |  2.8 |  4.5 |  1.3 |               1 |\n",
      "|  7.7 |  2.8 |  6.7 |  2   |               2 |\n",
      "+------+------+------+------+-----------------+\n",
      "Number of rows: 149\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     |   sl |   sw |   pl |   pw |   class_encoded |\n",
    "#     |------+------+------+------+-----------------|\n",
    "#     |  5.5 |  2.4 |  3.8 |  1.1 |               1 |\n",
    "#     |  6.4 |  3.2 |  4.5 |  1.5 |               1 |\n",
    "#     |  6.8 |  3.2 |  5.9 |  2.3 |               2 |\n",
    "#     |  6.7 |  3.3 |  5.7 |  2.1 |               2 |\n",
    "#     |  5.5 |  2.6 |  4.4 |  1.2 |               1 |\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     Number of rows: 149\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total                 rows... 149   Training rows: 119   Test rows: 30\n",
      "\n",
      "Number of total filtered/sliced rows... 100   Training rows: 78   Test rows: 22\n",
      "\n",
      "Train data:\n",
      "[[4.7 1.4 1]\n",
      " [5.8 1.6 2]\n",
      " [5.1 2.4 2]\n",
      " [4.4 1.3 1]\n",
      " [5.6 2.1 2]]\n",
      "\n",
      "Test  data:\n",
      "[[4.1 1 1]\n",
      " [5.5 1.8 2]\n",
      " [6.9 2.3 2]\n",
      " [4.4 1.2 1]\n",
      " [5.6 2.4 2]]\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml code we use later expect that.\n",
    "#  We only want two of the classes, 1 and 2.\n",
    "#  And we only want columns 2 and 3.\n",
    "#\n",
    "#     Why this data ?  It was harder to predict; see the plot below.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "\n",
    "\n",
    "#  Filter out given labels\n",
    "#\n",
    "np_iris[\"train_f\"] = np_iris[\"train\"][ ( np_iris[\"train\"][:, -1] > 0) & ( np_iris[\"train\"][:, -1] < 3) ]\n",
    "np_iris[\"test_f\" ] = np_iris[\"test\" ][ ( np_iris[\"test\" ][:, -1] > 0) & ( np_iris[\"test\" ][:, -1] < 3) ]\n",
    "\n",
    "\n",
    "#  Slicing only given columns\n",
    "#\n",
    "np_iris[\"train_fs\"] = np_iris[\"train_f\"][:, [2 ,3, 4]]\n",
    "np_iris[\"test_fs\" ] = np_iris[\"test_f\" ][:, [2, 3, 4]] \n",
    "\n",
    "\n",
    "#  Outputs for confirmation\n",
    "#\n",
    "print(\"Number of total                 rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "print()\n",
    "print(\"Number of total filtered/sliced rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  ( len(np_iris[\"train_fs\"]) + len(np_iris[\"test_fs\"]),\n",
    "    len(np_iris[\"train_fs\"]), len(np_iris[\"test_fs\"]) ) ) \n",
    "print()\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train_fs\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test_fs\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     Number of total                 rows... 149   Training rows: 119   Test rows: 30\n",
    "#     \n",
    "#     Number of total filtered/sliced rows... 100   Training rows: 78   Test rows: 22\n",
    "#     \n",
    "#     Train data:\n",
    "#     [[4.7 1.4 1]\n",
    "#      [5.8 1.6 2]\n",
    "#      [5.1 2.4 2]\n",
    "#      [4.4 1.3 1]\n",
    "#      [5.6 2.1 2]]\n",
    "#     \n",
    "#     Test  data:\n",
    "#     [[4.1 1 1]\n",
    "#      [5.5 1.8 2]\n",
    "#      [6.9 2.3 2]\n",
    "#      [4.4 1.2 1]\n",
    "#      [5.6 2.4 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Plot of just two features from the two class data set\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==1][:, 0], np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==1][:, 1], c = \"red\"  , label = \"Class 1\", marker = \".\")\n",
    "plt.scatter(np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==2][:, 0], np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==2][:, 1], c = \"blue\" , label = \"Class 2\", marker = \",\")\n",
    "    \n",
    "plt.legend()\n",
    "   #\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee2512-59dc-41ed-8cf2-96505468b1e7",
   "metadata": {},
   "source": [
    "<div> \n",
    "<img src=\"./01_Images/09_Results_Chart.png\" alt=\"Drawing\" style=\"width: 800px;\"/>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb4fa2-1927-4534-8ea4-1dde87fceddd",
   "metadata": {},
   "source": [
    "#  Step A2: Iris Data train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a59cef88-7f7a-4579-922c-fc7fa9960059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results:\n",
      "   Overall score: 95.45455 %\n",
      "\n",
      "   Sample   Actual Class   Predicted Class   Probability of being Class 1\n",
      "   ======   ============   ===============   ============================\n",
      "           000      1                1        100.0000 %\n",
      "           001      2                2        000.0002 %\n",
      "           002      2                2        000.0000 %\n",
      "           003      1                1        100.0000 %\n",
      "           004      2                2        000.0000 %\n",
      "           005      1                1        100.0000 %\n",
      "           006      1                1        100.0000 %\n",
      "           007      1                1        099.9999 %\n",
      "           008      1                1        100.0000 %\n",
      "           009      2                2        000.7321 %\n",
      "           010      1                1        100.0000 %\n",
      "           011      2                2        000.0000 %\n",
      "           012      2                2        000.0000 %\n",
      "           013      2                2        000.0000 %\n",
      "           014      1                1        099.9982 %\n",
      "           015      1                1        100.0000 %\n",
      "           016      2                2        000.0000 %\n",
      "           017      2                1        099.9550 %\n",
      "           018      1                1        100.0000 %\n",
      "           019      1                1        100.0000 %\n",
      "           020      2                2        000.0000 %\n",
      "           021      1                1        100.0000 %\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Train the neural network on Iris data\n",
    "#\n",
    "#  From PDL Pg 186\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_iris[\"train_fs\"]\n",
    "#     np_iris[\"test_fs\" ]\n",
    "#\n",
    "#        ^^^^  cols 0 and 1 are features, col 2 is the label\n",
    "#\n",
    "\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "l_clf = MLPClassifier(\n",
    "   hidden_layer_sizes = (3, 2),\n",
    "   activation         = \"logistic\",           #  aka, sigmoid\n",
    "   solver             = \"adam\",\n",
    "   tol                = 1e-9,\n",
    "   max_iter           = 50000,                #  5000 (book) would not settle\n",
    "   verbose            = False,\n",
    "   )\n",
    "\n",
    "\n",
    "l_clf.fit(np_iris[\"train_fs\"][:, [0, 1]], np_iris[\"train_fs\"][:, -1])\n",
    "\n",
    "\n",
    "   ###\n",
    "    \n",
    "\n",
    "l_probability = l_clf.predict_proba(np_iris[\"test_fs\"][:, [0, 1]])\n",
    "l_score       = l_clf.score(np_iris[\"test_fs\"][:, [0, 1]], np_iris[\"test_fs\"][:, -1]) \n",
    "\n",
    "\n",
    "#  Saving this model for future scoring\n",
    "#\n",
    "l_w12         = l_clf.coefs_[0]\n",
    "l_w23         = l_clf.coefs_[1]\n",
    "l_w34         = l_clf.coefs_[2]\n",
    "l_b1          = l_clf.intercepts_[0]\n",
    "l_b2          = l_clf.intercepts_[1]\n",
    "l_b3          = l_clf.intercepts_[2]\n",
    "   #\n",
    "l_weights     = [l_w12, l_b1, l_w23, l_b2, l_w34, l_b3]\n",
    "   #\n",
    "pickle.dump(l_weights, open(\"./20_Data/48_IrisWeights.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "   ###\n",
    "    \n",
    "#  Our actual data is class 1 and 2.\n",
    "#  Having two values only, this model labels these as zero and 1.\n",
    "#  In the print statement below, we adjust that for display only.\n",
    "#\n",
    "print()\n",
    "print(\"Test results:\")\n",
    "print(\"   Overall score: %0.5f %%\" % (l_score * 100))\n",
    "print()\n",
    "print(\"   Sample   Actual Class   Predicted Class   Probability of being Class 1\")\n",
    "print(\"   ======   ============   ===============   ============================\")\n",
    "for i in range(len(np_iris[\"test_fs\"][:, -1])):\n",
    "   l_prob = 0 if l_probability[i, 1] < 0.5 else 1\n",
    "   print(\"           %03d      %d                %d        %08.4f %%\" % (i, np_iris[\"test_fs\"][:, -1][i], l_prob + 1, l_probability[i, 0] * 100))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     Test results:\n",
    "#        Overall score: 90.90909 %\n",
    "#     \n",
    "#        Sample   Actual Class   Predicted Class   Probability of being Class 1\n",
    "#        ======   ============   ===============   ============================\n",
    "#                000      1                1        100.0000 %\n",
    "#                001      2                2        000.0001 %\n",
    "#                002      2                2        000.0001 %\n",
    "#                003      1                1        100.0000 %\n",
    "#                004      2                2        000.0001 %\n",
    "#                005      1                1        100.0000 %\n",
    "#                006      1                1        100.0000 %\n",
    "#                007      1                1        100.0000 %\n",
    "#                008      1                1        100.0000 %\n",
    "#                009      2                2        000.2876 %\n",
    "#                010      1                1        100.0000 %\n",
    "#                011      2                2        000.0001 %\n",
    "#                012      2                2        000.0001 %\n",
    "#                013      2                2        000.0001 %\n",
    "#                014      1                2        022.2527 %\n",
    "#                015      1                1        100.0000 %\n",
    "#                016      2                2        000.0001 %\n",
    "#                017      2                1        100.0000 %\n",
    "#                018      1                1        100.0000 %\n",
    "#                019      1                1        100.0000 %\n",
    "#                020      2                2        000.0001 %\n",
    "#                021      1                1        100.0000 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "baee9357-f45c-470e-bb8b-1456258a55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "[1.8 2]\n",
      "[2.3 2]\n",
      "[1.2 1]\n",
      "[2.4 2]\n",
      "[1.1 1]\n",
      "[1.2 1]\n",
      "[1.6 1]\n",
      "[1.4 1]\n",
      "[1.8 2]\n",
      "[1.1 1]\n",
      "[2.5 2]\n",
      "[2.1 2]\n",
      "[1.8 2]\n",
      "[1.7 1]\n",
      "[1 1]\n",
      "[2.2 2]\n",
      "[1.7 2]\n",
      "[1.5 1]\n",
      "[1.4 1]\n",
      "[2.2 2]\n",
      "[1.2 1]\n",
      "\n",
      "Test results:\n",
      "   Overall score: 0.00000 %\n",
      "\n",
      "   Sample   Actual Class   Predicted Class   Probability of being Class 1\n",
      "   ======   ============   ===============   ============================\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mIndexError\u001b[0m\u001b[0;31m:\u001b[0m too many indices for array: array is 1-dimensional, but 2 were indexed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Having written the model above to disk, read and use to score\n",
    "#\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def f_sigmoid(i_arg1):\n",
    "   return 1.0 / (1.0 + np.exp(-i_arg1))\n",
    "\n",
    "\n",
    "def f_evaluate(i_arg1, i_weights):\n",
    "    \n",
    "   i_data  = i_arg1[:, [1, 2]]\n",
    "   i_label = i_arg1[:, -1]\n",
    "    \n",
    "   l_w12, l_b1, l_w23, l_b2, l_w34, l_b3 = i_weights\n",
    "      #\n",
    "   l_nc = l_nw = 0\n",
    "\n",
    "   l_prob = np.zeros(len(i_label))\n",
    "      #\n",
    "   for i in range(len(i_label)):\n",
    "      print(i_data[i])\n",
    "      l_a1 = f_sigmoid(np.dot(i_data[i], l_w12) + l_b1)\n",
    "      l_a2 = f_sigmoid(np.dot(l_a1, l_w23) + l_b2)\n",
    "         #\n",
    "      l_prob[i] = f_sigmoid(np.dot(l_a2, l_w34) + l_b3)\n",
    "         #\n",
    "      l_tmp = 0 if l_prob[i] < 0.5 else 1\n",
    "         #\n",
    "      if (l_tmp == i_label[i]):\n",
    "         l_nc += 1\n",
    "      else:\n",
    "         l_nw += 1\n",
    "   return [float(l_nc) / float(l_nc + l_nw), l_prob]\n",
    "\n",
    "\n",
    "      ###\n",
    "    \n",
    "\n",
    "l_weights = pickle.load(open(\"./20_Data/48_IrisWeights.pkl\", \"rb\"))\n",
    "   #\n",
    "l_score, l_probability = f_evaluate(np_iris[\"test_fs\"],  l_weights)\n",
    "\n",
    "   ###\n",
    "    \n",
    "#  Our actual data is class 1 and 2.\n",
    "#  Having two values only, this model labels these as zero and 1.\n",
    "#  In the print statement below, we adjust that for display only.\n",
    "#\n",
    "print()\n",
    "print(\"Test results:\")\n",
    "print(\"   Overall score: %0.5f %%\" % (l_score * 100))\n",
    "print()\n",
    "print(\"   Sample   Actual Class   Predicted Class   Probability of being Class 1\")\n",
    "print(\"   ======   ============   ===============   ============================\")\n",
    "for i in range(len(np_iris[\"test_fs\"][:, -1])):\n",
    "   l_prob = 0 if l_probability[i, 1] < 0.5 else 1\n",
    "   print(\"           %03d      %d                %d        %08.4f %%\" % (i, np_iris[\"test_fs\"][:, -1][i], l_prob + 1, l_probability[i, 0] * 100))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3699e7-d0f9-4213-90e0-b1d0e63eee9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1f1e1-2fc4-4da4-b686-6288c22fff53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f3a82-175b-48c1-9ba1-2e92c24d35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Same as above, more rows, more columns\n",
    "#\n",
    "\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "l_clf = MLPClassifier(\n",
    "   hidden_layer_sizes = (8, 4),\n",
    "   activation         = \"logistic\",\n",
    "   solver             = \"adam\",\n",
    "   tol                = 1e-9,\n",
    "   max_iter           = 80000,                #  5000 (book) would not settle\n",
    "   verbose            = False,\n",
    "   )\n",
    "\n",
    "\n",
    "l_clf.fit(np_iris[\"train\"][:, 0:3], np_iris[\"train\"][:, -1])\n",
    "\n",
    "l_probability = l_clf.predict_proba(np_iris[\"test\"][:, 0:3])\n",
    "l_score       = l_clf.score(np_iris[\"test\"][:, 0:3], np_iris[\"test\"][:, -1]) \n",
    "\n",
    "\n",
    "print(l_probability)\n",
    "print(l_score)\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30ed00-e15b-41c4-afb9-b7f6c949e0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b37e69-c673-4d62-bfc0-54fe7422b8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad863a-124f-4428-a0aa-312936d86212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df4b7d-946c-4437-8965-d67a07a089c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976e37-8702-4f53-bf97-e28a958675f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397bde-64f0-4ec9-a728-d37e4c51ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
