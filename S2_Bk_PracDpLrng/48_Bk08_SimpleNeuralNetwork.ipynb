{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data sets ..\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "#  **  You must run this cell to do much of anything in this NoteBook\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "#  l_history.clear()\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "#  l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909c6ac-eef4-42ea-af33-cfda0b6d5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries are imported below, but ..\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     |   sl |   sw |   pl |   pw |   class_encoded |\n",
    "#     |------+------+------+------+-----------------|\n",
    "#     |  5.5 |  2.4 |  3.8 |  1.1 |               1 |\n",
    "#     |  6.4 |  3.2 |  4.5 |  1.5 |               1 |\n",
    "#     |  6.8 |  3.2 |  5.9 |  2.3 |               2 |\n",
    "#     |  6.7 |  3.3 |  5.7 |  2.1 |               2 |\n",
    "#     |  5.5 |  2.6 |  4.4 |  1.2 |               1 |\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     Number of rows: 149\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml code we use later expect that.\n",
    "#  We only want two of the classes, 1 and 2.\n",
    "#  And we only want columns 2 and 3.\n",
    "#\n",
    "#     Why this data ?  It was harder to predict; see the plot below.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "\n",
    "\n",
    "#  Filter out given labels\n",
    "#\n",
    "np_iris[\"train_f\"] = np_iris[\"train\"][ ( np_iris[\"train\"][:, -1] > 0) & ( np_iris[\"train\"][:, -1] < 3) ]\n",
    "np_iris[\"test_f\" ] = np_iris[\"test\" ][ ( np_iris[\"test\" ][:, -1] > 0) & ( np_iris[\"test\" ][:, -1] < 3) ]\n",
    "\n",
    "\n",
    "#  Slicing only given columns\n",
    "#\n",
    "np_iris[\"train_fs\"] = np_iris[\"train_f\"][:, [2 ,3, 4]]\n",
    "np_iris[\"test_fs\" ] = np_iris[\"test_f\" ][:, [2, 3, 4]] \n",
    "\n",
    "\n",
    "#  Outputs for confirmation\n",
    "#\n",
    "print(\"Number of total                 rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "print()\n",
    "print(\"Number of total filtered/sliced rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  ( len(np_iris[\"train_fs\"]) + len(np_iris[\"test_fs\"]),\n",
    "    len(np_iris[\"train_fs\"]), len(np_iris[\"test_fs\"]) ) ) \n",
    "print()\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train_fs\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test_fs\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     Number of total                 rows... 149   Training rows: 119   Test rows: 30\n",
    "#     \n",
    "#     Number of total filtered/sliced rows... 100   Training rows: 78   Test rows: 22\n",
    "#     \n",
    "#     Train data:\n",
    "#     [[4.7 1.4 1]\n",
    "#      [5.8 1.6 2]\n",
    "#      [5.1 2.4 2]\n",
    "#      [4.4 1.3 1]\n",
    "#      [5.6 2.1 2]]\n",
    "#     \n",
    "#     Test  data:\n",
    "#     [[4.1 1 1]\n",
    "#      [5.5 1.8 2]\n",
    "#      [6.9 2.3 2]\n",
    "#      [4.4 1.2 1]\n",
    "#      [5.6 2.4 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Plot of just two features from the two class data set\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==1][:, 0], np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==1][:, 1], c = \"red\"  , label = \"Class 1\", marker = \".\")\n",
    "plt.scatter(np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==2][:, 0], np_iris[\"train_fs\"][np_iris[\"train_fs\"][:, -1]==2][:, 1], c = \"blue\" , label = \"Class 2\", marker = \",\")\n",
    "    \n",
    "plt.legend()\n",
    "   #\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee2512-59dc-41ed-8cf2-96505468b1e7",
   "metadata": {},
   "source": [
    "<div> \n",
    "<img src=\"./01_Images/09_Results_Chart.png\" alt=\"Drawing\" style=\"width: 800px;\"/>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb4fa2-1927-4534-8ea4-1dde87fceddd",
   "metadata": {},
   "source": [
    "#  Step A2: Iris Data train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a59cef88-7f7a-4579-922c-fc7fa9960059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5.78e-07]\n",
      " [2.34e-06 1]\n",
      " [2.32e-06 1]\n",
      " [1 5.78e-07]\n",
      " [2.32e-06 1]\n",
      " [1 5.78e-07]\n",
      " [1 5.78e-07]\n",
      " [1 5.78e-07]\n",
      " [1 5.78e-07]\n",
      " [0.0015 0.998]\n",
      " [1 5.78e-07]\n",
      " [2.32e-06 1]\n",
      " [2.32e-06 1]\n",
      " [2.48e-06 1]\n",
      " [0.294 0.706]\n",
      " [1 5.78e-07]\n",
      " [2.32e-06 1]\n",
      " [1 5.78e-07]\n",
      " [1 5.78e-07]\n",
      " [1 5.78e-07]\n",
      " [2.32e-06 1]\n",
      " [1 5.78e-07]]\n",
      "0.9090909090909091\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Train the neural network on Iris data\n",
    "#\n",
    "#  From PDL Pg 186\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_iris[\"train_fs\"]\n",
    "#     np_iris[\"test_fs\" ]\n",
    "#\n",
    "#        ^^^^  cols 0 and 1 are features, col 2 is the label\n",
    "#\n",
    "\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "l_clf = MLPClassifier(\n",
    "   hidden_layer_sizes = (3, 2),\n",
    "   activation         = \"logistic\",           #  aka, sigmoid\n",
    "   solver             = \"adam\",\n",
    "   tol                = 1e-9,\n",
    "   max_iter           = 50000,                #  5000 (book) would not settle\n",
    "   verbose            = False,\n",
    "   )\n",
    "\n",
    "\n",
    "l_clf.fit(np_iris[\"train_fs\"][:, [0, 1]], np_iris[\"train_fs\"][:, -1])\n",
    "\n",
    "\n",
    "l_probability = l_clf.predict_proba(np_iris[\"test_fs\"][:, [0, 1]])\n",
    "l_score       = l_clf.score(np_iris[\"test_fs\"][:, [0 , 1]], np_iris[\"test_fs\"][:, -1]) \n",
    "   #\n",
    "l_w12         = l_clf.coefs[0]\n",
    "l_w23         = l_clf.coefs[1]\n",
    "l_w24         = l_clf.coefs[2]\n",
    "l_b1          = l_clf.intercepts[0]\n",
    "l_b1          = l_clf.intercepts[0]\n",
    "l_b1          = l_clf.intercepts[0]\n",
    "\n",
    "\n",
    "print(l_probability)\n",
    "print(l_score)\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "652f3a82-175b-48c1-9ba1-2e92c24d35d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1.27e-05 6.58e-06]\n",
      " [7.06e-07 1 2.96e-08]\n",
      " [0.00017 0.0595 0.94]\n",
      " [3.25e-07 9.53e-10 1]\n",
      " [4.3e-09 1 9.32e-12]\n",
      " [3.75e-07 1.04e-09 1]\n",
      " [4.57e-07 1 2.04e-08]\n",
      " [1.86e-06 1 6.54e-08]\n",
      " [3.43e-06 1 1.56e-07]\n",
      " [1 1.4e-05 6.94e-06]\n",
      " [1.82e-05 1 1.37e-06]\n",
      " [1 1.88e-05 7.12e-06]\n",
      " [1 2.54e-05 7.27e-06]\n",
      " [2.46e-06 1.36e-05 1]\n",
      " [4.1e-07 1 1.86e-08]\n",
      " [4.74e-06 1.59e-06 1]\n",
      " [4.74e-06 1.59e-06 1]\n",
      " [5.85e-07 7.1e-09 1]\n",
      " [1.79e-06 3.96e-06 1]\n",
      " [3.44e-07 1 1.55e-08]\n",
      " [5.39e-06 2.84e-06 1]\n",
      " [5.27e-07 4.62e-08 1]\n",
      " [2.82e-07 1 1.36e-08]\n",
      " [1 1.48e-05 6.67e-06]\n",
      " [9.14e-07 1 3.38e-08]\n",
      " [1 1.18e-05 6.11e-06]\n",
      " [1 1.1e-05 5.95e-06]\n",
      " [3.57e-07 9.72e-10 1]\n",
      " [1 1.24e-05 6.26e-06]\n",
      " [8.21e-07 1 3.11e-08]]\n",
      "0.9666666666666667\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Same as above, more rows, more columns\n",
    "#\n",
    "\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "l_clf = MLPClassifier(\n",
    "   hidden_layer_sizes = (8, 4),\n",
    "   activation         = \"logistic\",\n",
    "   solver             = \"adam\",\n",
    "   tol                = 1e-9,\n",
    "   max_iter           = 80000,                #  5000 (book) would not settle\n",
    "   verbose            = False,\n",
    "   )\n",
    "\n",
    "\n",
    "l_clf.fit(np_iris[\"train\"][:, 0:3], np_iris[\"train\"][:, -1])\n",
    "\n",
    "l_probability = l_clf.predict_proba(np_iris[\"test\"][:, 0:3])\n",
    "l_score       = l_clf.score(np_iris[\"test\"][:, 0:3], np_iris[\"test\"][:, -1]) \n",
    "\n",
    "\n",
    "print(l_probability)\n",
    "print(l_score)\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30ed00-e15b-41c4-afb9-b7f6c949e0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b37e69-c673-4d62-bfc0-54fe7422b8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad863a-124f-4428-a0aa-312936d86212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df4b7d-946c-4437-8965-d67a07a089c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976e37-8702-4f53-bf97-e28a958675f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397bde-64f0-4ec9-a728-d37e4c51ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
