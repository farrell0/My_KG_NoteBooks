{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776f754-ef98-4cbd-a423-647c483341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Here we demonstrate the following Dask DataFrame techniques;\n",
    "#\n",
    "#     .  Test, How to fetch data from a graph\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5f518-6e7b-4b73-a833-f8ea40262866",
   "metadata": {},
   "source": [
    "#  Part 01:  Setup, generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682150e3-6a50-4197-a239-80d1d2ea6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "NUM_ROWS        = 40000\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416c10d-a1cb-433d-ad5e-85498aaa1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "   #\n",
    "import dask.dataframe as dd\n",
    "   #\n",
    "from dask.dataframe import from_pandas\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c88322-8b40-4c26-9b01-60fadd32cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Generates (NUM_ROWS) rows of data\n",
    "#\n",
    "\n",
    "l_row = {\"col1\": list(), \"col2\": list()}\n",
    "   #\n",
    "for l_cntr in range(NUM_ROWS):\n",
    "   l_row[\"col1\"].append(l_cntr)\n",
    "   l_row[\"col2\"].append(\"Item number: \" + str(l_cntr))\n",
    "    \n",
    "pd_data = pd.DataFrame(l_row, columns = [\"col1\", \"col2\"])\n",
    "dd_data = from_pandas(pd_data, npartitions = NUM_PARTITIONS)\n",
    "\n",
    "\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in dd_data.itertuples():\n",
    "   l_cntr += 1\n",
    "      #\n",
    "   if (l_cntr <5):\n",
    "      print(\"Row (%d) of (%d) total rows.   Col1: (%4d)   Col2: (%s)\" % (l_cntr, len(dd_data), l_each.col1, l_each.col2))\n",
    "        \n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbdb7f3-d36a-4109-a089-714e0148233e",
   "metadata": {},
   "source": [
    "#  Part 02:  Create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f46cf-334f-42d3-9fc6-b0440fb199b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec5fcc-7c18-43ca-8a07-1ac343a74340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\" \n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf229e-a447-4771-ac6a-3c74eecb9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131298d0-5cb4-4b62-8413-5e5571ef4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b708e18-dcc4-4e8e-b508-de70687066f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d62e9-1cf8-4eee-9147-f351961b95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE GRAPHS\n",
    "\n",
    "my_graph=my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018453bc-385a-41cb-9d4f-6f578886b2ce",
   "metadata": {},
   "source": [
    "#  Part 03:  Import into the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e4b85-372f-491c-84b1-fc7714788163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:\n",
    "    \n",
    "   #  Movies\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      dd_data[[\"col1\", \"col2\"]],\n",
    "      id_column  = \"col1\",\n",
    "      id_space   = \"dd_data\"\n",
    "      )\n",
    "\n",
    "   df_importer.insert()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f49097-92db-4c90-b76c-199b5a7ca20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(\"Number of Graph Nodes: %d\" % (my_graph.num_nodes()))\n",
    "display(\"Number of Graph Edges: %s\" % (my_graph.num_edges()))\n",
    "\n",
    "#  Sample outpt,\n",
    "#\n",
    "#     'Number of Graph Nodes: 40000'\n",
    "#     'Number of Graph Edges: 0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e2410-26d9-4d2a-9070-447396fead5f",
   "metadata": {},
   "source": [
    "#  Part 04:  Run a traversal, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6e913-8271-4a3c-9f64-997ba6c1c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Aggregates, by definition, can return only one row. We use a slightly different\n",
    "#  technique to get the return value.\n",
    "#\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n) \n",
    "   RETURN COUNT(*) AS cnt\n",
    "   \"\"\".format()\n",
    "\n",
    "l_count = my_graph.query(l_query)[\"cnt\"][0]\n",
    "\n",
    "\n",
    "print(l_count)\n",
    "print(type(l_count))\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     40000\n",
    "#     <class 'numpy.int64'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c9f33-436c-44a3-ab44-63df3486d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Returning actual data, scale: 10 rows\n",
    "#\n",
    "\n",
    "l_rows = 10\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n) \n",
    "   RETURN n.col1 AS col1, n.col2 AS col2\n",
    "   LIMIT {0}\n",
    "   \"\"\".format(l_rows)\n",
    "\n",
    "dd_result1 = my_graph.query(l_query)\n",
    "\n",
    "\n",
    "print(tabulate(dd_result1, headers='keys', tablefmt='psql'))\n",
    "print(\"\")\n",
    "print(type(dd_result1))\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +----+--------+-----------------+\n",
    "#     |    |   col1 | col2            |\n",
    "#     |----+--------+-----------------|\n",
    "#     |  0 |      1 | Item number: 1  |\n",
    "#     |  1 |      6 | Item number: 6  |\n",
    "#     |  2 |      8 | Item number: 8  |\n",
    "#     |  3 |     14 | Item number: 14 |\n",
    "#     |  4 |     17 | Item number: 17 |\n",
    "#     |  5 |     21 | Item number: 21 |\n",
    "#     |  6 |     22 | Item number: 22 |\n",
    "#     |  7 |     26 | Item number: 26 |\n",
    "#     |  8 |     28 | Item number: 28 |\n",
    "#     |  9 |     30 | Item number: 30 |\n",
    "#     +----+--------+-----------------+\n",
    "#\n",
    "#     <class 'katana.remote.ResultSet'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455568-89d3-4516-ace5-c4a5411ca3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Return (NUM_ROWS: 40,000) rows.\n",
    "#\n",
    "#     This as step 1 when we want to validate contents, or use graph data\n",
    "#     for ML routines, other.\n",
    "#\n",
    "#     You should see the Python kernel become unresponsive for a long time.\n",
    "#\n",
    "\n",
    "\n",
    "#  l_rows = 40000                                #  My original use case, unresponsive for a long time\n",
    "#  l_rows = 5000                                 #  Takes 10 (?) seconds, then runs/continues\n",
    "   #\n",
    "l_rows = 1000                                    #  This scale works reliably\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n) \n",
    "   RETURN n.col1 AS col1, n.col2 AS col2\n",
    "   LIMIT {0}\n",
    "   \"\"\".format(l_rows)\n",
    "\n",
    "dd_result2 = my_graph.query(l_query)\n",
    "\n",
    "\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in dd_result2.itertuples():\n",
    "   l_cntr += 1  \n",
    "      #\n",
    "   if (l_cntr < 10):\n",
    "      print(\"Counter: %-4d   (%s)   (%s)\" % (l_cntr, l_each.col1, l_each.col2))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Number of rows in DataFrame: %d   Value of l_cntr: %d\" % (len(dd_result2), l_cntr))\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Counter: 1      (0)   (Item number: 0)\n",
    "#     Counter: 2      (5)   (Item number: 5)\n",
    "#     Counter: 3      (6)   (Item number: 6)\n",
    "#     Counter: 4      (8)   (Item number: 8)\n",
    "#     Counter: 5      (9)   (Item number: 9)\n",
    "#     Counter: 6      (11)   (Item number: 11)\n",
    "#     Counter: 7      (12)   (Item number: 12)\n",
    "#     Counter: 8      (13)   (Item number: 13)\n",
    "#     Counter: 9      (17)   (Item number: 17)\n",
    "#  \n",
    "#     Number of rows in DataFrame: 1000   Value of l_cntr: 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e4943-f54a-4315-8629-17a13f645c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Use this to see if/when next cell will run\n",
    "#\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de17d83-ae13-46e0-844d-800e5c999664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time \n",
    "\n",
    "#  Move the above to paginated fetching, which solves our (hanging, unresponsive) problem.\n",
    "#\n",
    "\n",
    "l_rows = 40000\n",
    "#  l_rows = 5000 \n",
    "#  l_rows = 10000\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n) \n",
    "   RETURN n.col1 AS col1, n.col2 AS col2\n",
    "   LIMIT {0}\n",
    "   \"\"\".format(l_rows)\n",
    "\n",
    "\n",
    "dd_result4 = my_graph.query_paginated(l_query)\n",
    "#\n",
    "#  Returns,  katana_enterprise.remote.sync_wrappers.PaginatedResultSet\n",
    "#     It has no length\n",
    "#     It has no itertuples()\n",
    "#     It does have a head, maxmimum 40\n",
    "#\n",
    "#  The above is true, because of [ paging ]. This is a list of lists.\n",
    "#  See examples below.\n",
    "\n",
    "\n",
    "#  l_resultA = dd_result3.head(10)\n",
    "#  print(type(l_resultA))\n",
    "      #\n",
    "#   Maximum value: 40\n",
    "#\n",
    "#     print(dd_result3.head(44))\n",
    "#     >> ValueError: You can only view a maximum of 40 rows.\n",
    "\n",
    "\n",
    "#  Using a query_paginated()\n",
    "#\n",
    "l_cntr1 = 0\n",
    "l_cntr2 = 0\n",
    "   #\n",
    "for l_page in dd_result4:\n",
    "   l_cntr1 += 1\n",
    "   for l_each in l_page.itertuples():\n",
    "      l_cntr2 += 1\n",
    "         #\n",
    "      if (l_cntr2 < 10):\n",
    "        print(\"Counter: %-4d   (%s)   (%s)\" % (l_cntr2, l_each.col1, l_each.col2))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Number of rows in total result set: %d   Number of pages: %d\" % (l_cntr2, l_cntr1))\n",
    " \n",
    "\n",
    "#  Again; 2MB of raw data, 40K rows.\n",
    "#        \n",
    "#  Sample output,\n",
    "#\n",
    "#     Counter: 1      (20178)   (Item number: 20178)\n",
    "#     Counter: 2      (20182)   (Item number: 20182)\n",
    "#     Counter: 3      (20183)   (Item number: 20183)\n",
    "#     Counter: 4      (20185)   (Item number: 20185)\n",
    "#     Counter: 5      (20187)   (Item number: 20187)\n",
    "#     Counter: 6      (20188)   (Item number: 20188)\n",
    "#     Counter: 7      (20189)   (Item number: 20189)\n",
    "#     Counter: 8      (20200)   (Item number: 20200)\n",
    "#     Counter: 9      (20201)   (Item number: 20201)\n",
    "#     \n",
    "#     Number of rows in total result set: 40000   Number of pages: 3\n",
    "#     CPU times: user 3min 43s, sys: 79.9 ms, total: 3min 43s\n",
    "#     Wall time: 3min 46s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038ddb4a-430e-40e9-a36b-b2bdadc621d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21531cb7b98e44f7a3704525d8784f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'set'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:26\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:8965\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8963\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m   8964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 8965\u001b[0m     \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8969\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8970\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8971\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py:294\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m     92\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/concat.py:384\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    380\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[0;32m--> 384\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    386\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'set'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time \n",
    "\n",
    "#  Modify the above; add capturing the full result set into a DataFrame\n",
    "#\n",
    "\n",
    "#  l_rows = 40000\n",
    "l_rows = 10\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n) \n",
    "   RETURN n.col1 AS col1, n.col2 AS col2\n",
    "   LIMIT {0}\n",
    "   \"\"\".format(l_rows)\n",
    "\n",
    "\n",
    "dd_result4 = my_graph.query_paginated(l_query)\n",
    "   #\n",
    "pd_data = pd.DataFrame()\n",
    "   #\n",
    "l_cntr1 = 0\n",
    "l_cntr2 = 0\n",
    "   #\n",
    "for l_page in dd_result4:\n",
    "   l_cntr1 += 1\n",
    "   for l_each in l_page.itertuples():\n",
    "      l_cntr2 += 1\n",
    "         #\n",
    "      pd_data = pd_data.append({l_each}, ignore_index=True)\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "#  print(\"Number of rows in total result set: %d   Number of pages: %d\" % (l_cntr2, l_cntr1))\n",
    " \n",
    "\n",
    "#  Sample output,\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4dd2ba-f696-4825-ab90-d6551bf2ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcfd326-a30e-4ca1-9b39-2524dfd63a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a729c3f-ab5c-4ec7-af2a-50810d5d75af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e955b06-998b-4e9f-ac19-8446a30868d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b0338-f186-4fa4-8487-737d6d4b8ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a4e65-eb1d-4e11-af61-0b14302b019a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
