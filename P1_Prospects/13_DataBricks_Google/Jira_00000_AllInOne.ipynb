{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54fd830-1317-4a52-b610-ef9716e5d744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Setup: Display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a38ebd7-d1d9-47a8-955c-a8270b024543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7ce90-67cf-462c-94a6-3c8c9d0754b3",
   "metadata": {},
   "source": [
    "# Setup: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87b75ba-c072-4111-8cca-4b4f394a0fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<katana_enterprise.remote.sync_wrappers.Client object at 0x7f1c54520bb0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from katana import remote\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a77f99-f11b-4105-ab43-17ce605b15e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2292b8-7df0-49a0-b3da-523f56cfe4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f69a0e-451b-4679-b49c-5db1208d4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3bc00-fafb-481d-ba5a-8b52ae7d6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8ba088b-2ec5-4b2a-8171-3c87ddffb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_Graph my_graph, Wq39LrHZxk85kmXBwhYQRJf3uevDrUPbm5r3Ef2EHiQ, 0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  CREATE GRAPH\n",
    "\n",
    "my_graph = my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f948b-cec2-42fb-9287-2a3bcf3e8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CONNECT TO GRAPH\n",
    "\n",
    "my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a456b-e425-454d-83a2-5b2c3e7fa666",
   "metadata": {},
   "source": [
    "# Setup: For test .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9511e9f3-bf32-4c66-b66c-382ec5e0ee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#   Build a data structure ..\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "l_UmlsVocabularyNodes         = [\n",
    "   {\"id\": \"XX-1001\", \"LABEL\": \"UmlsVocabulary\"},\n",
    "   {\"id\": \"XX-1002\", \"LABEL\": \"UmlsVocabulary\"},\n",
    "   {\"id\": \"XX-1003\", \"LABEL\": \"UmlsVocabulary\"},\n",
    "   {\"id\": \"XX-1004\", \"LABEL\": \"UmlsVocabulary\"},\n",
    "   ]\n",
    "\n",
    "l_recd3 = { \"id\": \"XX-4000\", \"vocabulary_code\": \"MMM\", \"LABEL\": \"UmlsVocabulary\" }\n",
    "   #\n",
    "l_UmlsVocabularyNodes.append(l_recd3)\n",
    "\n",
    "\n",
    "df_UmlsVocabularyNodes = pd.DataFrame.from_records(l_UmlsVocabularyNodes       ) # .drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721f96b-147e-4ed6-ad3c-d4621dca8565",
   "metadata": {},
   "source": [
    "#  Step 00:  Actual Test .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bebcb-a530-4a0a-b4a8-3a38926dfbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226d0112069c42abba096fae7018edce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  The cell that throws the error ..\n",
    "#\n",
    "#  Comments,\n",
    "#\n",
    "#     .  This is a test NoteBook, to support a Jira.\n",
    "#        In my real, larger program, I get the error pasted in the next cell.\n",
    "#\n",
    "#     .  In this sample, smaller NoteBook, the program just hangs in this cell-\n",
    "#\n",
    "\n",
    "\n",
    "from katana.remote import import_data\n",
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "     \n",
    "   df_importer.nodes_dataframe(\n",
    "      df_UmlsVocabularyNodes,\n",
    "      id_column             = \"id\",\n",
    "      id_space              = \"UmlsVocabulary\",  \n",
    "      label                 = \"UmlsVocabulary\",  \n",
    "      ) \n",
    "\n",
    "   df_importer.insert()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d607abb-6e9b-4dfd-9b10-302c237556d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     Error received above when running my larger program,\n",
    "#\n",
    "\n",
    "\n",
    "#     Host 0 errors:\n",
    "#     Traceback (most recent call last):\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py\", line 111, in execute\n",
    "#         value = function(graph)\n",
    "#       File \"/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py\", line 512, in remote_import_function\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py\", line 206, in _write_intermediate_parquet_files\n",
    "#         node_header = \"\\n\".join(_write_dfs_to_parquet(node_df_infos, \"nodes\")) + \"\\n\"\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py\", line 194, in _write_dfs_to_parquet\n",
    "#         dask.dataframe.to_parquet(\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 963, in to_parquet\n",
    "#         out = out.compute(**compute_kwargs)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/base.py\", line 315, in compute\n",
    "#         (result,) = compute(self, traverse=False, **kwargs)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/base.py\", line 598, in compute\n",
    "#         results = schedule(dsk, keys, **kwargs)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 3036, in get\n",
    "#         results = self.gather(packed, asynchronous=asynchronous, direct=direct)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 2210, in gather\n",
    "#         return self.sync(\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 338, in sync\n",
    "#         return sync(\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 405, in sync\n",
    "#         raise exc.with_traceback(tb)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 378, in f\n",
    "#         result = yield future\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/tornado/gen.py\", line 762, in run\n",
    "#         value = future.result()\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 2073, in _gather\n",
    "#         raise exception.with_traceback(traceback)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/optimization.py\", line 990, in __call__\n",
    "#         return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/core.py\", line 149, in get\n",
    "#         result = _execute_task(task, cache)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\n",
    "#         return func(*(_execute_task(a, cache) for a in args))\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 163, in __call__\n",
    "#         return self.engine.write_partition(\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py\", line 686, in write_partition\n",
    "#         t = cls._pandas_to_arrow_table(df, preserve_index=preserve_index, schema=schema)\n",
    "#       File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py\", line 647, in _pandas_to_arrow_table\n",
    "#         raise ValueError(\n",
    "#     ValueError: Failed to convert partition to expected pyarrow schema:\n",
    "#         `ArrowInvalid(\"Could not convert 'MMM' with type str: tried to convert to double\", 'Conversion failed for column vocabulary_code with type object')`\n",
    "#     \n",
    "#     Expected partition schema:\n",
    "#         id: string\n",
    "#         LABEL: string\n",
    "#         vocabulary_code: double\n",
    "#     \n",
    "#     Received partition schema:\n",
    "#         id: string\n",
    "#         LABEL: string\n",
    "#         vocabulary_code: string\n",
    "#     \n",
    "#     This error *may* be resolved by passing in schema information for\n",
    "#     the mismatched column(s) using the `schema` keyword in `to_parquet`.\n",
    "#     \n",
    "#     ---------------------------------------------------------------------------\n",
    "#     ValueError                                Traceback (most recent call last)\n",
    "#     Cell In[3], line 4\n",
    "#           1 #  Enrich/decode text entry from above\n",
    "#           2 #\n",
    "#     ----> 4 l_return, l_pvid = f_enrich(l_text01.value.lower(), my_graph)\n",
    "#           6 print(\"Unique Patient Vist Id: %s\" % (l_pvid))\n",
    "#           7 print(\"\")\n",
    "#     \n",
    "#     File ~/work/My_KG_NoteBooks/P1_Prospects/13_DataBricks_Google/libraries/SupportFor34.py:373, in f_enrich(i_arg1, i_arg2)\n",
    "#         371 l_df1, l_df2, l_fg3, l_df4, l_df5, l_df6, l_df7 = f_ready_for_graph_int(l_data_asjson, l_uniqid)\n",
    "#         372    #\n",
    "#     --> 373 f_insert_into_graph(i_arg2, l_df1, l_df2, l_fg3, l_df4, l_df5, l_df6, l_df7)\n",
    "#         376 return l_data_asjson, l_uniqid\n",
    "#     \n",
    "#     File ~/work/My_KG_NoteBooks/P1_Prospects/13_DataBricks_Google/libraries/SupportFor34.py:337, in f_insert_into_graph(i_arg1, i_arg2, i_arg3, i_arg4, i_arg5, i_arg6, i_arg7, i_arg8)\n",
    "#         295       df_importer.nodes_dataframe(\n",
    "#         296          i_arg4,\n",
    "#         297          id_column             = \"id\",\n",
    "#         298          id_space              = \"UmlsVocabulary\",  \n",
    "#         299          label                 = \"UmlsVocabulary\",  \n",
    "#         300          ) \n",
    "#         302       #  Just edges\n",
    "#         303       #\n",
    "#         304 #     df_importer.edges_dataframe(\n",
    "#        (...)\n",
    "#         334 #        type                  = \"ALSO_CODED_AS\"\n",
    "#         335 #        )\n",
    "#     --> 337       df_importer.insert()\n",
    "#         340    return\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:259, in AsyncToSync.<locals>.do_wrap.<locals>.wrapper(self, *args, **kwargs)\n",
    "#         256 @wraps(underlying_func)\n",
    "#         257 def wrapper(self, *args, **kwargs):\n",
    "#         258     return registry.async_to_sync(\n",
    "#     --> 259         underlying_func(\n",
    "#         260             get_self_func(self),\n",
    "#         261             *(registry.sync_to_async(a) for a in args),\n",
    "#         262             **{k: registry.sync_to_async(v) for k, v in kwargs.items()},\n",
    "#         263         )\n",
    "#         264     )\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:176, in async_to_sync.<locals>.wrapper(timeout, *args, **kwargs)\n",
    "#         166     registry = AsyncToSyncClassRegistry.get()\n",
    "#         167     return registry.async_to_sync(\n",
    "#         168         wait_for(\n",
    "#         169             async_func(\n",
    "#        (...)\n",
    "#         174         )\n",
    "#         175     )\n",
    "#     --> 176 return wait_for(async_func(*args, **kwargs), timeout=timeout)\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:147, in wait_for(coro, timeout)\n",
    "#         145 try:\n",
    "#         146     future = asyncio.run_coroutine_threadsafe(timeout_coro, loop=AsyncRunnerThread.get().loop)\n",
    "#     --> 147     return future.result()\n",
    "#         148 except KeyboardInterrupt:\n",
    "#         149     inner_future.cancel()\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/concurrent/futures/_base.py:444, in Future.result(self, timeout)\n",
    "#         442     raise CancelledError()\n",
    "#         443 elif self._state == FINISHED:\n",
    "#     --> 444     return self.__get_result()\n",
    "#         445 else:\n",
    "#         446     raise TimeoutError()\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/concurrent/futures/_base.py:389, in Future.__get_result(self)\n",
    "#         387 if self._exception:\n",
    "#         388     try:\n",
    "#     --> 389         raise self._exception\n",
    "#         390     finally:\n",
    "#         391         # Break a reference cycle with the exception in self._exception\n",
    "#         392         self = None\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/asyncio/tasks.py:455, in wait_for(fut, timeout, loop)\n",
    "#         450     warnings.warn(\"The loop argument is deprecated since Python 3.8, \"\n",
    "#         451                   \"and scheduled for removal in Python 3.10.\",\n",
    "#         452                   DeprecationWarning, stacklevel=2)\n",
    "#         454 if timeout is None:\n",
    "#     --> 455     return await fut\n",
    "#         457 if timeout <= 0:\n",
    "#         458     fut = ensure_future(fut, loop=loop)\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py:539, in DataFrameImporter.__aexit__(self, exc_type, exc_val, exc_tb)\n",
    "#         537 async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "#         538     if not exc_type:\n",
    "#     --> 539         await self.execute()\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py:530, in DataFrameImporter.execute(self)\n",
    "#         526     csv_options.edge_match_property = edge_global_info.join_key_column or \"\"\n",
    "#         528     bulk_ingest_native(csv_options, graph)\n",
    "#     --> 530 await self.graph.run(remote_import_function)\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:660, in Graph.run(self, function)\n",
    "#         658 print(result.stdout, file=sys.stdout, end=\"\")\n",
    "#         659 print(result.stderr, file=sys.stderr, end=\"\")\n",
    "#     --> 660 return result.value\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/run_result.py:16, in RunResult.value(self)\n",
    "#          14 @property\n",
    "#          15 def value(self):\n",
    "#     ---> 16     self.reraise_if_error()\n",
    "#          17     assert self.success\n",
    "#          18     return self._value\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/run_result.py:12, in RunResult.reraise_if_error(self)\n",
    "#          10 def reraise_if_error(self):\n",
    "#          11     if not self.success:\n",
    "#     ---> 12         raise self._value\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py:153, in execute()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py:111, in execute()\n",
    "#     \n",
    "#     File /opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py:512, in remote_import_function()\n",
    "#         510 if MPI.COMM_WORLD.Get_rank() == 0:\n",
    "#         511     with dask_integration.client():\n",
    "#     --> 512         node_header, edge_header = parquet_write_fun(graph, node_df_infos, edge_df_infos)\n",
    "#         514 node_header, edge_header = MPI.COMM_WORLD.bcast((node_header, edge_header), root=0)\n",
    "#         516 csv_options = CSVImportOptions(node_header, edge_header, stash_uri_for_graph(graph))\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py:206, in _write_intermediate_parquet_files()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/aio/import_data/dataframe_importer/__init__.py:194, in _write_dfs_to_parquet()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:963, in to_parquet()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/base.py:315, in compute()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/base.py:598, in compute()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/client.py:3036, in get()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/client.py:2210, in gather()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:338, in sync()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:405, in sync()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:378, in f()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/tornado/gen.py:762, in run()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/distributed/client.py:2073, in _gather()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/optimization.py:990, in __call__()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/core.py:149, in get()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/core.py:119, in _execute_task()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:163, in __call__()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:686, in write_partition()\n",
    "#     \n",
    "#     File /opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:647, in _pandas_to_arrow_table()\n",
    "#     \n",
    "#     ValueError: Failed to convert partition to expected pyarrow schema:\n",
    "#         `ArrowInvalid(\"Could not convert 'MMM' with type str: tried to convert to double\", 'Conversion failed for column vocabulary_code with type object')`\n",
    "#     \n",
    "#     Expected partition schema:\n",
    "#         id: string\n",
    "#         LABEL: string\n",
    "#         vocabulary_code: double\n",
    "#     \n",
    "#     Received partition schema:\n",
    "#         id: string\n",
    "#         LABEL: string\n",
    "#         vocabulary_code: string\n",
    "#     \n",
    "#     This error *may* be resolved by passing in schema information for\n",
    "#     the mismatched column(s) using the `schema` keyword in `to_parquet`.\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
