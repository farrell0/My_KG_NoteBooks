{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data sets ..\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {},
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "#  **  You must run this cell to do much of anything in this NoteBook\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "\n",
    "#  The sklearn ML routines follow a very consistent pattern. As such, we\n",
    "#  put these in a function, reduce redundant code below-\n",
    "#\n",
    "\n",
    "def do_model(i_routine, i_train_data, i_train_labels, i_test_data, i_test_labels, i_name_of_test):\n",
    "\n",
    "   #  Train whatever model\n",
    "   #\n",
    "   i_routine.fit(i_train_data, i_train_labels)\n",
    "   \n",
    "   #  Predict on the test data\n",
    "   #\n",
    "   l_predicted_labels = i_routine.predict(i_test_data)\n",
    "   l_accuracy         = (i_routine.score(i_test_data, i_test_labels) * 100)\n",
    "      #\n",
    "   l_history.add(event = i_name_of_test, measure = l_accuracy)\n",
    "   \n",
    "   #  Output results\n",
    "   #\n",
    "   print(i_name_of_test + \" ...\")\n",
    "   print(\"   Actual    labels from test......... %s\" % (i_test_labels     ) )\n",
    "   print(\"   Predicted labels from test......... %s\" % (l_predicted_labels) )\n",
    "   print(   \"   ###\")\n",
    "   print(\"   Accuracy: %0.4f %%\" % (l_accuracy))\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe2eac-169f-4068-b5a4-d70e1e2856a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Boxplot, and normalize ..\n",
    "#\n",
    "#  Normalize from,\n",
    "#     https://datascience.stackexchange.com/questions/39142/normalize-matrix-in-python-numpy\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "   #\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(type(np_iris[\"train\"]))\n",
    "\n",
    "plt.boxplot(np_iris[\"train\"])\n",
    "plt.show()\n",
    "\n",
    "   ###\n",
    "\n",
    "def my_normalize(X, x_min, x_max):\n",
    "   nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "   denom = X.max(axis=0) - X.min(axis=0)\n",
    "   denom[denom==0] = 1\n",
    "   return x_min + nom/denom \n",
    "\n",
    "#  If we normalize the \"class\" column, we lose the categorical nature\n",
    "#  of that data. So, create a deep copy, then just normalize the non-\n",
    "#  class columns.\n",
    "#\n",
    "np_iris[\"train_norm\"] = np.copy(np_iris[\"train\"])\n",
    "np_iris[\"test_norm\" ] = np.copy(np_iris[\"test\" ])\n",
    "   #\n",
    "np_iris[\"train_norm\"][:, :4] = my_normalize(np_iris[\"train_norm\"][:, :4], 0, 1)\n",
    "np_iris[\"test_norm\" ][:, :4] = my_normalize(np_iris[\"test_norm\" ][:, :4], 0, 1)\n",
    "\n",
    "plt.boxplot(np_iris[\"train_norm\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Legend:\n",
    "#\n",
    "#  Per a given column-\n",
    "#\n",
    "#    . The lower box line, marks 1st quartile. 25% of entries are below this line\n",
    "#      Middle line, 2nd.                       50% above/below\n",
    "#      Top box line, 3rd.                      25% above\n",
    "#\n",
    "#    . The true top and bottom lines-\n",
    "#      There's a formula for this; marks the boundary for entries considered outliers.\n",
    "#\n",
    "#           o            Outliers\n",
    "#           o\n",
    "#\n",
    "#          ---           Q3 + 1.5 QR\n",
    "#           |\n",
    "#           |\n",
    "#           |\n",
    "#           |\n",
    "#       +-------+        Q3      <-----------------+\n",
    "#       |       |                                  |\n",
    "#       |       |                                 1 QR\n",
    "#       +-------+        Median  (Q2)              |\n",
    "#       |       |                                  |\n",
    "#       |       |                                  |\n",
    "#       +-------+        Q1      <-----------------+\n",
    "#           |\n",
    "#           |\n",
    "#          ---           Q1 - 1.5 QR\n",
    "#\n",
    "#           o\n",
    "#           o\n",
    "#           o            Outliers\n",
    "#           o\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642d7fa-e89f-47c8-90c4-13e33fc2106c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A2: Iris Data train, test .. NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15b429-f361-434a-a3c4-f91f48d61824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: Centroid\") \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(NearestCentroid(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: Centroid Normalized\") \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25a3d4-cf32-4503-8c86-e14146b7fa9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A3: Iris Data train, test .. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1202c-c630-4e27-aea8-4ed425b139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: kNN=3\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: kNN=3 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5328044-4f54-41b6-a37a-0f96a11e2250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A4: Iris Data train, test .. Naive Bayes, Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1740a-f656-4d6d-bdf3-cb2f053fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#  Naive Bayes, Gaussian\n",
    "#\n",
    "#     Gaussian usually does better than the Multinomial below because,\n",
    "#        Gaussian expects continuous values\n",
    "#        Multinomial expects discreet values\n",
    "#\n",
    "#     And our values are continuous\n",
    "#\n",
    "\n",
    "do_model(GaussianNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: GaussianNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(GaussianNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: GaussianNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f815d9-6eb7-4aaa-863c-3c7ce613d127",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A5: Iris Data train, test .. Naive Bayes, Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e0e-31d0-44c1-bdb3-0ee3c5ca3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Naive Bayes, Multinomial\n",
    "#\n",
    "\n",
    "do_model(MultinomialNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: MultinomialNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(MultinomialNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: MultinomialNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662897e8-2b96-4d7a-bf24-74aa2da5c006",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A6: Iris Data train, test .. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb7874-3d2c-4f27-83db-147b953228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Decision Tree\n",
    "#\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: DecisionTree\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(DecisionTreeClassifier(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: DecisionTree Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5d6be-ecfa-4ca1-b518-0b37274c04de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A7: Iris Data train, test .. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a74fa-57c5-44ef-ade3-dd5438751064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  Random Forest\n",
    "#\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RandomForest\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RandomForest Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7973bf-5a1a-4999-810d-91e52c13bd0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step A8: Iris Data train, test .. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0262-190c-455d-b2f9-99056c1bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: SVC/Linear\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: SVC/Linear Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF 2\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF 2 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45c758-b0db-43dd-9aa7-832598413085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3964740-6c41-4e86-8dd0-0cd5f7101cee",
   "metadata": {},
   "source": [
    "##  Block: All things Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cf6a-434a-4fcf-bfdb-edc3308c5252",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step B1:  Breast Cancer Data load, encode, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe262a-4fb5-4954-9d6f-c8cbea09d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Breast Cancer data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1)     ID number\n",
    "#     2)     Diagnosis (M = malignant, B = benign)\n",
    "#     3-32)\n",
    "#       Ten real-valued features are computed for each cell nucleus:\n",
    "#     \n",
    "#     \ta) radius (mean of distances from center to points on the perimeter)\n",
    "#     \tb) texture (standard deviation of gray-scale values)\n",
    "#     \tc) perimeter\n",
    "#     \td) area\n",
    "#     \te) smoothness (local variation in radius lengths)\n",
    "#     \tf) compactness (perimeter^2 / area - 1.0)\n",
    "#     \tg) concavity (severity of concave portions of the contour)\n",
    "#     \th) concave points (number of concave portions of the contour)\n",
    "#     \ti) symmetry \n",
    "#     \tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "#\n",
    "#  Sample data line,\n",
    "#     842302,M,\n",
    "#     17.99,    10.38,    122.8,    1001,    0.1184,    0.2776,    0.3001,    0.1471,    0.2419,    0.07871,         #  10 count\n",
    "#     1.095,    0.9053,   8.589,    153.4,   0.006399,  0.04904,   0.05373,   0.01587,   0.03003,   0.006193,\n",
    "#     25.38,    17.33,    184.6,    2019,    0.1622,    0.6656,    0.7119,    0.2654,    0.4601     ,0.1189\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"22_wdbc.data.txt\"\n",
    "\n",
    "\n",
    "pd_bc  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"id\", \"class\",\n",
    "            \"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \n",
    "            \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\", \"f20\", \n",
    "            \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "           ],\n",
    "   dtype = {\"id\": \"int\", \"class\": \"string\",\n",
    "            \"f01\": \"float\", \"f02\": \"float\", \"f03\": \"float\", \"f04\": \"float\", \"f05\": \"float\", \"f06\": \"float\", \"f07\": \"float\", \"f08\": \"float\", \"f09\": \"float\", \"f10\": \"float\", \n",
    "            \"f11\": \"float\", \"f12\": \"float\", \"f13\": \"float\", \"f14\": \"float\", \"f15\": \"float\", \"f16\": \"float\", \"f17\": \"float\", \"f18\": \"float\", \"f19\": \"float\", \"f20\": \"float\", \n",
    "            \"f21\": \"float\", \"f22\": \"float\", \"f23\": \"float\", \"f24\": \"float\", \"f25\": \"float\", \"f26\": \"float\", \"f27\": \"float\", \"f28\": \"float\", \"f29\": \"float\", \"f30\": \"float\", \n",
    "           } )\n",
    "      #\n",
    "pd_bc[\"class_encoded\"]  =  my_le.fit_transform(pd_bc[\"class\"])\n",
    "   #\n",
    "pd_bc = pd_bc.drop([\"class\", \"id\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized count of rows\n",
    "#\n",
    "print(tabulate(pd_bc.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_bc)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05409-32ac-4da0-bd05-6d97b35df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_bc = {}\n",
    "   #\n",
    "np_bc[\"train\"], np_bc[\"test\"] = train_test_split(pd_bc.to_numpy(),                    #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_bc), len(np_bc[\"train\"]), len(np_bc[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_bc[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_bc[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885ac6-db00-4fd0-9ef3-c7b5bd130542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Normalizing the data\n",
    "#\n",
    "\n",
    "def my_normalize(X, x_min, x_max):\n",
    "   nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "   denom = X.max(axis=0) - X.min(axis=0)\n",
    "   denom[denom==0] = 1\n",
    "   return x_min + nom/denom \n",
    "\n",
    "\n",
    "print(\"Number of columns in matrix: %d\" % (np_bc[\"train\"].shape[1]))\n",
    "      \n",
    "#  If we normalize the \"class\" column, we lose the categorical nature\n",
    "#  of that data. So, create a deep copy, then just normalize the non-\n",
    "#  class columns.\n",
    "#\n",
    "np_bc[\"train_norm\"] = np.copy(np_bc[\"train\"])\n",
    "np_bc[\"test_norm\" ] = np.copy(np_bc[\"test\" ])\n",
    "   #\n",
    "np_bc[\"train_norm\"][:, :30] = my_normalize(np_bc[\"train_norm\"][:, :30], 0, 1)\n",
    "np_bc[\"test_norm\" ][:, :30] = my_normalize(np_bc[\"test_norm\" ][:, :30], 0, 1)\n",
    "\n",
    "plt.boxplot(np_bc[\"train\"     ])\n",
    "plt.show()\n",
    "plt.boxplot(np_bc[\"train_norm\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a63d6f-96d6-42c3-9782-8be69c555bef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step B2:  Breast Cancer Data, run against all models .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36b4ec-23da-4af1-8cb4-fe5669cc5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "#  Our numpy array has many columns, with the last column being the class.\n",
    "#\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 30 columns use,\n",
    "#        np_iris[\"train\"][:, :30]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Centroid\") \n",
    "#  do_model(NearestCentroid(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Centroid Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: kNN=3\") \n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: kNN=3 Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: GaussianNB\") \n",
    "#  do_model(GaussianNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: GaussianNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: MultinomialNB\") \n",
    "#  do_model(MultinomialNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: MultinomialNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: DecisionTree\") \n",
    "#  do_model(DecisionTreeClassifier(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: DecisionTree Normalized\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Random Forest = 5\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Random Forest = 5 Normalized\") \n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: SVC/Linear\") \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: SVC/Linear Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF 2\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF 2 Normalized\") \n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ab3c9-9466-440d-bab4-51c4369c11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25592f04-c344-4a58-8c1d-1d8684656a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step C1:  MNist Data load, encode, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb083d-60ba-4c42-b65c-f8f7c0864b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We will be using Keras, so pip install it inside the Jupyter NoteBook container ..\n",
    "#\n",
    "\n",
    "l_package1 = \"keras\"\n",
    "l_package2 = \"tensorflow\"\n",
    "    \n",
    "def my_func(arg1):\n",
    "    \n",
    "   import sys\n",
    "   import subprocess\n",
    "    \n",
    "   subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", arg1 ])\n",
    "      #\n",
    "   print(\"From each host ..\")\n",
    "      #\n",
    "   return\n",
    "\n",
    "\n",
    "   ##########################################\n",
    "    \n",
    "\n",
    "print(\"Install Python Pip packages on Jupyter container ..\")\n",
    "   #\n",
    "my_return = my_func(l_package1)\n",
    "my_return = my_func(l_package2)\n",
    "print()\n",
    "    \n",
    "\n",
    "#  Use this if installing o nthe KGIP worker nodes ..\n",
    "#\n",
    "#  print(\"Install Python Pip packages on KGIP worker node containers ..\")\n",
    "#     # \n",
    "#  my_return = my_graph.run(lambda g: my_func(l_package))\n",
    "#  print()\n",
    "    \n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a359-02b1-4bb0-aced-216eb7cad1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Intead of loading MNist from disk, we load it from the Keras library ..\n",
    "#\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "np_mnist = {}\n",
    "   #\n",
    "(np_mnist[\"train\"], np_mnist[\"train_label\"]), (np_mnist[\"test\"], np_mnist[\"test_label\"]) = mnist.load_data()\n",
    "\n",
    "\n",
    "#  train and test ccome in as an array [(n), 28, 28] where n == 60000 for train,\n",
    "#  and 100000 for test\n",
    "#\n",
    "#  We need that 28*28 as a vector, so ..\n",
    "#\n",
    "np_mnist[\"train_v\"] = np_mnist[\"train\"].reshape(-1, 28*28)\n",
    "np_mnist[\"test_v\"]  = np_mnist[\"test\" ].reshape(-1, 28*28)\n",
    "\n",
    "\n",
    "print(\"Train shape ................ %s\" % (str(np_mnist[\"train\"].shape)))\n",
    "print(\"Train label shape .......... %s\" % (str(np_mnist[\"train_label\"].shape)))\n",
    "   #\n",
    "print(\"Test  shape ................ %s\" % (str(np_mnist[\"test\"].shape)))\n",
    "print(\"Test  label shape .......... %s\" % (str(np_mnist[\"test_label\"].shape)))\n",
    "   #\n",
    "print(\"Train vector shape ......... %s\" % (str(np_mnist[\"train_v\"].shape)))\n",
    "print(\"Test  vector shape ......... %s\" % (str(np_mnist[\"test_v\" ].shape)))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "#  tabulate() displays poorly with this wide data. Straight up print() works well.\n",
    "#\n",
    "# print(tabulate(np_mnist[\"train\"][0:2], headers='keys', tablefmt='psql', showindex=False))\n",
    "print(np_mnist[\"train\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"train_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "    \n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3148ac2-2ed4-433c-8825-745eb7e269b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step CN: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425b03-8d9c-4208-af6b-9f6115104b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     Train shape ................ (60000, 28, 28)\n",
    "#     Train label shape .......... (60000,)\n",
    "#     Test  shape ................ (10000, 28, 28)\n",
    "#     Test  label shape .......... (10000,)\n",
    "#     Train vector shape ......... (60000, 784)\n",
    "#     Test  vector shape ......... (10000, 784)\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252 253 122   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228  47  79 255 168   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0   0   0 253 252 165   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253 196   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135 253 186  12   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165 252 173   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167  56   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [5 0]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [7 2]\n",
    "#     Number of rows: 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a3191-9af2-4937-9221-3499953b67a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step CN: End of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cda4d-95a6-46ac-8871-aa7826962680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step C2: MNist train, test .. (All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bcf95-6f46-448e-a618-4bf0fb15e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97564456-56d7-4f55-b4d8-94ec6ddde2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "\n",
    "#  Here we run given ML routines against the MNist data set\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Adding these to the above\n",
    "#\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e883ec4-3c77-43cd-8d71-588f58f12503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Centroid\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=3\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=7\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: GaussianNB\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: DecisionTree\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   \") \n",
    "do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  \") \n",
    "do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 \") \n",
    "do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "#  As configured, these throw warnings, never settle ..\n",
    "#\n",
    "\n",
    "#  do_model(LinearSVC(C = 0.01), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.01   \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 0.1 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.1    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 1.0 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=1.0    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 10.0), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=10.0   \") \n",
    "#  print()\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac6b7c-b45d-49fa-95ba-e5cafed4af26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step CN: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b1c44-a03b-4965-9f81-c838e23136ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     MNist: Centroid ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 2 9 0 2 9 0 1 5 9 7 3 4 7 6 4 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 0 6 6 0 1 8 8 4 5 6 7 8 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 82.0300 %\n",
    "#     \n",
    "#     MNist: kNN=3 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0500 %\n",
    "#     MNist: kNN=7 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.9400 %\n",
    "#     \n",
    "#     MNist: GaussianNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [9 2 1 0 9 1 8 9 4 9 0 6 9 0 1 0 9 7 2 9 9 6 6 8 9 0 7 9 0 1 ... 6 0 8 9 8 8 6 9 1 9 3 6 6 0 1 9 8 9 8 6 9 8 9 0 1 8 8 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 55.5800 %\n",
    "#     \n",
    "#     MNist: MultinomialNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 3 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 2 2 4 9 4 2 6 4 1 7 2 6 6 0 1 8 8 4 5 6 7 8 9 0 1 2 3 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6500 %\n",
    "#     \n",
    "#     MNist: DecisionTree ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 7 6 9 0 6 9 0 1 5 9 7 6 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 8 4 1 7 5 6 8 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.6700 %\n",
    "#     \n",
    "#     MNist: Random Forest = 5    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 8 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 91.9100 %\n",
    "#     MNist: Random Forest = 50   ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 3 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.7000 %\n",
    "#     MNist: Random Forest = 500  ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0400 %\n",
    "#     MNist: Random Forest = 5000 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.1800 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.01    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.1200 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.1     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 1 6 4 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 4 4 2 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 86.4700 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=1.0     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 2 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.9900 %\n",
    "#     \n",
    "#     MNist: LinearSVC c=10.0    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 8 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 8 8 4 5 6 7 8 9 0 1 8 3 5 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6900 %\n",
    "#     \n",
    "#     \n",
    "#     +-----------------------------+------------+\n",
    "#     | Category                    | Accuracy   |\n",
    "#     |-----------------------------+------------|\n",
    "#     |                             |            |\n",
    "#     | MNist: Centroid             | 82.03      |\n",
    "#     | MNist: kNN=3                | 97.05      |\n",
    "#     | MNist: kNN=7                | 96.94      |\n",
    "#     | MNist: GaussianNB           | 55.58      |\n",
    "#     | MNist: MultinomialNB        | 83.65      |\n",
    "#     | MNist: DecisionTree         | 87.67      |\n",
    "#     | MNist: Random Forest = 5    | 91.91      |\n",
    "#     | MNist: Random Forest = 50   | 96.7       |\n",
    "#     | MNist: Random Forest = 500  | 97.04      |\n",
    "#     | MNist: Random Forest = 5000 | 97.18      |\n",
    "#     | MNist: LinearSVC c=0.01     | 87.12      |\n",
    "#     | MNist: LinearSVC c=0.1      | 86.47      |\n",
    "#     | MNist: LinearSVC c=1.0      | 83.99      |\n",
    "#     | MNist: LinearSVC c=10.0     | 83.69      |\n",
    "#     +-----------------------------+------------+\n",
    "#     \n",
    "#     --\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612d30f-3774-4620-a843-7c04c7a6095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Regarding this,\n",
    "#\n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
    "#        Liblinear failed to converge, increase the number of iterations.\n",
    "#        warnings.warn(\n",
    "#\n",
    "#  From,\n",
    "#     https://stackoverflow.com/questions/52670012/convergencewarning-liblinear-failed-to-converge-increase-the-number-of-iterati\n",
    "#\n",
    "#      Normally when an optimization algorithm does not converge, it is usually because the problem is not well-conditioned,\n",
    "#      perhaps due to a poor scaling of the decision variables. There are a few things you can try.\n",
    "#      \n",
    "#          Normalize your training data so that the problem hopefully becomes more well conditioned, which in turn can speed up\n",
    "#          convergence. One possibility is to scale your data to 0 mean, unit standard deviation using Scikit-Learn's StandardScaler\n",
    "#          for an example.\n",
    "#\n",
    "#          Note that you have to apply the StandardScaler fitted on the training data to the test data. Also, if you have discrete\n",
    "#          features, make sure they are transformed properly so that scaling them makes sense.\n",
    "#\n",
    "#          Related to 1), make sure the other arguments such as regularization weight, C, is set appropriately. C has to be > 0.\n",
    "#          Typically one would try various values of C in a logarithmic scale (1e-5, 1e-4, 1e-3, ..., 1, 10, 100, ...) before\n",
    "#          finetuning it at finer granularity within a particular interval. These days, it probably make more sense to tune\n",
    "#          parameters using, for e.g., Bayesian Optimization using a package such as Scikit-Optimize.\n",
    "#\n",
    "#          Set max_iter to a larger value. The default is 1000. This should be your last resort. If the optimization process does\n",
    "#          not converge within the first 1000 iterations, having it converge by setting a larger max_iter typically masks other\n",
    "#          problems such as those described in 1) and 2). It might even indicate that you have some in appropriate features or\n",
    "#          strong correlations in the features. Debug those first before taking this easy way out.\n",
    "#\n",
    "#          Set dual = True if number of features > number of examples and vice versa. This solves the SVM optimization problem using\n",
    "#          the dual formulation. Thanks @Nino van Hooff for pointing this out, and @JamesKo for spotting my mistake.\n",
    "#\n",
    "#          Use a different solver, for e.g., the L-BFGS solver if you are using Logistic Regression. See @5ervant's answer.\n",
    "#      \n",
    "#      Note: One should not ignore this warning.\n",
    "#      \n",
    "#      This warning came about because\n",
    "#      \n",
    "#          Solving the linear SVM is just solving a quadratic optimization problem. The solver is typically an iterative algorithm\n",
    "#          that keeps a running estimate of the solution (i.e., the weight and bias for the SVM). It stops running when the solution\n",
    "#          corresponds to an objective value that is optimal for this convex optimization problem, or when it hits the maximum number\n",
    "#          of iterations set.\n",
    "#      \n",
    "#          If the algorithm does not converge, then the current estimate of the SVM's parameters are not guaranteed to be any good, \n",
    "#          hence the predictions can also be complete garbage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3b1a5-ff23-4af4-bc41-4798e0c58487",
   "metadata": {},
   "source": [
    "#  Step CN: End of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d986c-991a-472c-b2a0-62ac654473fc",
   "metadata": {},
   "source": [
    "#  Step C3: Compare MNist test when data is randomized .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff57e71-9dc7-4e7c-9e6c-eb447e07867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2]\n",
      "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
      "  [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
      "  [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
      "  [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
      "Number of rows: 10000\n",
      "\n",
      "[  7   2]\n",
      "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0  22   0   0 249   0  17 198]\n",
      "  [254   0   0   0   0   0   0   0   0  52   0   0   0   0 229   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0 224   0   0 198   0   0 236   0   0   0   0  18   0   0   0   0   0 115   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0  67   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 233   0   0  35   0  67 254 219   0   0   0   0  19   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0  62   0   0   0   0   0   0 254 185   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0   0]\n",
      "  [254   0   0   0   0   0   0   0 251   0   0   0   0   0   0   0   0   0   0   0 205   0 254   0   0   0   0   0]\n",
      "  [  0   0  77 254  61   0   0   0   0   0   0   0   0  14 225 238   0   0   0   0   0   0 254   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 198 151   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0 253   0   0   0   0   0 198   0   0   0   0   0   0   0   0   0   0  83   0   0   0]\n",
      "  [182   0   0   0   0   0   0  84   0   0   0   0 254 254   0   0   0   0   0   0   0   0  66 254   0   0  59  83]\n",
      "  [  0   0   0   0   0   0   0   0   0  44   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0  75 198   0]\n",
      "  [  0   0   0   0   0   3  36   0   0 133 106   0   0   0   0   0   0   0   0   0   0   0 227 198   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  57 254   0   0   0   0  52 203 198   0   0   0   0   0   0   0   0   5]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21   0   0   0   0 254   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 221   0   0   0 219  67   0   0   0   0   0   0 240]\n",
      "  [  0  60   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0   0  58   0]\n",
      "  [  0   0   0   0 254   0   0   0   0   0   0 121   0   0   0   0   0   0   0   0 159   0   0   0   0   0 248 255]\n",
      "  [  0   0   0   0   0  59   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0  67   0   0   0   0   0]\n",
      "  [  0   1   0 254   0   0   0 140 114   0   0   0   0   0   0   0   0   0   0   0   0   0   0  40   0   0 114   0]\n",
      "  [  0   0   0   0   0   0   0  18   0   0   0   0 254   0 254   0   0   0   0   0   0   0   0   0 121   0   0   0]\n",
      "  [  0   0   0   0   0   0 209   0 254 254   0   0   0   0   0 198   0   0   0 163   0   0 250   0   0 254   0   0]\n",
      "  [  0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0  38   0   0   0]\n",
      "  [  0   0   0 166 129  72   0   0   0   0   0   0   0   0   0   0   0 133   0   0 254   0   0   0   0 207   0   0]\n",
      "  [  0   0 254   0   0   0   0   0   0   0   0   0 222   0   0   0 242   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0 241   0   0   0 126   0   0   0   0   0 187   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0   0   0   0   0 218   0 253   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0]\n",
      "  [253   0   0   0   0   0 169   0   0   0 210  20   0   0   0   0   0   0   0   0   0   0   0   0  65   0   0 134]\n",
      "  [  0   0   0   0   0   0   0   0 253   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   6   0  10   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0  37 253  20  12   0 253]\n",
      "  [  0   0   0   0 168   0 253   0   0   0   0   0 248   0   0   0   0   0   0   0 253   0   0   0   0   0  57   0]\n",
      "  [  0  78   0  10   0   0   0   0 123   0   0   0  43   0   0   0   0   0   0   0   0   0 200   0 253   0   0   0]\n",
      "  [  0 253 253   0   0  32   0   0   0   0   0   0  93   0   0   0   0  12   0   0   0   0   0   0  20   0  25 253]\n",
      "  [198   0   0   0   0   0   0   0   0   0 233   0   0   0   0   0   0   0   0   0 116 253   0   0 122   0   0   0]\n",
      "  [  0   0 253 166   0   0   0   0   0 253   0   0   0 253   0 253   0   0   0   0   0   0   0 206   0   0   0   0]\n",
      "  [  0   0 253   0   0   0   0   0   0  41   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0  30   0   0   0   0   0   0   0   0 173  31   0   0 231   0   0 143   0   0   0 253   0   0   0   0   0]\n",
      "  [  0 253 128   0   0 155   0   0   0   5 253 141   0   0  77   0   0   0   0   0   0   0   0 253   0   0   0   0]\n",
      "  [  0   0   0 250   0 123   0   0   0   0 122   0   0   0 159   0   0   0   0   0   0   0   0 253 171   0   0   0]\n",
      "  [  0   0   0   0   0  35 253   0   0   0   0   0 125   0   0   0   0   0   0   0   0   0 253   0   0   0   0   0]\n",
      "  [  0   0 144   0   0   0   0   0 169   0   0  63   0   0   0   0 213   0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [118   0   0   0   0   0   0   0   0   0   0   0   0   0   0 210   0   0   0   0   0   0   0   0   0   0 150   0]\n",
      "  [  0   0   0   0   0   0   0   0  25 253   0   0   0   0   0   0   0   0   0   0   0   0 117   0   0   0   0   0]\n",
      "  [246   0   0   0   0   0   0   0   0   0   5   0   0  65   0   0 253 150   0 123   0   0   0 253   0   0   0 253]\n",
      "  [  0   0  20   0   0   0   0   0   0   0   0   0   0   0   0 174   0   0   0   0   0 253   0   0   0   0 150   0]\n",
      "  [  0   0   0   0 248   0   0   0   0   0   0   0   0 253   0 248   0   0   0 253   0 142   0   0 253 253  12   0]\n",
      "  [  0   0   0   0   0   0 253   0   0   0  52   0   0   0   0   0 166   0 253   0   0   0 253   0   0   0   0   0]\n",
      "  [  0   0 253   0   0 176 253   0   0   0 247   0   0 253   0   0 253 248   0   0   0   0   0   0 176   0 123   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  12   0 189   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0 253]\n",
      "  [  0   0 253   0   0   0   0   0   0 253   0  25   0   0   0   0   0   0 248   0   0 255   0   0   0 198   0   0]\n",
      "  [  0   0   0   0   0   0   0 253   0   0   0   0 253 141   0   0   0   0 253  19 247 123   0   0 117   0   0   0]\n",
      "  [169  20   0 253   0   0   0   0 253   0 123   0   0  20 249 140 253   0 247   0   0   0   0 150 253   0   0 253]\n",
      "  [  0   0   0   0 209   0   0   0   0   0 251 253   0   0  76   0   0   0   0   0   0   0 247   0   0   0   0 117]\n",
      "  [  0   0   0   0 253   0   0  18   0 253   0   0 147 234   0 253   0   0   0   0 253   0   0   0 255   0   0   0]]]\n",
      "Number of rows: 2\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  Effect of randomness, moving the bits around inside each image\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_mnist[\"train\"] \n",
    "#     np_mnist[\"train_label\"]\n",
    "#     np_mnist[\"test\"]\n",
    "#     np_mnist[\"test_label\"]\n",
    "#     np_mnist[\"train_v\"]           #  vectors of the two data sets above\n",
    "#     np_mnist[\"test_v\"] \n",
    "#\n",
    "\n",
    "#  Here we want to copy the two \"v\" arrays and randomize them\n",
    "#\n",
    "np_mnist[\"train_v_s\"] = np.copy(np_mnist[\"train_v\"])\n",
    "np_mnist[\"test_v_s\" ] = np.copy(np_mnist[\"test_v\" ])\n",
    "   #\n",
    "for i in range(np_mnist[\"train_v_s\"].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"train_v_s\"][i, :])\n",
    "for i in range(np_mnist[\"test_v_s\" ].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"test_v_s\" ][i, :])\n",
    "\n",
    "\n",
    "#  Looking at the non-scrambled, and yes-scrambled data\n",
    "#\n",
    "#  Currently the data lives as a vector. To look at it, copy\n",
    "#  it back to a 28*28 numpy array. We only need this for two\n",
    "#  rows we wish to view, and we choose to use test.\n",
    "#\n",
    "np_mnist[\"test_s\"] = np.zeros((2, np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2]), dtype = int)\n",
    "   #\n",
    "for i in range(np_mnist[\"test_s\"].shape[0]):\n",
    "   np_mnist[\"test_s\"][i,:,:] = np_mnist[\"test_v_s\"][i].reshape(28, 28)\n",
    "\n",
    "#  And the actual print\n",
    "#\n",
    "#  Non-randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "#  Problems with print formatting. These lines help\n",
    "#\n",
    "np.set_printoptions()\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000,  formatter = dict(int = lambda x: \"%3i\" % x))\n",
    "\n",
    "#  Randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test_s\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_s\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40de98e-9e12-4ee5-bc98-b3ab683ade35",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step CN: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1983d12-36a3-42fd-83dc-3fb41fe464d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [ 61   0  38   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0 198 241   0   0   0]\n",
    "#       [  0   0   0   0   0   0 170   0 121   0 233 254   0   0   0 115   0 185 198   0   0   0   0   0 129   0   0   0]\n",
    "#       [  0   0 225   0   0   0   0   0   0   0   0   0   0 205   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [159   0   0  19   0   0   0   0   0  18   0   0   0   0  58   0  21 254   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 229   0   0   0   0 121   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0  60   0   0 238  67   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 151   0   0   0  59   0 254   0   0   0   0   0   0   0   0 207   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 209   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  67   0   0   0   0   0 254   0   0   0   0   0   0   0   0  52]\n",
    "#       [  0  57 163  77   0   0   0   0   0   0  84   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0 248]\n",
    "#       [  0   0   0   0   0   0   0   0 254   0   0   0 236   0   0   0 249   0   0   0   0   0   0   0  59   0   0   0]\n",
    "#       [  0   0   0   1   0   0   0   0 221   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 133   0   0   0   0   0   0 240   0   0   0 219   0   0   0   0]\n",
    "#       [  0 251   0   0   0   0   0  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  17]\n",
    "#       [  0   0   0  31   0   0   0 254   0 254   0   0   0   0   0   0   0 219   0  66   0   0   0   0   0   0   0   0]\n",
    "#       [166   0   0   0   0 254   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  62   0   0   3   0   0]\n",
    "#       [  0   0   0   0   0  18   0   0   0   0   0   0 254   0   0   0   0 254   0   0  83   0   0   0   0  40   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 250  75   0   0 198   0   0   0   0   0   0   0 203   0   0   0  67 114   0   0]\n",
    "#       [  0   0   0 140   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 106   0 227   0  52   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0 222]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0 182]\n",
    "#       [126   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0 242   0   0  44   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 254 198 254   0   0   0 114   0   0   0   0 133   0   0 198   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254 253   5   0   0   0 187   0   0   0   0  67   0   0   0  72 198   0  83   0   0   0   0]\n",
    "#       [  0   0 254 198   0 254 254   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0  35   0   0  22   0]\n",
    "#       [  0   0   0 255   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198   0 224]]\n",
    "#     \n",
    "#      [[  0   0 247   0   0 253  12 118  31   0 248   0   0   0   0   0 176 166   0   0   0   0   0  25   0   0   0   0]\n",
    "#       [  0   0 209   0  93   0   0   0   0   0   0   0   0   0   0 123   0   0   0   0 200   0  35  10   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 141   0 253 253   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0 253]\n",
    "#       [  0   0   0   0   0   0   0   0   0 117   0   0 206 122 253  10   0 150   0   0   0   0 253 253   0   0 253 253]\n",
    "#       [ 43   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0  32   0   0 253   0   0   0   0 253 155   0   0   0   0   0   0   0   0 198 140   0   0   0   0   0]\n",
    "#       [  0   0   0  12   0   0   0 141   0 255   0   0   0  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [249   0   0   0   0 123 166   0   0   0   0   0   0 253   0   0   0   0 210 248   0   0   0  20   0   0   0   0]\n",
    "#       [  0   0 123  18   0   0   0   0   0   0   0   0  20 253   0   0   0   0   0   0 198   0 253   0   0   0   0   0]\n",
    "#       [  0 255   0   0 253   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0  63   0   0 253   0]\n",
    "#       [  0   0   0   0 116   6   0   0   0   0  20   0   0   0 248   0   0  12 142   0   0   0   0   0 253   0 253   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0   0 150   0   0   0   0 253 234   0   0 253   0   0   0   0  78   0   0   0]\n",
    "#       [  0   0   0 253   0   0   0   0   0   0   0 169   0   0 218   0   0   0   0   0 253   0   0 253   0   0   5   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 213   0   0   0   0   0   0 253   0   0 253   0   0 231   0   0   0 253]\n",
    "#       [  0   0 253   0   0   0   0   0   0 134   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [174   0   0   0   0   0   0   0  19   0 123   0   0   0   0   0   0   0   0 171 168   0   0   0   0   0   0 128]\n",
    "#       [  0   0  20  41 253   0 253 144   0   0  76   0   0   0   0 253   0   0   0 176   0 159   0 253   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248   0  20   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [246   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0 253   0 253   0   0 253   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 253 253   0   0   0   0   0   0   0   0 123   0   0   0 117   0   0   0   0   0 125   5]\n",
    "#       [  0   0   0   0   0   0 253   0   0   0   0   0   0   0 250   0 253   0   0  52   0 122 123   0   0   0   0   0]\n",
    "#       [  0 147   0 253   0   0 169   0   0   0   0   0 253   0 253   0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 150   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0 253   0   0   0   0  77   0 253   0   0   0   0]\n",
    "#       [248  37   0   0   0   0   0  65   0   0   0   0 173 233   0   0 253   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [150   0 169 247   0   0   0   0   0  12   0   0   0   0   0   0  25   0   0   0   0  65   0   0   0   0 189   0]\n",
    "#       [  0 253   0 251   0   0   0   0   0   0   0   0 253 253   0   0   0   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [117   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253  20 210 253   0  57   0   0   0   0   0]]]\n",
    "#     Number of rows: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b208e4-2d65-4efa-9ed1-f4f51be6bf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Creating a bar chart; Are these the same values ?\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image pre-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v_s\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image post-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e165c-4d92-48cb-8ee2-85782fc4119d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa52d68-ea0e-4304-852b-97e2f0e0495a",
   "metadata": {},
   "source": [
    "#  Step CN: End of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68398d-130c-4359-8e90-1c28f076a60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eae7a2-b06a-435c-9930-13fed78717b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc972a-abf1-433d-8ecb-d58699a6fbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6316f92-89a4-440c-9861-090b6f6e8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  The results below were on images that were not scrambled.\n",
    "#\n",
    "#     +-----------------------------+-------------------+\n",
    "#     | Category                    | Accuracy          |\n",
    "#     |-----------------------------+-------------------|\n",
    "#     | MNist: Centroid             | 82.03             |\n",
    "#     | MNist: kNN=3                | 97.05             |\n",
    "#     | MNist: kNN=7                | 96.94             |\n",
    "#     | MNist: GaussianNB           | 55.58             |\n",
    "#     | MNist: MultinomialNB        | 83.65             |\n",
    "#     | MNist: DecisionTree         | 87.72             |\n",
    "#     | MNist: Random Forest = 5    | 92.36999999999999 |\n",
    "#     | MNist: Random Forest = 50   | 96.67999999999999 |\n",
    "#     | MNist: Random Forest = 500  | 97.15             |\n",
    "#     | MNist: Random Forest = 5000 | 97.17             |\n",
    "#     |                             |                   |\n",
    "#     +-----------------------------+-------------------+\n",
    "\n",
    "#  Rerun now o nthe scrambled images\n",
    "#\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Centroid, Scramble\") \n",
    "print()\n",
    "\n",
    "#  do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: kNN=3, Scramble\" ) \n",
    "#  do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: kNN=7, Scramble\") \n",
    "#  print()\n",
    "\n",
    "#  do_model(GaussianNB(), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: GaussianNB, Scramble\") \n",
    "#  print()\n",
    "\n",
    "#  do_model(MultinomialNB(), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB, Scramble\") \n",
    "#  print()\n",
    "\n",
    "#  do_model(DecisionTreeClassifier(), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: DecisionTree, Scramble\") \n",
    "#  print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000, Scramble\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf646e34-43c1-48a0-b369-7aa59aed6fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad074-e31f-44ff-844a-2c77217929f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f9af4-927b-42cd-aa56-d7ba85422a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2506248-ba2a-4b82-82fc-afbb6b909e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee49c01-e2a6-43c5-82c7-e3c76815d2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a84dc94-53e2-42f8-b92f-7593a268b81a",
   "metadata": {},
   "source": [
    "#  Step CN: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c16a43-f6f7-4e67-b7c1-2ba2cdbe9590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a96567-70df-4093-b310-f88ca3a644de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7758e3d2-8156-4b6f-bb84-baf0de7cb434",
   "metadata": {},
   "source": [
    "#  Step CN: End of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b89fa9-100e-4b6f-b728-e281d8b4d725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976e37-8702-4f53-bf97-e28a958675f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499d30f-d8c8-46d2-9cef-22fd45a841b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397bde-64f0-4ec9-a728-d37e4c51ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
