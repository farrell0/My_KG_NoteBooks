{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54fd830-1317-4a52-b610-ef9716e5d744",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Setup: Display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38ebd7-d1d9-47a8-955c-a8270b024543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7ce90-67cf-462c-94a6-3c8c9d0754b3",
   "metadata": {},
   "source": [
    "# Setup: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b75ba-c072-4111-8cca-4b4f394a0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a77f99-f11b-4105-ab43-17ce605b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2292b8-7df0-49a0-b3da-523f56cfe4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f69a0e-451b-4679-b49c-5db1208d4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3bc00-fafb-481d-ba5a-8b52ae7d6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba088b-2ec5-4b2a-8171-3c87ddffb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE GRAPH\n",
    "#\n",
    "my_graph = my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3685a36-d987-4ad8-a209-7115d726ac03",
   "metadata": {},
   "source": [
    "# Step 01: Support Methods to Create CSV files .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fd04c-9880-498e-978b-6a45da00f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  The overall goal of this NoteBook is to show incremental import. That is, importing\n",
    "#  into the graph many smaller pieces versus perhaps running one single import operation.\n",
    "#\n",
    "#  As such, we'll create (n) DataFrames with Nodes, (m) with Edges, and import those.\n",
    "#\n",
    "#     (n) and (m) are determined by how we invoke the method below.\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def f_create_dataframe(i_node_or_edge, i_keyranges, i_label_or_type):\n",
    "\n",
    "   l_data_array = []\n",
    "\n",
    "   if (i_node_or_edge == \"node\"):\n",
    "      #\n",
    "      #  This is for nodes; we loop from i_keyranges[0] to i_keyranges[1]\n",
    "      #\n",
    "      for l_key in range(i_keyranges[0], i_keyranges[1] + 1):\n",
    "         l_key_str = str(i_label_or_type + \"_id\").lower()\n",
    "            #\n",
    "         l_data_dict = { l_key_str: l_key, \"col2\": \"222\", \"col3\": \"333\", \"col4\": 444, \"LABEL\": i_label_or_type}\n",
    "            #\n",
    "         l_data_array.append(l_data_dict)\n",
    "            #\n",
    "      l_dataframe =  pd.DataFrame(l_data_array, columns = [l_key_str, \"col2\", \"col3\", \"col4\", \"LABEL\"])\n",
    "   else:\n",
    "      #\n",
    "      #  This is for edges; here we expect five integers in i_keyranges[]\n",
    "      #\n",
    "      #     .  We (outer) loop from i_keyranges[0] to i_keyranges[1]\n",
    "      #        This is for the left edge, and form the key range for a given\n",
    "      #        set of nodes.\n",
    "      #     .  For each record above, we loop (n) times, where n is equal\n",
    "      #        to i_keyanges[2]. Call this the (inner) loop.\n",
    "      #     .  The values produced in the inner loop are sequential from\n",
    "      #        i_keyranges[3] to i_keyranges[4]\n",
    "      #\n",
    "      #     .  See examples in next cell\n",
    "      #\n",
    "      l_right_key = i_keyranges[3] - 1\n",
    "         #\n",
    "      for l_left_key in range(i_keyranges[0], i_keyranges[1] + 1):\n",
    "         for l_each in range(1, i_keyranges[2] + 1):\n",
    "            l_right_key +=1\n",
    "               #\n",
    "            if (l_right_key > i_keyranges[4]):\n",
    "               l_right_key = i_keyranges[3]\n",
    "                  #\n",
    "            l_data_dict1 = { \"start_id\": l_left_key,  \"end_id\": l_right_key, \"weight\": 444, \"uniq_col\": str(l_each), \"TYPE\": i_label_or_type}\n",
    "            l_data_dict2 = { \"end_id\": l_left_key,  \"start_id\": l_right_key, \"weight\": 444, \"uniq_col\": str(l_each), \"TYPE\": i_label_or_type}\n",
    "               #\n",
    "            l_data_array.append(l_data_dict1)\n",
    "            l_data_array.append(l_data_dict2)\n",
    "            #\n",
    "         l_dataframe =  pd.DataFrame(l_data_array, columns = [\"start_id\", \"end_id\", \"weight\", \"uniq_col\", \"TYPE\"])\n",
    "\n",
    "\n",
    "   return l_dataframe\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37711f-eb7d-4336-8d4b-8938a6d2ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Example demonstrating the above-\n",
    "#\n",
    "\n",
    "#  Create Person nodes in the range 100-103\n",
    "#\n",
    "df_nodes1 = f_create_dataframe(\"node\", [100, 103], \"Person\")\n",
    "   #                         \n",
    "print(tabulate(df_nodes1, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "#  Create Flight nodes in the range 400-410\n",
    "#\n",
    "df_nodes2 = f_create_dataframe(\"node\", [400, 410], \"Flight\")\n",
    "   #\n",
    "print(tabulate(df_nodes2, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "#  From this method invocation,\n",
    "#\n",
    "#     df_edges  = f_create_dataframe(\"edge\", [100, 103, 2, 400, 410], \"TAKES_FLIGHT\")\n",
    "#\n",
    "#  Create 2 TAKES_FLIGHT edges, for each left edge node in the\n",
    "#  range 100-103. Whatever this loop creates, assign right-edge\n",
    "#  key value sequentially from 400 to 410.\n",
    "#\n",
    "#  If we need more right-edge records, start over at 400.\n",
    "#\n",
    "#  If there are not enough left-edge records produced, not\n",
    "#  all right-edge nodes may recieve an edge.\n",
    "#\n",
    "#     If so, you may call this method again, say with these\n",
    "#     arguments,\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 404, 406, \"TAKES_FLIGHT\")\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 407, 408, \"TAKES_FLIGHT\")\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 409, 410, \"TAKES_FLIGHT\")\n",
    "#\n",
    "#     or whatever\n",
    "#\n",
    "\n",
    "df_edges  = f_create_dataframe(\"edge\", [100, 103, 2, 400, 410], \"TAKES_FLIGHT\")\n",
    "   #\n",
    "print(tabulate(df_edges, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "del  df_nodes1\n",
    "del  df_nodes2\n",
    "del  df_edges\n",
    "\n",
    "                               \n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     |    |   person_id |   col2 |   col3 |   col4 | LABEL   |\n",
    "#     |----+-------------+--------+--------+--------+---------|\n",
    "#     |  0 |         100 |    222 |    333 |    444 | Person  |\n",
    "#     |  1 |         101 |    222 |    333 |    444 | Person  |\n",
    "#     |  2 |         102 |    222 |    333 |    444 | Person  |\n",
    "#     |  3 |         103 |    222 |    333 |    444 | Person  |\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     |    |   flight_id |   col2 |   col3 |   col4 | LABEL   |\n",
    "#     |----+-------------+--------+--------+--------+---------|\n",
    "#     |  0 |         400 |    222 |    333 |    444 | Flight  |\n",
    "#     |  1 |         401 |    222 |    333 |    444 | Flight  |\n",
    "#     |  2 |         402 |    222 |    333 |    444 | Flight  |\n",
    "#     |  3 |         403 |    222 |    333 |    444 | Flight  |\n",
    "#     |  4 |         404 |    222 |    333 |    444 | Flight  |\n",
    "#     |  5 |         405 |    222 |    333 |    444 | Flight  |\n",
    "#     |  6 |         406 |    222 |    333 |    444 | Flight  |\n",
    "#     |  7 |         407 |    222 |    333 |    444 | Flight  |\n",
    "#     |  8 |         408 |    222 |    333 |    444 | Flight  |\n",
    "#     |  9 |         409 |    222 |    333 |    444 | Flight  |\n",
    "#     | 10 |         410 |    222 |    333 |    444 | Flight  |\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     +----+------------+----------+----------+------------+--------------+\n",
    "#     |    |   start_id |   end_id |   weight |   uniq_col | TYPE         |\n",
    "#     |----+------------+----------+----------+------------+--------------|\n",
    "#     |  0 |        100 |      400 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  1 |        400 |      100 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  2 |        100 |      401 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  3 |        401 |      100 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  4 |        101 |      402 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  5 |        402 |      101 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  6 |        101 |      403 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  7 |        403 |      101 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  8 |        102 |      404 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  9 |        404 |      102 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 10 |        102 |      405 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 11 |        405 |      102 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 12 |        103 |      406 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 13 |        406 |      103 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 14 |        103 |      407 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 15 |        407 |      103 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     +----+------------+----------+----------+------------+--------------+\n",
    "\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e1596-03e6-450f-bcf0-144658f00701",
   "metadata": {},
   "source": [
    "#  Read CSVs into Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed37a38-5140-45c0-915b-e88a0516f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c98ee1-3c20-4e3a-b075-3bbdb39ace7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  Just nodes\n",
    "\n",
    "#  Sample data,\n",
    "#\n",
    "#     Sent|counterparty|cntAppr|cntDecl|cntRiskDecl1|amtRiskDecl|cntRiskDecl2|sumRcvd|cntRcvd|cntDist|cntDecl2\n",
    "#     0|N|N|N|N|XbRqfTcGJL9fxmNp4simTykwKr|qhBymw13PneK5hpntNVwjNwaYklX8P379JZo|Y|416|0|inactive|1941730454454|0|2018-01-24T01:09:18|9.07632e+09|1419493889|1894897856|2676929303.1430|6614868331.8687|8283173087.0037|6020979256.1980|1984359695|5077917542.6596|1923699935|1948138778|4876422147.1566|\n",
    "\n",
    "df_nodes = dd.read_csv(\n",
    "   l_nodes,\n",
    "   delimiter = \"|\",\n",
    "   dtype = {\n",
    "      \"Sent\"          : np.dtype(\"O\"),                         #  Change these if you wish,  Numpy datatypes\n",
    "      \"counterparty\"  : np.dtype(\"O\"),\n",
    "      \"cntAppr\"       : np.dtype(\"O\"),\n",
    "      \"cntDecl\"       : np.dtype(\"O\"),\n",
    "      \"cntRiskDecl1\"  : np.dtype(\"O\"),\n",
    "      \"amtRiskDecl\"   : np.dtype(\"O\"),\n",
    "      \"cntRiskDecl2\"  : np.dtype(\"O\"),\n",
    "      \"sumRcvd\"       : np.dtype(\"O\"),\n",
    "      \"cntRcvd\"       : np.dtype(\"O\"),\n",
    "      \"cntDist\"       : np.dtype(\"O\"),\n",
    "      \"cntDecl2\"      : np.dtype(\"O\"),\n",
    "      })\n",
    "\n",
    "print(len(df_nodes))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     20000000\n",
    "#     --\n",
    "#     CPU times: user 3min, sys: 18 s, total: 3min 18s\n",
    "#     Wall time: 2min 48s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a2d41-2763-449b-928d-aa0d745539f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  Just edges\n",
    "\n",
    "#  Sample data,\n",
    "#\n",
    "#     Account1.id|Account2.id|type|date\n",
    "#     16089173|16089175|FriendConB|2018-10-10T11:20:05\n",
    "\n",
    "df_edges = dd.read_csv(\n",
    "    \n",
    "   #  l_edges,                                                   #  This would be all files, at once, in memory\n",
    "   l_edges_small,\n",
    "    \n",
    "   delimiter = \"|\",\n",
    "   dtype = {\n",
    "      \"Account1.id\"   : np.dtype(\"O\"),\n",
    "      \"Account2.id\"   : np.dtype(\"O\"),\n",
    "      \"type\"          : np.dtype(\"O\"),                           #  These next two column names are keywords in most worlds -- bad idea\n",
    "      \"date\"          : np.dtype(\"O\"),\n",
    "      })\n",
    "\n",
    "print(len(df_edges))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     200000000\n",
    "#     --\n",
    "#     CPU times: user 4min 25s, sys: 31.2 s, total: 4min 56s\n",
    "#     Wall time: 4min 23s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337d260-8583-41fc-9300-e9994520cda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d607abb-6e9b-4dfd-9b10-302c237556d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
