{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data swets ..\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {},
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "\n",
    "#  The sklearn ML routines follow a very consistent pattern. As such, we\n",
    "#  put these in a function, reduce redundant code below-\n",
    "#\n",
    "\n",
    "def do_model(i_routine, i_train_data, i_train_labels, i_test_data, i_test_labels, i_name_of_test):\n",
    "\n",
    "   #  Train whatever model\n",
    "   #\n",
    "   i_routine.fit(i_train_data, i_train_labels)\n",
    "   \n",
    "   #  Predict on the test data\n",
    "   #\n",
    "   l_predicted_labels = i_routine.predict(i_test_data)\n",
    "   l_accuracy         = (i_routine.score(i_test_data, i_test_labels) * 100)\n",
    "      #\n",
    "   l_history.add(event = i_name_of_test, measure = l_accuracy)\n",
    "   \n",
    "   #  Output results\n",
    "   #\n",
    "   print(i_name_of_test + \" ...\")\n",
    "   print(\"   Actual    labels from test......... %s\" % (i_test_labels     ) )\n",
    "   print(\"   Predicted labels from test......... %s\" % (l_predicted_labels) )\n",
    "   print(   \"   ###\")\n",
    "   print(\"   Accuracy: %0.4f %%\" % (l_accuracy))\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe2eac-169f-4068-b5a4-d70e1e2856a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {},
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Boxplot, and normalize ..\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "   #\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(type(np_iris[\"train\"]))\n",
    "\n",
    "plt.boxplot(np_iris[\"train\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "l_normarr = MinMaxScaler(feature_range=(0, 1)).fit(np_iris[\"train\"])\n",
    "\n",
    "#  plt.boxplot(l_normarr)\n",
    "#  plt.show()\n",
    "\n",
    "print(type(l_normarr))\n",
    "print(l_normarr)\n",
    "#  print(tabulate(l_normarr, headers=[\"col1\", \"col2\", \"col3\", \"col4\", \"col5\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69037948-f083-42c7-be69-21ab5e5f5838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.187 0.7   0.053 0.042 0.   ]\n",
      " [0.406 0.35  0.509 0.375 0.5  ]\n",
      " [0.625 0.5   0.754 0.708 1.   ]\n",
      " [1.    0.3   1.    0.917 1.   ]\n",
      " [0.312 0.3   0.561 0.458 0.5  ]\n",
      " [0.562 0.7   0.772 0.958 1.   ]\n",
      " [0.344 0.25  0.474 0.417 0.5  ]\n",
      " [0.375 0.5   0.526 0.458 0.5  ]\n",
      " [0.469 0.7   0.579 0.625 0.5  ]\n",
      " [0.063 0.6   0.07  0.042 0.   ]\n",
      " [0.5   0.5   0.596 0.542 0.5  ]\n",
      " [0.094 0.5   0.035 0.    0.   ]\n",
      " [0.    0.15  0.018 0.083 0.   ]\n",
      " [0.5   0.5   0.649 0.708 1.   ]\n",
      " [0.312 0.2   0.456 0.417 0.5  ]\n",
      " [0.688 0.65  0.789 1.    1.   ]\n",
      " [0.688 0.65  0.789 0.833 1.   ]\n",
      " [0.844 0.6   0.842 0.708 1.   ]\n",
      " [0.688 0.5   0.667 0.667 0.5  ]\n",
      " [0.156 0.    0.404 0.375 0.5  ]\n",
      " [0.594 0.4   0.772 0.875 1.   ]\n",
      " [0.125 0.25  0.579 0.667 1.   ]\n",
      " [0.625 0.4   0.596 0.583 0.5  ]\n",
      " [0.375 0.9   0.088 0.083 0.   ]\n",
      " [0.688 0.55  0.561 0.542 0.5  ]\n",
      " [0.187 0.9   0.053 0.083 0.   ]\n",
      " [0.406 1.    0.    0.042 0.   ]\n",
      " [1.    0.9   0.965 0.875 1.   ]\n",
      " [0.281 0.85  0.053 0.042 0.   ]\n",
      " [0.406 0.35  0.474 0.458 0.5  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def scale(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom \n",
    "\n",
    "X = np.array([\n",
    "    [ 0,  1],\n",
    "    [ 2,  3],\n",
    "    [ 4,  5],\n",
    "    [ 6,  7],\n",
    "    [ 8,  9],\n",
    "    [10, 11],\n",
    "    [12, 13],\n",
    "    [14, 15]\n",
    "])\n",
    "\n",
    "#  X_scaled = scale(X, -1, 1)\n",
    "#  print(X_scaled)\n",
    "\n",
    "np_iris_scaled = scale(np_iris[\"test\"], 0, 1)\n",
    "print(np_iris_scaled)\n",
    "\n",
    "plt.boxplot(np_iris_scaled)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18068e00-f3e5-42ab-b15e-4659342de19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becb924-c2e4-4f88-a69c-93108652e622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec018d-278d-410f-8fdf-e0ff18d5f2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5642d7fa-e89f-47c8-90c4-13e33fc2106c",
   "metadata": {},
   "source": [
    "#  Step A2: Iris Data train, test .. NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15b429-f361-434a-a3c4-f91f48d61824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: Centroid\") \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25a3d4-cf32-4503-8c86-e14146b7fa9d",
   "metadata": {},
   "source": [
    "#  Step A3: Iris Data train, test .. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1202c-c630-4e27-aea8-4ed425b139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: kNN=3\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5328044-4f54-41b6-a37a-0f96a11e2250",
   "metadata": {},
   "source": [
    "#  Step A4: Iris Data train, test .. Naive Bayes, Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1740a-f656-4d6d-bdf3-cb2f053fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#  Naive Bayes, Gaussian\n",
    "#\n",
    "#     Gaussian usually does better than the Multinomial below because,\n",
    "#        Gaussian expects continuous values\n",
    "#        Multinomial expects discreet values\n",
    "#\n",
    "#     And our values are continuous\n",
    "#\n",
    "\n",
    "do_model(GaussianNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: GaussianNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f815d9-6eb7-4aaa-863c-3c7ce613d127",
   "metadata": {},
   "source": [
    "#  Step A5: Iris Data train, test .. Naive Bayes, Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e0e-31d0-44c1-bdb3-0ee3c5ca3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Naive Bayes, Multinomial\n",
    "#\n",
    "\n",
    "do_model(MultinomialNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: MultinomialNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662897e8-2b96-4d7a-bf24-74aa2da5c006",
   "metadata": {},
   "source": [
    "#  Step A6: Iris Data train, test .. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb7874-3d2c-4f27-83db-147b953228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Decision Tree\n",
    "#\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: DecisionTree\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5d6be-ecfa-4ca1-b518-0b37274c04de",
   "metadata": {},
   "source": [
    "#  Step A7: Iris Data train, test .. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a74fa-57c5-44ef-ade3-dd5438751064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  Random Forest\n",
    "#\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RandomForest\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7973bf-5a1a-4999-810d-91e52c13bd0b",
   "metadata": {},
   "source": [
    "#  Step A8: Iris Data train, test .. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0262-190c-455d-b2f9-99056c1bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: SVC/Linear\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF 2\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45c758-b0db-43dd-9aa7-832598413085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cf6a-434a-4fcf-bfdb-edc3308c5252",
   "metadata": {},
   "source": [
    "#  Step B1:  Breast Cancer Data load, encode, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe262a-4fb5-4954-9d6f-c8cbea09d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Breast Cancer data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1)     ID number\n",
    "#     2)     Diagnosis (M = malignant, B = benign)\n",
    "#     3-32)\n",
    "#       Ten real-valued features are computed for each cell nucleus:\n",
    "#     \n",
    "#     \ta) radius (mean of distances from center to points on the perimeter)\n",
    "#     \tb) texture (standard deviation of gray-scale values)\n",
    "#     \tc) perimeter\n",
    "#     \td) area\n",
    "#     \te) smoothness (local variation in radius lengths)\n",
    "#     \tf) compactness (perimeter^2 / area - 1.0)\n",
    "#     \tg) concavity (severity of concave portions of the contour)\n",
    "#     \th) concave points (number of concave portions of the contour)\n",
    "#     \ti) symmetry \n",
    "#     \tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "#\n",
    "#  Sample data line,\n",
    "#     842302,M,\n",
    "#     17.99,    10.38,    122.8,    1001,    0.1184,    0.2776,    0.3001,    0.1471,    0.2419,    0.07871,         #  10 count\n",
    "#     1.095,    0.9053,   8.589,    153.4,   0.006399,  0.04904,   0.05373,   0.01587,   0.03003,   0.006193,\n",
    "#     25.38,    17.33,    184.6,    2019,    0.1622,    0.6656,    0.7119,    0.2654,    0.4601     ,0.1189\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"22_wdbc.data.txt\"\n",
    "\n",
    "\n",
    "pd_bc  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"id\", \"class\",\n",
    "            \"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \n",
    "            \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\", \"f20\", \n",
    "            \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "           ],\n",
    "   dtype = {\"id\": \"int\", \"class\": \"string\",\n",
    "            \"f01\": \"float\", \"f02\": \"float\", \"f03\": \"float\", \"f04\": \"float\", \"f05\": \"float\", \"f06\": \"float\", \"f07\": \"float\", \"f08\": \"float\", \"f09\": \"float\", \"f10\": \"float\", \n",
    "            \"f11\": \"float\", \"f12\": \"float\", \"f13\": \"float\", \"f14\": \"float\", \"f15\": \"float\", \"f16\": \"float\", \"f17\": \"float\", \"f18\": \"float\", \"f19\": \"float\", \"f20\": \"float\", \n",
    "            \"f21\": \"float\", \"f22\": \"float\", \"f23\": \"float\", \"f24\": \"float\", \"f25\": \"float\", \"f26\": \"float\", \"f27\": \"float\", \"f28\": \"float\", \"f29\": \"float\", \"f30\": \"float\", \n",
    "           } )\n",
    "      #\n",
    "pd_bc[\"class_encoded\"]  =  my_le.fit_transform(pd_bc[\"class\"])\n",
    "   #\n",
    "pd_bc = pd_bc.drop([\"class\", \"id\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized count of rows\n",
    "#\n",
    "print(tabulate(pd_bc.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_bc)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05409-32ac-4da0-bd05-6d97b35df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_bc = {}\n",
    "   #\n",
    "np_bc[\"train\"], np_bc[\"test\"] = train_test_split(pd_bc.to_numpy(),                    #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_bc), len(np_bc[\"train\"]), len(np_bc[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_bc[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_bc[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a63d6f-96d6-42c3-9782-8be69c555bef",
   "metadata": {},
   "source": [
    "#  Step B2:  Breast Cancer Data, run against all models .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36b4ec-23da-4af1-8cb4-fe5669cc5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "#  Our numpy array has many columns, with the last column being the class.\n",
    "#\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 30 columns use,\n",
    "#        np_iris[\"train\"][:, :30]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: Centroid\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: kNN=3\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: GaussianNB\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: MultinomialNB\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: DecisionTree\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: Random Forest = 5\") \n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: SVC/Linear\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train\"][:, :4], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :4], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF 2\") \n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a359-02b1-4bb0-aced-216eb7cad1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66fc5d-8f1b-4243-8f06-69a91d8ae685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916a655-4bb6-4e41-be06-e11b244da0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37e56f-cca5-4af4-9bb5-89be55420d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff57e71-9dc7-4e7c-9e6c-eb447e07867a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
