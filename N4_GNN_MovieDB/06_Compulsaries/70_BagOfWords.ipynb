{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d776f754-ef98-4cbd-a423-647c483341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Here we demonstrate the following Dask DataFrame techniques;\n",
    "#\n",
    "#     .  How to create a Dask DataFrame from an array.\n",
    "#\n",
    "#     .  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682150e3-6a50-4197-a239-80d1d2ea6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0416c10d-a1cb-433d-ad5e-85498aaa1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "   #\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "   #\n",
    "from dask.dataframe import from_pandas\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c6a99e-7b23-4cf6-9880-d70fffb4b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131298d0-5cb4-4b62-8413-5e5571ef4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Create our source Dask DataFrame from an array\n",
    "\n",
    "np_airports = np.array([\n",
    "       #\n",
    "   [\"MKE\", \"Milwaukee\"     , \"WI\", \"Airport\"],\n",
    "   [\"ORD\", \"Chicago O-Hare\", \"IL\", \"Airport\"],\n",
    "   [\"SJC\", \"San Jose\"      , \"CA\", \"Airport\"],\n",
    "   [\"LAX\", \"Los Angeles\"   , \"CA\", \"Airport\"],\n",
    "   [\"DEN\", \"Denver\"        , \"CO\", \"Airport\"],\n",
    "       #\n",
    "   ], dtype=\"str\")\n",
    "\n",
    "pd_airports = pd.DataFrame(np_airports, columns = [\"airport_code\", \"airport_name\", \"state_code\", \"LABEL\"])\n",
    "   #\n",
    "dd_airports = from_pandas(pd_airports, npartitions = NUM_PARTITIONS)\n",
    "\n",
    "\n",
    "for l_each in dd_airports.itertuples():\n",
    "   print(\"Airport:  %3s   %-18s   %-2s   %-10s\" % (l_each.airport_code, l_each.airport_name, l_each.state_code, l_each.LABEL))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  Airport:  MKE   Milwaukee            WI   Airport   \n",
    "#  Airport:  ORD   Chicago O-Hare       IL   Airport   \n",
    "#  Airport:  SJC   San Jose             CA   Airport   \n",
    "#  Airport:  LAX   Los Angeles          CA   Airport   \n",
    "#  Airport:  DEN   Denver               CO   Airport  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f23d1-6559-4c0b-89c6-86c19eda8028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aba548-02b0-4290-af3f-8d39fcad0e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216ee1f-b485-4ad0-86e9-df7a65cfb12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b9e1e-86ad-4c87-94c1-7804ec7e6454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828d62e9-1cf8-4eee-9147-f351961b95f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dd_airports' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 33\u001b[0m\n\u001b[1;32m     21\u001b[0m my_input_arr \u001b[38;5;241m=\u001b[39m [ \n\u001b[1;32m     22\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseball\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfootball\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcricket\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m ]\n\u001b[1;32m     32\u001b[0m my_cv_counts \u001b[38;5;241m=\u001b[39m my_cv\u001b[38;5;241m.\u001b[39mfit_transform(my_input_arr)\n\u001b[0;32m---> 33\u001b[0m my_cv_counts \u001b[38;5;241m=\u001b[39m my_cv\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdd_airports\u001b[49m\u001b[38;5;241m.\u001b[39mairport_code)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(my_cv_counts))                  \u001b[38;5;66;03m#  <class 'scipy.sparse._csr.csr_matrix'>\u001b[39;00m\n\u001b[1;32m     38\u001b[0m                                            \u001b[38;5;66;03m#  For my_input_arr above\u001b[39;00m\n\u001b[1;32m     39\u001b[0m                                            \u001b[38;5;66;03m#  -----------------------------------\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dd_airports' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Working with  sklearn.feature_extraction.text.CountVectorizer\n",
    "#\n",
    "#     See,\n",
    "#        https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#tokenizing-text-with-scikit-learn\n",
    "\n",
    "\n",
    "#  .  The results array is sorted by input key value.\n",
    "#        ..  So below, baseball occupies the output's zero'th position,\n",
    "#            where cricket will occupy the 1'st.\n",
    "#  .  Words will be automatically split on whitespace, hyphens, other.\n",
    "#        ..  So I plan to do my own splitting beforehand, lest I not know what the output array represents.\n",
    "#  .  Duplicates do receive multiple entries in the output. Not certain of the effect of that.\n",
    "#\n",
    "#  .  2d integer64 array is output;\n",
    "#        ..  1st col is a counter, index into array\n",
    "#        ..  2nd col is for each word in the array, and the reference to 1st col, this word's position in the input\n",
    "#\n",
    "\n",
    "my_cv = CountVectorizer()\n",
    "\n",
    "my_input_arr = [ \n",
    "   \"baseball\",\n",
    "   \"football\",\n",
    "   \"cricket\",\n",
    "   \"golf\",\n",
    "   \"racing\",\n",
    "   \"fencing\",\n",
    "   \"cricket\",\n",
    "]\n",
    "\n",
    "\n",
    "my_cv_counts = my_cv.fit_transform(my_input_arr)\n",
    "my_cv_counts = my_cv.fit_transform(dd_airports.airport_code)\n",
    "\n",
    "\n",
    "print(type(my_cv_counts))                  #  <class 'scipy.sparse._csr.csr_matrix'>\n",
    "\n",
    "                                           #  For my_input_arr above\n",
    "                                           #  -----------------------------------\n",
    "print(my_cv_counts.shape)                  #  (7, 6)\n",
    "print(my_cv_counts      )                  #  (0, 0)\t1\n",
    "                                           #  (1, 3)\t1\n",
    "                                           #  (2, 1)\t1\n",
    "                                           #  (3, 4)\t1\n",
    "                                           #  (4, 5)\t1\n",
    "                                           #  (5, 2)\t1\n",
    "                                           #  (6, 1)\t1\n",
    " \n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# df_words = pd.DataFrame(my_cv_counts.toarray())\n",
    "#    #\n",
    "# for l_each in df_words.iterrows():\n",
    "#    print(l_each)\n",
    "# \n",
    "# \n",
    "# print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea72023-5366-444e-8cdf-cdb280b75e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e4b85-372f-491c-84b1-fc7714788163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f49097-92db-4c90-b76c-199b5a7ca20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
