{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b1755b-2af6-4570-84de-764a0024a919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Display options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb5ac6-bcb9-49a5-8cf0-60f8441171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  References for this Notebook,\n",
    "#\n",
    "#     Lines 135-139\n",
    "#     https://github.com/KatanaGraph/solutions/blob/main/fsi/src/katana_ai.py\n",
    "#     Lines 31-37\n",
    "#     https://github.com/KatanaGraph/test-datasets/blob/450232fe5739f327ed0795030a4b9d05731586ee/rdg_datasets/two_self_loops_ai/add_features.py\n",
    "#\n",
    "#     https://docs.k9h.dev/latest/recipes/udf-recipes.html?highlight=nodes%20get_property\n",
    "#\n",
    "#     https://github.com/KatanaGraph/katana-enterprise/blob/master/python/test/integration/remote/remote_operations_test.py\n",
    "#\n",
    "#     https://github.com/KatanaGraph/katana-enterprise/tree/master/lonestar/analytics/distributed/experimental\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a11486-11ea-4a6c-8f7b-6f3808dfc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db99d1-7e45-49d6-8e9c-b6a998c56d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  When using UDFs, these execute on another host.\n",
    "#\n",
    "#  As such, these methods will need to be copied and run locally also.\n",
    "#\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebe820-bc6d-4948-b668-8b81cd3cbf29",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Setup stuff: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea957d6-30c6-427a-ae4e-15ecfba0c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "#  from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97571016-7c02-4e90-a75a-136a0dacd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5db6505-7fc8-4779-b194-9ed8945b9a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_Graph my_graph, 2XV5TdCuQpgkTgwvDSbEwxZpqvpYh1chH5z5X3Uw7suh, 36>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  CONNECT TO GRAPH\n",
    "\n",
    "my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ac246-4852-44ac-8a63-8631b38858ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61556ce5-9044-42bc-bb13-80b6a514ae27",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UDFs, Part 01: Mutating Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11c4e0-4b91-4a64-b06f-340f03873246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We will use this counter to generate a unique column name below-\n",
    "#\n",
    "l_cntr = 20\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b2926-ca30-446a-b74f-4542f174d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Add a new column to each node, one that is derived from columns local to each node; approach 1\n",
    "#\n",
    "#     .  This will fail if the named new column already exists in the graph.\n",
    "#     .  Just get this working, then make it more functional.\n",
    "#\n",
    "\n",
    "def my_func(i_graph, i_label, i_properties, i_new_colname):\n",
    "    \n",
    "   from katana.distributed import KeyedColumnNode\n",
    "   import numpy as np\n",
    "    \n",
    "    \n",
    "   l_node_props = i_graph.nodes.get_property(i_properties[0])                     #  An existing column, we will upshift this existing value\n",
    "      #\n",
    "   l_node_keys  = l_node_props.keys()                                             #  keys() works against any column in the node.\n",
    "      #\n",
    "   l_new_cols   = np.zeros(len(l_node_props), dtype=\"object\")                     #  An empty NumPy array, same length as l_node_props\n",
    "\n",
    "\n",
    "   for l_index, l_key in enumerate(l_node_keys):                                  #  Loop over the keys that are already in the graph\n",
    "      l_new_cols[l_index] = str(l_node_props[l_key]).upper()                      #  Derive a new column property value\n",
    "\n",
    "    \n",
    "   l_keyed_cols = KeyedColumnNode(l_new_cols, l_node_props, i_new_colname)        #  Building what we need to send to add_property()\n",
    "   i_graph.nodes.add_property(l_keyed_cols)\n",
    "\n",
    "\n",
    "   return\n",
    "\n",
    "l_cntr   += 1\n",
    "l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "\n",
    "   #\n",
    "l_result = my_graph.run(lambda g: my_func(g, \"Airport\", [\"airport_name\"], l_newcol))\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e413eea-dfcd-4368-acb7-ec69a8d07a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Add a new column to each node, one that is derived from columns local to each node; approach 2\n",
    "#\n",
    "#     .  We moved properties to our comprehension technique. Why ?  When dealing with multiple\n",
    "#        properties, this is handy.\n",
    "#\n",
    "\n",
    "def my_func(i_graph, i_label, i_properties, i_new_colname):\n",
    "    \n",
    "   from katana.distributed import KeyedColumnNode\n",
    "   import numpy as np\n",
    "    \n",
    "    \n",
    "   l_node_props = {each: i_graph.nodes.get_property(each) for each in i_properties}                 #  An existing column, we will upshift this existing value\n",
    "      #\n",
    "   l_node_keys  = l_node_props[i_properties[0]].keys()                                              #  keys() works against any column in the node.\n",
    "      #\n",
    "   l_new_cols   = np.zeros(len(l_node_props[i_properties[0]]), dtype=\"object\")                      #  An empty NumPy array, same length as l_node_props\n",
    "\n",
    "\n",
    "   for l_index, l_key in enumerate(l_node_keys):                                                    #  Loop over the keys that are already in the graph\n",
    "      l_new_cols[l_index] = str(l_node_props[i_properties[0]][l_key]).upper()                       #  Derive a new column property value\n",
    "\n",
    "    \n",
    "   l_keyed_cols = KeyedColumnNode(l_new_cols, l_node_props[i_properties[0]], i_new_colname)         #  Building what we need to send to add_property()\n",
    "      #\n",
    "   i_graph.nodes.add_property(l_keyed_cols)\n",
    "\n",
    "\n",
    "   return\n",
    "\n",
    "l_cntr   += 1\n",
    "l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "\n",
    "   #\n",
    "l_result = my_graph.run(lambda g: my_func(g, \"Airport\", [\"airport_name\"], l_newcol))\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f99942-9543-49a9-9c4d-ed27eccaa367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  View the graph; verify results\n",
    "#\n",
    "#  Based on our return list, not easily certain if new column was added to Restaurant\n",
    "#\n",
    "\n",
    "def f_printtable1(i_colname):\n",
    "    \n",
    "   l_query  = \"\"\"\n",
    "      MATCH (n)\n",
    "      RETURN n.restaurant_name, n.airport_name, n.{0}\n",
    "      \"\"\".format(i_colname)\n",
    "   \n",
    "   l_result = my_graph.query(l_query)\n",
    "   \n",
    "   print(tabulate(l_result, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "f_printtable1(l_newcol)\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +----+-----------------------------+------------------+-----------------+\n",
    "#     |    | n.restaurant_name           | n.airport_name   | n.newcol_0021   |\n",
    "#     |----+-----------------------------+------------------+-----------------|\n",
    "#     |  0 |                             | San Jose         | SAN JOSE        |\n",
    "#     |  1 |                             | Chicago O-Hare   | CHICAGO O-HARE  |\n",
    "#     |  2 |                             | Milwaukee        | MILWAUKEE       |\n",
    "#     |  3 | Pappadeauxs Seafood Kitchen |                  | NONE            |\n",
    "#     |  4 |                             | Denver           | DENVER          |\n",
    "#     +----+-----------------------------+------------------+-----------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfd392-fc73-4c81-96de-f4792cd3b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  View the graph; verify results\n",
    "#\n",
    "#  Confirming new column was added to Restaurant\n",
    "#\n",
    "\n",
    "def f_printtable2(i_colname):\n",
    "    \n",
    "   l_query  = \"\"\"\n",
    "      MATCH (n: Restaurant)\n",
    "      // RETURN n.restaurant_name, n.{0}\n",
    "      RETURN n\n",
    "      \"\"\".format(i_colname)\n",
    "   \n",
    "   l_result = my_graph.query(l_query)\n",
    "   \n",
    "   print(tabulate(l_result, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "f_printtable2(l_newcol)\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +----+-----------------+----------------+--------+-----------------+-----------------------------+----------+\n",
    "#     |    |   n.internal_id | n.labels       | n.id   | n.newcol_0021   | n.restaurant_name           | n.type   |\n",
    "#     |----+-----------------+----------------+--------+-----------------+-----------------------------+----------|\n",
    "#     |  0 | 562949953421313 | ['Restaurant'] | PAP    | NONE            | Pappadeauxs Seafood Kitchen | node     |\n",
    "#     +----+-----------------+----------------+--------+-----------------+-----------------------------+----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1c0c7-7cab-461f-84f6-6b6c4d34bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Add a new column to each node, one that is derived from columns local to each node; approach 3\n",
    "#\n",
    "#     .  Here we see that if the new column value is None, then the property is not actually added\n",
    "#        to the node. \n",
    "#\n",
    "\n",
    "def my_func(i_graph, i_label, i_properties, i_new_colname):\n",
    "    \n",
    "   from katana.distributed import KeyedColumnNode\n",
    "   import numpy as np\n",
    "    \n",
    "    \n",
    "   l_node_props = {each: i_graph.nodes.get_property(each) for each in i_properties}                 #  An existing column, we will upshift this existing value\n",
    "      #\n",
    "   l_node_keys  = l_node_props[i_properties[0]].keys()                                              #  keys() works against any column in the node.\n",
    "      #\n",
    "   l_new_cols   = np.zeros(len(l_node_props[i_properties[0]]), dtype=\"object\")                      #  An empty NumPy array, same length as l_node_props\n",
    "\n",
    "\n",
    "   for l_index, l_key in enumerate(l_node_keys):                                                    #  Loop over the keys that are already in the graph\n",
    "      if (i_label in i_graph.nodes.labels(l_key) ):                                                   \n",
    "         #  Is Airport\n",
    "         if (str(l_node_props[i_properties[0]][l_key]).upper() < \"M\"):                              #  Further testing what we can set to None\n",
    "            l_new_cols[l_index] = str(l_node_props[i_properties[0]][l_key]).upper()\n",
    "         else:\n",
    "            l_new_cols[l_index] = None\n",
    "      else:\n",
    "         #  Not Airport\n",
    "         l_new_cols[l_index] = None\n",
    "    \n",
    "   l_keyed_cols = KeyedColumnNode(l_new_cols, l_node_props[i_properties[0]], i_new_colname)         #  Building what we need to send to add_property()\n",
    "      #\n",
    "   i_graph.nodes.add_property(l_keyed_cols)\n",
    "\n",
    "\n",
    "   return\n",
    "\n",
    "l_cntr   += 1\n",
    "l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "\n",
    "   #\n",
    "l_result = my_graph.run(lambda g: my_func(g, \"Airport\", [\"airport_name\"], l_newcol))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e69aa9-3bb0-40d2-affe-337a24b7d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Checking results above\n",
    "#\n",
    "\n",
    "f_printtable1(l_newcol)\n",
    "f_printtable2(l_newcol)\n",
    "\n",
    "\n",
    "#  Here you should see a new property in the first table, but not in this table.\n",
    "#  Basically; the nodes did not receive the property.\n",
    "#\n",
    "\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n: Airport)\n",
    "   WHERE n.airport_name > \"M\"\n",
    "   RETURN n\n",
    "   \"\"\".format(l_newcol)\n",
    "\n",
    "l_result = my_graph.query(l_query)\n",
    "\n",
    "print(tabulate(l_result, headers='keys', tablefmt='psql'))\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +----+-----------------------------+------------------+-----------------+\n",
    "#     |    | n.restaurant_name           | n.airport_name   | n.newcol_0026   |\n",
    "#     |----+-----------------------------+------------------+-----------------|\n",
    "#     |  0 |                             | San Jose         |                 |\n",
    "#     |  1 |                             | Chicago O-Hare   | CHICAGO O-HARE  |\n",
    "#     |  2 | Pappadeauxs Seafood Kitchen |                  |                 |\n",
    "#     |  3 |                             | Milwaukee        |                 |\n",
    "#     |  4 |                             | Denver           | DENVER          |\n",
    "#     +----+-----------------------------+------------------+-----------------+\n",
    "#     \n",
    "#     +----+-----------------+----------------+--------+-----------------+-----------------+-----------------+-----------------------------+----------+\n",
    "#     |    |   n.internal_id | n.labels       | n.id   | n.newcol_0021   | n.newcol_0022   | n.newcol_0023   | n.restaurant_name           | n.type   |\n",
    "#     |----+-----------------+----------------+--------+-----------------+-----------------+-----------------+-----------------------------+----------|\n",
    "#     |  0 |               2 | ['Restaurant'] | PAP    | NONE            | NONE            | NONE            | Pappadeauxs Seafood Kitchen | node     |\n",
    "#     +----+-----------------+----------------+--------+-----------------+-----------------+-----------------+-----------------------------+----------+\n",
    "#     \n",
    "#     +----+-----------------+-------------+-----------+------------------+--------+-----------------+-----------------+-----------------+-----------------+----------+\n",
    "#     |    |   n.internal_id | n.labels    | n.LABEL   | n.airport_name   | n.id   | n.newcol_0021   | n.newcol_0022   | n.newcol_0023   | n.newcol_0024   | n.type   |\n",
    "#     |----+-----------------+-------------+-----------+------------------+--------+-----------------+-----------------+-----------------+-----------------+----------|\n",
    "#     |  0 |               1 | ['Airport'] | Airport   | San Jose         | SJC    | SAN JOSE        | SAN JOSE        | SAN JOSE        | SAN JOSE        | node     |\n",
    "#     |  1 | 281474976710656 | ['Airport'] | Airport   | Milwaukee        | MKE    | MILWAUKEE       | MILWAUKEE       | MILWAUKEE       | MILWAUKEE       | node     |\n",
    "#     +----+-----------------+-------------+-----------+------------------+--------+-----------------+-----------------+-----------------+-----------------+----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e15eb-e9a6-4afd-a758-215472626c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Add a new column to each node, one that is derived from columns local to each node; approach 4  (copy from Approach 2)\n",
    "#\n",
    "#     .  Move to upsert\n",
    "#        Where add_property() could break on (column already found), upsert_property doesn't suffer that restriction.\n",
    "#\n",
    "\n",
    "def my_func(i_graph, i_label, i_properties, i_new_colname):\n",
    "    \n",
    "   from katana.distributed import KeyedColumnNode\n",
    "   import numpy as np\n",
    "    \n",
    "    \n",
    "   l_node_props = {each: i_graph.nodes.get_property(each) for each in i_properties}                 #  An existing column, we will upshift this existing value\n",
    "      #\n",
    "   l_node_keys  = l_node_props[i_properties[0]].keys()                                              #  keys() works against any column in the node.\n",
    "      #\n",
    "   l_new_cols   = np.zeros(len(l_node_props[i_properties[0]]), dtype=\"object\")                      #  An empty NumPy array, same length as l_node_props\n",
    "\n",
    "\n",
    "   for l_index, l_key in enumerate(l_node_keys):                                                    #  Loop over the keys that are already in the graph\n",
    "      l_new_cols[l_index] = str(l_node_props[i_properties[0]][l_key]).upper()                       #  Derive a new column property value\n",
    "\n",
    "    \n",
    "   l_keyed_cols = KeyedColumnNode(l_new_cols, l_node_props[i_properties[0]], i_new_colname)         #  Building what we need to send to add_property()\n",
    "      #\n",
    "   i_graph.nodes.upsert_property(l_keyed_cols)\n",
    "\n",
    "\n",
    "   return\n",
    "\n",
    "l_cntr   += 1\n",
    "l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "\n",
    "   #\n",
    "l_result = my_graph.run(lambda g: my_func(g, \"Airport\", [\"airport_name\"], l_newcol))\n",
    "\n",
    "\n",
    "f_printtable1(l_newcol)\n",
    "f_printtable2(l_newcol)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f716c71-e564-4733-a97b-52b5eb0529bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdfda8-a1e0-4c88-804c-592d59d47358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Deleting a property from Nodes; approach 1\n",
    "#\n",
    "#     .  From the examples above, we could easily project that we could delete a column by setting\n",
    "#        its value to None.\n",
    "#\n",
    "#     .  But there is also, remove_property()\n",
    "#        This will work if the column is found on some Nodes. \n",
    "#        This will fail if the column is found on no Nodes.\n",
    "#\n",
    "#  We'll do both, starting with remove_property()\n",
    "#\n",
    "\n",
    "def my_func(i_graph, i_delcol):\n",
    "    \n",
    "   i_graph.nodes.remove_property(i_delcol)\n",
    "\n",
    "   return\n",
    "\n",
    "\n",
    "#  We wont increment l_cntr as we usually do, and instead leave it set to it's\n",
    "#  last value\n",
    "#\n",
    "#  l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "l_newcol = \"newcol_0026\"\n",
    "\n",
    "l_result = my_graph.run(lambda g: my_func(g, l_newcol))\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01ed4926-52ea-4fa6-8ef7-49a863d8840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90edf54ca5504aa084b269cdc8f88c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OperationError",
     "evalue": "BNntXuDq1HFR5rFoYf8sBL9GcuQ3w16yxX8yMYzMx98H-4QNd5idVWdVt6PQ1D backtrace (QueryOperation.cpp:67): backtrace (Network.h:331): backtrace (QueryOperation.cpp:70): backtrace (OpGraph.cpp:560): backtrace (OpGraph.h:596): backtrace (OpGraph.cpp:571): backtrace (OpGraph.cpp:64): backtrace (ProjectOperator.cpp:184): backtrace (Evaluate.cpp:2008): backtrace (Evaluate.cpp:1444): backtrace (ListFunc.cpp:1098): backtrace (PropertiesFunc.cpp:109): backtrace (PropertiesFunc.cpp:57): backtrace (Evaluate.cpp:2008): backtrace (EvaluateSelection.cpp:168): backtrace (KeyedSelection.cpp:287): backtrace (KeyedSelection.cpp:124): backtrace (KeyedCommunication.h:422): backtrace (KeyedCommunication.h:393): (../../libgluon/include/katana/KeyedCommunication.h:316): backtrace: backtrace (ColumnDistOps.cpp:30): buffer_index out of range.: arrow error: arrow error: arrow error: arrow error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#  Output a raw listing of all columns, for all nodes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m l_query  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m   MATCH (n)\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m   RETURN DISTINCT LABELS(n) AS label, KEYS(n)\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m   \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat()\n\u001b[0;32m----> 8\u001b[0m l_result \u001b[38;5;241m=\u001b[39m \u001b[43mmy_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m    \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(l_result, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m, tablefmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsql\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:249\u001b[0m, in \u001b[0;36mAsyncToSync.<locals>.do_wrap.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(underlying_func)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[0;32m--> 249\u001b[0m         \u001b[43munderlying_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_self_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:176\u001b[0m, in \u001b[0;36masync_to_sync.<locals>.wrapper\u001b[0;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     registry \u001b[38;5;241m=\u001b[39m AsyncToSyncClassRegistry\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[1;32m    168\u001b[0m         wait_for(\n\u001b[1;32m    169\u001b[0m             async_func(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:147\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(coro, timeout)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(timeout_coro, loop\u001b[38;5;241m=\u001b[39mAsyncRunnerThread\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mloop)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     inner_future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/asyncio/tasks.py:455\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    450\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe loop argument is deprecated since Python 3.8, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand scheduled for removal in Python 3.10.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    458\u001b[0m     fut \u001b[38;5;241m=\u001b[39m ensure_future(fut, loop\u001b[38;5;241m=\u001b[39mloop)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:299\u001b[0m, in \u001b[0;36mGraph.query\u001b[0;34m(self, query, memory_usage_factor, contextualize, **parameters)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m memory_usage_factor:\n\u001b[1;32m    297\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__katana_internal_match_batch_limit_scale_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m memory_usage_factor\n\u001b[0;32m--> 299\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_query(query, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[1;32m    300\u001b[0m rows \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    301\u001b[0m columns \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:277\u001b[0m, in \u001b[0;36mGraph._run_query\u001b[0;34m(self, query, parameters, parquet)\u001b[0m\n\u001b[1;32m    273\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcypher\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_operation_metadata(data)\n\u001b[0;32m--> 277\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_run_on_graph_and_wait(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/client.py:326\u001b[0m, in \u001b[0;36mDatabase._run_on_graph_and_wait\u001b[0;34m(self, graph, data)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_attempts:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_op(op)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mServerCommunicationError:\n\u001b[1;32m    328\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror while waiting, retrying (attempt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/client.py:263\u001b[0m, in \u001b[0;36mDatabase._wait_op\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m _progress_bar() \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m wait_fn(operation_id) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m    264\u001b[0m             status \u001b[38;5;241m=\u001b[39m update[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m update\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/asyncstdlib/builtins.py:445\u001b[0m, in \u001b[0;36mmap\u001b[0;34m(function, *iterable)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_iter:\n\u001b[1;32m    444\u001b[0m     result \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/asyncstdlib/_core.py:134\u001b[0m, in \u001b[0;36mforce_async.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/rpc/client.py:169\u001b[0m, in \u001b[0;36m_OperationClient._event_stream.<locals>.parse_stream\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    166\u001b[0m status \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOperationError(operation_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanceled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mCanceledError()\n",
      "\u001b[0;31mOperationError\u001b[0m: BNntXuDq1HFR5rFoYf8sBL9GcuQ3w16yxX8yMYzMx98H-4QNd5idVWdVt6PQ1D backtrace (QueryOperation.cpp:67): backtrace (Network.h:331): backtrace (QueryOperation.cpp:70): backtrace (OpGraph.cpp:560): backtrace (OpGraph.h:596): backtrace (OpGraph.cpp:571): backtrace (OpGraph.cpp:64): backtrace (ProjectOperator.cpp:184): backtrace (Evaluate.cpp:2008): backtrace (Evaluate.cpp:1444): backtrace (ListFunc.cpp:1098): backtrace (PropertiesFunc.cpp:109): backtrace (PropertiesFunc.cpp:57): backtrace (Evaluate.cpp:2008): backtrace (EvaluateSelection.cpp:168): backtrace (KeyedSelection.cpp:287): backtrace (KeyedSelection.cpp:124): backtrace (KeyedCommunication.h:422): backtrace (KeyedCommunication.h:393): (../../libgluon/include/katana/KeyedCommunication.h:316): backtrace: backtrace (ColumnDistOps.cpp:30): buffer_index out of range.: arrow error: arrow error: arrow error: arrow error"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Output a raw listing of all columns, for all nodes\n",
    "#\n",
    "l_query  = \"\"\"\n",
    "   MATCH (n)\n",
    "   RETURN DISTINCT LABELS(n) AS label, KEYS(n)\n",
    "   \"\"\".format()\n",
    "\n",
    "l_result = my_graph.query(l_query)\n",
    "   #\n",
    "print(tabulate(l_result, headers='keys', tablefmt='psql'))\n",
    "\n",
    "#  SAmple output,\n",
    "#\n",
    "#     +----+----------------+------------------------------------------------------------------------------------------------------------+\n",
    "#     |    | label          | KEYS(n)                                                                                                    |\n",
    "#     |----+----------------+------------------------------------------------------------------------------------------------------------|\n",
    "#     |  0 | ['Airport']    | ['LABEL', 'airport_name', 'id', 'newcol_0021', 'newcol_0022', 'newcol_0023', 'newcol_0024']                |\n",
    "#     |  1 | ['Airport']    | ['LABEL', 'airport_name', 'id', 'newcol_0021', 'newcol_0022', 'newcol_0023', 'newcol_0024', 'newcol_0026'] |\n",
    "#     |  2 | ['Restaurant'] | ['id', 'restaurant_name', 'newcol_0021', 'newcol_0022', 'newcol_0023']                                     |\n",
    "#     +----+----------------+------------------------------------------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e14ef74-6122-4cb9-bb8d-d8a8909d460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cae0345cd941f8ad0afcdaef53507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Deleting a property from Nodes; approach 2\n",
    "#\n",
    "#  We'll show deleting a property just from one Node type; Airport\n",
    "#\n",
    "\n",
    "\n",
    "def my_func(i_graph, i_label, i_delcol):\n",
    "    \n",
    "   from katana.distributed import KeyedColumnNode\n",
    "   import numpy as np\n",
    "    \n",
    "    \n",
    "   l_node_props = i_graph.nodes.get_property(i_delcol)\n",
    "      #\n",
    "   l_node_keys  = l_node_props.keys()                                                               #  keys() works against any column in the node.\n",
    "      #\n",
    "   l_new_cols   = np.zeros(len(l_node_props), dtype=\"object\")                                       #  An empty NumPy array, same length as l_node_props\n",
    "\n",
    "\n",
    "   for l_index, l_key in enumerate(l_node_keys):                                                    #  Loop over the keys that are already in the graph\n",
    "      if (i_label in i_graph.nodes.labels(l_key) ):                                                   \n",
    "         #  Is Airport\n",
    "         l_new_cols[l_index] = None\n",
    "      else:\n",
    "         #  Not Airport\n",
    "         l_new_cols[l_index] = l_node_props[l_key]\n",
    "    \n",
    "   l_keyed_cols = KeyedColumnNode(l_new_cols, l_node_props, i_delcol)                               #  Building what we need to send to upsert_property()\n",
    "      #\n",
    "   i_graph.nodes.upsert_property(l_keyed_cols)\n",
    "\n",
    "\n",
    "   return\n",
    "\n",
    "\n",
    "#  l_newcol =  \"newcol_\" + str(l_cntr).zfill(4)\n",
    "l_newcol = \"newcol_0023\"\n",
    "   #\n",
    "l_result = my_graph.run(lambda g: my_func(g, \"Airport\", l_newcol))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab78c3-5a51-407a-b796-bae790d246c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccaf3b-5f2c-4fce-bf0a-8bea63292344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f988f-a9b2-48f5-a03d-195112306076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36630b5-7169-4f3f-8ddf-84dd50c7be45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a07d2-7e81-4ce6-99eb-9e06457ca128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31854d56-0685-4b84-b095-7a5eb9af6b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33175f5a-d69c-4259-a732-1655c972a4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c44a97-4f73-42cd-ae7f-807e7f847cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8f1a9-0cd1-406e-8644-5640d4eef18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a63af-466c-4f62-9cce-66d95d054eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec1aed-4120-4626-8b98-68d384b02045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c93825-5067-4c50-b40c-6c2441bc2bc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  UDFs, Part 04: Data enrichment/derivation .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f7e01-7c71-46a2-aa37-4ac54afe3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Same as above, but add a derived column\n",
    "\n",
    "\n",
    "def my_func_III(i_graph, i_properties):\n",
    "    \n",
    "    \n",
    "   from katana_enterprise.distributed import single_host\n",
    "      #\n",
    "   import numpy  as np\n",
    "   import pandas as pd\n",
    "    \n",
    "\n",
    "   ##################################################################\n",
    "\n",
    "   #  Nested function, load a Python DataFrame from the KG graph\n",
    "    \n",
    "   def l_load_df(i_graph, i_properties):\n",
    "      l_nodes = []\n",
    "    \n",
    "      for l_property in i_properties:\n",
    "         l_node = i_graph.get_node_property(l_property).to_numpy().reshape(-1, 1)\n",
    "         l_nodes.append(l_node)\n",
    "       \n",
    "      l_array     = np.hstack(l_nodes)\n",
    "      l_dataframe = pd.DataFrame(l_array, columns=i_properties)\n",
    "         #\n",
    "    \n",
    "      return l_dataframe\n",
    "    \n",
    "   ##################################################################\n",
    "\n",
    "   #  Nested function, add a new, derived column to the DataFrame\n",
    "    \n",
    "   def l_enrich_df(i_dataframe, i_source_property, i_new_property):\n",
    "    \n",
    "      def l_to_upper(i_str):\n",
    "         if i_str.get(i_source_property) is not None:\n",
    "            return str(i_str[i_source_property]).upper()\n",
    "         else:\n",
    "            return\n",
    "    \n",
    "      i_dataframe[i_new_property] = i_dataframe.apply(l_to_upper, axis=1)\n",
    "    \n",
    "      return\n",
    "\n",
    "   ##################################################################\n",
    "    \n",
    "    \n",
    "   l_dataframe = l_load_df(i_graph, i_properties)\n",
    "      #\n",
    "   l_enrich_df(l_dataframe, \"fname\", \"fname_upper\")\n",
    "\n",
    "        \n",
    "   return single_host(host=0, result=l_dataframe)\n",
    "\n",
    "\n",
    "l_result = my_graph.run(lambda g: my_func_III(g, [\"id\", \"fname\", \"lname\"]))\n",
    "   #\n",
    "print(l_result)\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#                         id   fname    lname fname_upper\n",
    "#     0  1111-1111-1111-1111  Justin     Fine      JUSTIN\n",
    "#     1  2222-2222-2222-2222  Thomas     Cook      THOMAS\n",
    "#     2  3333-3333-3333-3333  Sameer  Iyengar      SAMEER\n",
    "#     3  4444-4444-4444-4444   Brian  Spencer       BRIAN\n",
    "#     4                  101    None     None        None\n",
    "#     5                  102    None     None        None\n",
    "#     6                  103    None     None        None\n",
    "#     7                  104    None     None        None\n",
    "#     8                  105    None     None        None\n",
    "#     9                  106    None     None        None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de7941-e0b1-4ff7-ac14-3471b1234940",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UDFs, Part 05: Just writing to the graph .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c5449-ea48-4ff6-a34c-d3eb334b12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_func_JJJ(i_graph):\n",
    "\n",
    "   import pandas as pd\n",
    "       \n",
    "   l_array     = [\n",
    "      [ \"7777-7777-7777-7777\", \"Bob\"     , \"Person\" ],\n",
    "      [ \"8888-8888-8888-8888\", \"Mary\"    , \"Person\" ],\n",
    "      [ \"9999-9999-9999-9999\", \"Earl\"    , \"Person\" ],\n",
    "      ]\n",
    "   l_dataframe = pd.DataFrame(l_array, columns=[\"id\", \"newcol\", \"type\"])\n",
    "    \n",
    "   i_graph.upsert_node_property(l_dataframe)\n",
    "\n",
    "    \n",
    "my_graph.run(lambda g: my_func_JJJ(g))\n",
    "\n",
    "\n",
    "#     Host 0 errors:\n",
    "#           ...\n",
    "#     ValueError: expected 10 rows found 3 instead (PropertyGraph.cpp:1282): invalid argument\n",
    "#     \n",
    "#     Host 1 errors:\n",
    "#           ...\n",
    "#     ValueError: expected 6 rows found 3 instead (PropertyGraph.cpp:1282): invalid argument\n",
    "#     \n",
    "#     Host 2 errors:\n",
    "#           ...\n",
    "#     ValueError: expected 0 rows found 3 instead (PropertyGraph.cpp:1282): invalid argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e4da1-fb79-430a-80f4-780be26843c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Attempt 01 to match what is expected by upsert_node_property()\n",
    "\n",
    "def my_func_KKK(i_graph):\n",
    "\n",
    "   l_node_ids = i_graph.get_node_property(\"id\")\n",
    "\n",
    "\n",
    "   for l_node in i_graph.master_nodes():\n",
    "      print(l_node)\n",
    "\n",
    "    \n",
    "my_graph.run(lambda g: my_func_KKK(g))\n",
    "\n",
    "\n",
    "#     Host 0 output:\n",
    "#     0\n",
    "#     1\n",
    "#     2\n",
    "#     3\n",
    "#     \n",
    "#     Host 1 output:\n",
    "#     0\n",
    "#     1\n",
    "#     2\n",
    "#     3\n",
    "#     4\n",
    "#     5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbea87c-6868-463f-97cb-5b3a631b8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This technique works differently than that above because we fetch the property titled, \"id\", which is present everywhere.\n",
    "#\n",
    "#  **  Arthur\n",
    "\n",
    "def my_func_MMM(i_graph, i_properties):\n",
    "    \n",
    "   import numpy  as np\n",
    "   import pandas as pd\n",
    "    \n",
    "   pd.set_option(\"display.max_columns\", None)\n",
    "   pd.set_option(\"max_colwidth\", None)\n",
    "    \n",
    "   l_nodes = []\n",
    " \n",
    "   for l_property in i_properties:\n",
    "      l_node = i_graph.get_node_property(l_property).to_numpy().reshape(-1, 1)\n",
    "      l_nodes.append(l_node)\n",
    "    \n",
    "   l_array     = np.hstack(l_nodes)\n",
    "   l_dataframe = pd.DataFrame(l_array, columns=i_properties)\n",
    "    \n",
    "   \n",
    "   #  todo-   Want better example\n",
    "   #          Also, one that only affects given rows\n",
    "   #\n",
    "   # xxx = l_dataframe.assign(new_column=lambda x: (None if x.fname is None else \"Mr. \" + x.fname))\n",
    "\n",
    "   xxx = l_dataframe.assign(new_column=lambda x: (x.fname))\n",
    "    \n",
    "   print(xxx)\n",
    "\n",
    "   #  This statement returns, but I see no changes to the graph.\n",
    "   #\n",
    "   i_graph.upsert_node_property(xxx)\n",
    "    \n",
    "   #  This statement hangs\n",
    "   #\n",
    "   i_graph.write()\n",
    "    \n",
    "    \n",
    "my_graph.run(lambda g: my_func_MMM(g, [\"id\", \"fname\"]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a72e1a-9ded-4514-9eee-8332cdbc9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  View the graph; verify results\n",
    "\n",
    "l_result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (n)\n",
    "   RETURN n\n",
    "   \n",
    "   \"\"\", contextualize=True)\n",
    "\n",
    "l_result.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef17e9-2b5d-4270-8fb6-ffc3958f61e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd437b6-b242-48cc-a1e5-6e95f390a624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10de210-06d5-4a8b-a08f-a7c5528f8b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9ea84-9ada-48ed-9971-cfe81fe32a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_func(i_graph, i_properties):\n",
    "    \n",
    "   import numpy as np\n",
    "   from katana_enterprise.distributed import single_host\n",
    "\n",
    "\n",
    "   l_return = np.random.randint(1, 101, 4)                #  Generate an array[4] of random numbers\n",
    "   print(l_return)\n",
    "    \n",
    "   return single_host(host=0, result=l_return)\n",
    "\n",
    "\n",
    "\n",
    "my_return = my_graph.run(lambda g: my_func(g, [\"xxx\", \"yyy\"]))\n",
    "   #\n",
    "display(\"--\")\n",
    "display(my_return)\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Host 0 output:\n",
    "#     [ 5 14 50 87]\n",
    "#     \n",
    "#     Host 1 output:\n",
    "#     [15 50 81 79]\n",
    "#     \n",
    "#     Host 2 output:\n",
    "#     [48 36 97 66]\n",
    "#     \n",
    "#     '--'\n",
    "#     \n",
    "#     array([ 5, 14, 50, 87])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e081913-611b-481f-bb32-c171fa87317d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8dd0d7-62b4-4847-bf2f-6b81ed69134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719c630-3a86-4972-8f07-e27db23fb5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342a07b-f7b5-436a-b8d5-173934a7475b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf796ba7-b2e8-4310-ab88-c0d5e1e66eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a15b9-759e-48ca-936e-51e5279e6457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843d673-8112-4bfc-b2c0-de33e13db880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74b584-e2f6-4262-a42c-4f34be250a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930391bc-81c8-40b9-afb9-a960169d2a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba708a04-094b-4069-b2eb-98def14eb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_func_JJJ(i_graph, i_properties):\n",
    "    \n",
    "    \n",
    "   from katana_enterprise.distributed import single_host\n",
    "      #\n",
    "   import numpy  as np\n",
    "   import pandas as pd\n",
    "    \n",
    "\n",
    "   ##################################################################\n",
    "\n",
    "   #  Nested function, load a Python DataFrame from the KG graph\n",
    "    \n",
    "   def l_load_df(i_graph, i_properties):\n",
    "      l_nodes = []\n",
    "    \n",
    "      for l_property in i_properties:\n",
    "         l_node = i_graph.get_node_property(l_property).to_numpy().reshape(-1, 1)\n",
    "         l_nodes.append(l_node)\n",
    "       \n",
    "      l_array     = np.hstack(l_nodes)\n",
    "      l_dataframe = pd.DataFrame(l_array, columns=i_properties)\n",
    "         #\n",
    "    \n",
    "      return l_dataframe\n",
    "    \n",
    "   ##################################################################\n",
    "\n",
    "   #  Nested function, add a new, derived column to the DataFrame\n",
    "    \n",
    "   def l_enrich_df(i_dataframe, i_source_property, i_new_property):\n",
    "    \n",
    "      def l_to_upper(i_str):\n",
    "         if i_str.get(i_source_property) is not None:\n",
    "            return str(i_str[i_source_property]).upper()\n",
    "         else:\n",
    "            return\n",
    "    \n",
    "      i_dataframe[i_new_property] = i_dataframe.apply(l_to_upper, axis=1)\n",
    "    \n",
    "      return\n",
    "\n",
    "   ##################################################################\n",
    "    \n",
    "   def l_save_df(i_graph, i_dataframe):\n",
    "    \n",
    "      # i_graph.upsert_node_property(i_dataframe)\n",
    "\n",
    "    \n",
    "    \n",
    "   ##################################################################\n",
    "    \n",
    "   l_dataframe = l_load_df(i_graph, i_properties)\n",
    "      #\n",
    "   l_enrich_df(l_dataframe, \"fname\", \"fname_upper\")\n",
    "      #\n",
    "   l_save_df(i_graph, l_dataframe)\n",
    "\n",
    "        \n",
    "   return single_host(host=0, result=l_dataframe)\n",
    "\n",
    "\n",
    "l_result = my_graph.run(lambda g: my_func_JJJ(g, [\"id\", \"fname\", \"lname\"]))\n",
    "   #\n",
    "print(l_result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
