{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfd2274-8be4-4517-a0bb-e5bf3e9370a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Notebook overview .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f14aa-01d9-4d3c-9986-a42fa4b15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This Notebook is part of a set that demonstrate GNN using a movie dataset.\n",
    "#  About this Notebook,\n",
    "#\n",
    "#  .  There was a Kaggle GNN challenge circa 2019 detailed here,\n",
    "#        https://www.kaggle.com/c/movie-genre-classification/data\n",
    "#\n",
    "#     That data is locked down, but a similarly themed dataset also on \n",
    "#     Kaggle is here,\n",
    "#        https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots \n",
    "#\n",
    "#     And this is the data set in use here.\n",
    "#\n",
    "#  .  77 MB, plus or minus. To remove dependencies on GS/S3 hosted data,\n",
    "#     this program expects this data to be local to the container hosting \n",
    "#     this Jupyter Notebook.\n",
    "#\n",
    "#     Since we host on GitHub, and GitHub has a 25 MB file size limit,\n",
    "#     the 77 MB total data set os now split across multiple files.\n",
    "#\n",
    "#  .  ASCII text format (CSV), the schema to the input text file is,\n",
    "#\n",
    "#        Release Year,Title,Origin/Ethnicity,Director,Cast,Genre,Wiki Page,Plot\n",
    "#\n",
    "#     And sample data resembles,\n",
    "#\n",
    "#        1981,Stripes,American,Ivan Reitman,\"Bill Murray, Harold Ramis, Warren Oates,\n",
    "#           John Candy, Sean Young, P.J. Soles, John Larroquette\", comedy,\n",
    "#           https://en.wikipedia.org/wiki/Stripes_(film), \"John Winger is a cab driver\n",
    "#           who, in the span of a few hours, loses his job, his apartment, his car,\n",
    "#           and his girlfriend. Realizing that he is a loser with no prospects, he\n",
    "#           decides to join the Army. Talking his best friend Russell Ziskey, a\n",
    "#           teacher of English as a second language, into joining with him, they go\n",
    "#           to a recruiting office and are soon sent off to basic training.\n",
    "#\n",
    "#   .  The source data is comprised of one flat file (model). We use Dask to \n",
    "#      extract nodes of type; Movie, Person, Genre, etcetera. And we use Dask\n",
    "#      to extract our relationships/edges.\n",
    "#\n",
    "#       The final product is a Movie graph, loaded using KataGraph's DataFrame\n",
    "#       importer..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a2149-2554-45a3-be06-8e2ebea43932",
   "metadata": {},
   "source": [
    "#  Load CSV's into Dask DataFrames .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a874df7-993f-404d-aa53-c8ca266f40a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef00ba9f-bad6-4db2-bee6-207d3be3a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l_InputFile  = \"./02_Files/10_08_Part01.txt\"\n",
    "\n",
    "df_raw_data = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      \"release_year\" : np.dtype(str),\n",
    "      \"title\"        : np.dtype(str),\n",
    "      \"country\"      : np.dtype(str),\n",
    "      \"director\"     : np.dtype(str),\n",
    "      \"cast\"         : np.dtype(str),\n",
    "      \"genre\"        : np.dtype(str),\n",
    "      \"wiki_url\"     : np.dtype(str),\n",
    "      \"plot\"         : np.dtype(str),\n",
    "      })\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00381493-ac45-4121-8b65-d7190f627e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8184 Rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1903</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>American</td>\n",
       "      <td>Cecil Hepworth</td>\n",
       "      <td>May Clark</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>Alice follows a large white rabbit down a \"Rab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905</td>\n",
       "      <td>The Little Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Little_Train...</td>\n",
       "      <td>The opening scene shows the interior of the ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1905</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Night_Before...</td>\n",
       "      <td>Scenes are introduced using lines of the poem....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "5          1903               Alice in Wonderland         American   \n",
       "6          1903           The Great Train Robbery         American   \n",
       "7          1904                   The Suburbanite         American   \n",
       "8          1905          The Little Train Robbery         American   \n",
       "9          1905        The Night Before Christmas         American   \n",
       "\n",
       "                             Director       Cast    Genre  \\\n",
       "0                             Unknown        NaN  unknown   \n",
       "1                             Unknown        NaN  unknown   \n",
       "2                             Unknown        NaN  unknown   \n",
       "3                             Unknown        NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter        NaN  unknown   \n",
       "5                      Cecil Hepworth  May Clark  unknown   \n",
       "6                     Edwin S. Porter        NaN  western   \n",
       "7                  Wallace McCutcheon        NaN   comedy   \n",
       "8                Edwin Stanton Porter        NaN  unknown   \n",
       "9                Edwin Stanton Porter        NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "5  https://en.wikipedia.org/wiki/Alice_in_Wonderl...   \n",
       "6  https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7      https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "8  https://en.wikipedia.org/wiki/The_Little_Train...   \n",
       "9  https://en.wikipedia.org/wiki/The_Night_Before...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  \n",
       "5  Alice follows a large white rabbit down a \"Rab...  \n",
       "6  The film opens with two bandits breaking into ...  \n",
       "7  The film is about a family who move to the sub...  \n",
       "8  The opening scene shows the interior of the ro...  \n",
       "9  Scenes are introduced using lines of the poem....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['releaser_year', 'title'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#  Other output\u001b[39;00m\n\u001b[1;32m      8\u001b[0m display(df_raw_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m display(df_raw_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreleaser_year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py:4486\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4480\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m   4482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   4483\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_dask_collection(key) \u001b[38;5;129;01mand\u001b[39;00m (is_series_like(key) \u001b[38;5;129;01mor\u001b[39;00m is_index_like(key))\n\u001b[1;32m   4484\u001b[0m ):\n\u001b[1;32m   4485\u001b[0m     \u001b[38;5;66;03m# error is raised from pandas\u001b[39;00m\n\u001b[0;32m-> 4486\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4488\u001b[0m     dsk \u001b[38;5;241m=\u001b[39m partitionwise_graph(operator\u001b[38;5;241m.\u001b[39mgetitem, name, \u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m   4489\u001b[0m     graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(name, dsk, dependencies\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3464\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3463\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3464\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3466\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[1;32m   1318\u001b[0m ):\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1374\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   1373\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['releaser_year', 'title'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "#  Number of rows, two different ways\n",
    "\n",
    "display(len(df_raw_data))\n",
    "display(print(\"{} Rows\".format(df_raw_data.shape[0].compute())))\n",
    "\n",
    "#  Other output\n",
    "\n",
    "display(df_raw_data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ad2bd-f77c-4d0c-bc22-7304a0609d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa5d25-c0d8-4a73-bf59-02207b28f659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b0c91-fde8-4fc0-ac76-9bcba213c989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff4019-7fe0-4d3d-bf60-db83deba659c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38bd3-1c7e-46ba-9e2c-13b784052efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05070e73-8c0a-4fef-8bd8-c60e83b22b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e6482-1186-4a12-91cc-91580fded193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27725cb6-5404-4132-95e4-f26ea493e899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a009883-fadd-4dfe-9f83-efd5e4ef6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc3b51-a38f-406d-b4cb-4bcd13c5f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e9e29-c90b-4ed6-9997-db56ff225fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  This section; basic graph and database setup, reset for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfb83b-fd1f-46c3-96ad-95ceed14058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04909ce0-17bc-4214-84a7-3016cdbf52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb24521-9a8d-4fad-bdec-52876bc71e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6371d-6d53-4052-b895-f61c76b0792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE A GRAPH\n",
    "\n",
    "my_graph=my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f6eb7-59ef-4c9b-813a-e8370b25b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CONNECT TO GRAPH\n",
    "\n",
    "for l_graph in my_client.get_database(name=DB_NAME).graphs_in_database():\n",
    "   if (l_graph.name == GRAPH_NAME):\n",
    "      my_graph=my_client.get_database(name=DB_NAME).get_graph_by_id(id=l_graph.graph_id)\n",
    "         #\n",
    "      break\n",
    "\n",
    "# my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedb2fa-cec7-474a-acc2-5cefbbb3660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb5a2d-bddb-4bba-9169-e5dfc1d44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Load from source CSV, in this case we are using the Neo4J Movie graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ddce-66b8-43a8-b551-3a51a6983449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259d64d-c879-4e1f-ab10-6cf663b293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Nodes/Vertices\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/24_nodes.txt\"\n",
    "\n",
    "df_all_nodes1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"id\"        : int,\n",
    "      \"id\"        : np.dtype('O'),\n",
    "      \"_labels\"   : np.dtype('O'),\n",
    "      # \"born\"      : float, \n",
    "      \"born\"      : np.dtype('O'),\n",
    "      \"name\"      : np.dtype('O'),\n",
    "      # \"released\"  : float,\n",
    "      \"released\"  : np.dtype('O'),\n",
    "      \"tagline\"   : np.dtype('O'),\n",
    "      \"title\"     : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91245c1-9a0f-455b-b9c1-f975018d98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of rows, two different ways\n",
    "\n",
    "display(len(df_all_nodes1))\n",
    "display(print(\"{} Rows\".format(df_all_nodes1.shape[0].compute())))\n",
    "\n",
    "#  Other output\n",
    "\n",
    "display(df_all_nodes1.head(10))\n",
    "display(df_all_nodes1[[\"born\", \"name\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07d63f-9c74-43e8-ba54-cdbd6099e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print all rows, subsetted columns\n",
    "\n",
    "for l_each in df_all_nodes1.iterrows():\n",
    "   print(l_each[0], \"   \", l_each[1][\"_labels\"], \"   \", l_each[1][\"name\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490285c-abad-4c3b-804d-2534515c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#   https://www.askpython.com/python/examples/subset-a-dataframe\n",
    "#   https://www.codegrepper.com/code-examples/python/convert+float+to+int+python+pandas\n",
    "#   https://docs.dask.org/en/latest/generated/dask.dataframe.DataFrame.assign.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dc5f0-3ce2-4c47-8db4-0b7438277f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We have some issues we want to change with our data\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n",
    "#  .  The label values are currently \";Person\" and \";Movie\". Let's remove those semicolons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf635-c973-4c1d-91d4-36bc47eb5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Column renames\n",
    "\n",
    "df_all_nodes2 = df_all_nodes1.rename(columns={\"_id\": \"id\", \"_labels\": \"label\"})\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc357f2-0a17-42c9-ab81-3d984a1604b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Change float values to integer, remove leading semicolon from label\n",
    "\n",
    "df_all_nodes3 = df_all_nodes2.assign(\n",
    "   # born     = lambda x: x.born.fillna(0.0).astype(int), \n",
    "   born     = lambda x: x.born.fillna(0.0).astype(str), \n",
    "   # id       = lambda x: x.id.fillna(0.0).astype(int),\n",
    "   id       = lambda x: x.id.fillna(0.0).astype(str),\n",
    "   # released = lambda x: x.released.fillna(0.0).astype(int),\n",
    "   released = lambda x: x.released.fillna(0.0).astype(str),\n",
    "   label    = lambda x: x.label.astype(str).str[1:]\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485b323-6335-4dd2-8d63-dfbf7e845f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_nodes3))\n",
    "display(df_all_nodes3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e942-6083-4ddc-a55d-104bd0cf5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83330545-9507-4cef-831a-bb1ea802029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now, populate Persons and Movies\n",
    "\n",
    "df_persons = df_all_nodes3[df_all_nodes3[\"label\"] == \"Person\"][[\"id\", \"label\", \"born\", \"name\"]]\n",
    "\n",
    "df_movies  = df_all_nodes3[df_all_nodes3[\"label\"] == \"Movie\"][[\"id\", \"label\", \"released\", \"tagline\", \"title\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c958-2366-45e6-b316-6b30198858d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_persons))\n",
    "display(df_persons.head(10))\n",
    "display(len(df_movies))\n",
    "display(df_movies.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ec1d4-2f6a-42d7-b026-6d4db9979aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Repeat the style of work from above, but now for edges\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb9803-9e7b-4471-83ad-d279bb733d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Edges\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/25_edges.txt\"\n",
    "\n",
    "df_all_edges1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"_start\"    : float,\n",
    "      \"_start\"    : np.dtype('O'),\n",
    "      # \"_end\"      : float, \n",
    "      \"_end\"      : np.dtype('O'),\n",
    "      \"_type\"     : np.dtype('O'),\n",
    "      # \"rating\"    : float,\n",
    "      \"rating\"    : np.dtype('O'),\n",
    "      \"roles\"     : np.dtype('O'),\n",
    "      \"summary\"   : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fde9ff-5304-4d2c-b351-84fe21d97f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges1))\n",
    "display(df_all_edges1.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9356971-a6d7-4cba-ae07-cc0d693e39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_edges2 = df_all_edges1.rename(columns={\"_start\": \"START_ID\", \"_end\": \"END_ID\", \"_type\": \"TYPE\",\n",
    "   \"rating\": \"RATING\", \"roles\": \"ROLES\", \"summary\": \"SUMMARY\"})\n",
    "\n",
    "df_all_edges3 = df_all_edges2.assign(\n",
    "   # START_ID = lambda x: x.START_ID.fillna(0.0).astype(int), \n",
    "   START_ID = lambda x: x.START_ID.fillna(0.0).astype(str), \n",
    "   # END_ID   = lambda x: x.END_ID.fillna(0.0).astype(int),\n",
    "   END_ID   = lambda x: x.END_ID.fillna(0.0).astype(str),\n",
    "   # RATING   = lambda x: x.RATING.fillna(0.0).astype(int)\n",
    "   RATING   = lambda x: x.RATING.fillna(0.0).astype(str)\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddde16b-d104-4e12-aac2-40d6598ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges3))\n",
    "display(df_all_edges3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a838f-d161-4898-95ca-80f608fa82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split out the various edges\n",
    "\n",
    "df_reviewed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"REVIEWED\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]]\n",
    "\n",
    "df_wrote    = df_all_edges3[df_all_edges3[\"TYPE\"] == \"WROTE\"   ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_produced = df_all_edges3[df_all_edges3[\"TYPE\"] == \"PRODUCED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_directed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"DIRECTED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_follows  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"FOLLOWS\" ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "#  \"roles\" is a string similar to  '[ \"a\", \"b\", \"c\" ]'\n",
    "#\n",
    "#  This was automatically coming in as a list-\n",
    "#  Cool\n",
    "\n",
    "df_actedin  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"ACTED_IN\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f1fa7-3ac5-4eb9-a749-6f3d89267d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_reviewed))\n",
    "display(df_reviewed.head(2))\n",
    "\n",
    "display(len(df_wrote))\n",
    "display(df_wrote.head(2))\n",
    "\n",
    "display(len(df_produced))\n",
    "display(df_produced.head(2))\n",
    "\n",
    "display(len(df_directed))\n",
    "display(df_directed.head(2))\n",
    "\n",
    "display(len(df_follows))\n",
    "display(df_follows.head(2))\n",
    "\n",
    "display(len(df_actedin))\n",
    "display(df_actedin.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e959b0-0040-4556-a486-8267ae32c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47455c-f349-4c06-be7f-214e996a33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Didn't need this; also don't know if it had any effect\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=4, threads_per_worker=2)\n",
    "\n",
    "# print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba15117-b555-4953-8580-38e4222f4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Finally now, load the vertices/nodes into a graph\n",
    "#\n",
    "#  Some hinkiness we need to work around ..\n",
    "#\n",
    "#     .  The Dask DataFrames here were loaded from CSV, and those CSV\n",
    "#        files were found, in scope.\n",
    "#        The KG DataFrame importer will reference that same file\n",
    "#        pathname, and the file will not be in scope. Basically,\n",
    "#        it was expected that these files be on S3/GS all along.\n",
    "#        I hate to have that dependency because, just one more thing\n",
    "#        to have to manage.\n",
    "#\n",
    "#     .  So, we'll copy the DataFrames to Dask arrays, then back into\n",
    "#        a Dask DataFrame.\n",
    "#        Why not just copy the DaskDataFrame ?  Currently there is only \n",
    "#        shallow copies of DataFrames.\n",
    "#\n",
    "#  See,\n",
    "#     https://stackoverflow.com/questions/52119342/how-do-i-convert-a-dask-dataframe-into-a-dask-array\n",
    "#     https://docs.dask.org/en/latest/generated/dask.dataframe.from_dask_array.html\n",
    "\n",
    "\n",
    "da_persons    = df_persons.to_dask_array()\n",
    "da_movies     = df_movies.to_dask_array()\n",
    "   #\n",
    "da_directed   = df_directed.to_dask_array()\n",
    "da_reviewed   = df_reviewed.to_dask_array()\n",
    "da_wrote      = df_wrote.to_dask_array()\n",
    "da_produced   = df_produced.to_dask_array()\n",
    "da_follows    = df_follows.to_dask_array()\n",
    "da_actedin    = df_actedin.to_dask_array()\n",
    "\n",
    "\n",
    "df_persons2   = dd.io.from_dask_array(da_persons,  columns=[\"id\", \"label\", \"born\", \"name\"]).compute()\n",
    "df_movies2    = dd.io.from_dask_array(da_movies,   columns=[\"id\", \"label\", \"released\", \"tagline\", \"title\"]).compute()\n",
    "   #\n",
    "df_directed2  = dd.io.from_dask_array(da_directed, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_reviewed2  = dd.io.from_dask_array(da_reviewed, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]).compute()\n",
    "df_wrote2     = dd.io.from_dask_array(da_wrote, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_produced2  = dd.io.from_dask_array(da_produced, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_follows2   = dd.io.from_dask_array(da_follows, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_actedin2   = dd.io.from_dask_array(da_actedin, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]).compute()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060507c-c49f-4cda-92c0-a53752091fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from katana_enterprise.remote import import_data\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737ce45-e17f-49e4-ac98-af1dc3bf8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:\n",
    "    \n",
    "   # Person\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_persons2[[\"id\", \"label\", \"born\", \"name\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Person\"\n",
    "      )\n",
    "   #  Movie\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_movies2[[\"id\", \"label\", \"title\", \"tagline\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Movie\"\n",
    "      )  \n",
    "    \n",
    "   #  DIRECTED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_directed2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"DIRECTED\"\n",
    "      )\n",
    "   #  REVIEWED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_reviewed2[[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"REVIEWED\"\n",
    "      )\n",
    "   #  WROTE\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_wrote2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"WROTE\"\n",
    "      )\n",
    "   #  PRODUCED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_produced2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"PRODUCED\"\n",
    "      )\n",
    "   #  FOLLOWS\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_follows2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"FOLLOWS\"\n",
    "      )\n",
    "   #  ACTEDIN\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_actedin2[[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"ACTEDIN\"\n",
    "      )\n",
    "\n",
    "   df_importer.execute()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d9a40-4d2e-4972-9113-3084d2258d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (a) \n",
    "   WITH DISTINCT LABELS(a) AS temp, COUNT(a) AS tempCnt\n",
    "   UNWIND temp AS label\n",
    "   RETURN label, SUM(tempCnt) AS cnt\n",
    "   ORDER BY label\n",
    "   \n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef49e4-30e4-488c-963b-bf13c44e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (m)-[r]->(n) \n",
    "   WITH DISTINCT TYPE(r) AS temp, COUNT(r) AS tempCnt\n",
    "   RETURN temp, tempCnt\n",
    "   ORDER BY temp\n",
    "\n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550017-2685-48ed-994b-5a51395ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (x) -[r]-> (a)\n",
    "   RETURN x, r AS rel, a\n",
    "   \n",
    "   \"\"\",\n",
    "   contextualize=True)\n",
    "\n",
    "result.view()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb62f6-0d3f-4d22-924f-a2630e3405a7",
   "metadata": {},
   "source": [
    "# Output a graph as a a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800b8bb-11ec-4904-9217-51e56a5b9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Formatting could use a little work, but the concept is here ..\n",
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "   MATCH (n: Person) \n",
    "   RETURN n\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result1))\n",
    "\n",
    "l_result2 = my_graph.query(\"\"\"\n",
    "   MATCH (n) - [r: WROTE] -> (m)\n",
    "   RETURN r\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd62f55-1b27-43f1-bdc4-e1b79de25609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_nodes = []\n",
    "   #\n",
    "for l_node in l_result1.iterrows():\n",
    "   l_nodes.append(l_node)\n",
    "\n",
    "l_file = open(\"nodes.txt\", \"w\")\n",
    "l_file.write(str(l_nodes))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "l_edges = []\n",
    "   #\n",
    "for l_edge in l_result2.iterrows():\n",
    "   l_edges.append(l_edge)\n",
    "\n",
    "l_file = open(\"edges.txt\", \"w\")\n",
    "l_file.write(str(l_edges))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
