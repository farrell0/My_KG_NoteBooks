{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776f754-ef98-4cbd-a423-647c483341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Here we demonstrate the following Dask DataFrame techniques;\n",
    "#\n",
    "#     .  How to create a Dask DataFrame from an array.\n",
    "#\n",
    "#     .  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682150e3-6a50-4197-a239-80d1d2ea6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0416c10d-a1cb-433d-ad5e-85498aaa1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "   #\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "   #\n",
    "from dask.dataframe import from_pandas\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c6a99e-7b23-4cf6-9880-d70fffb4b889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131298d0-5cb4-4b62-8413-5e5571ef4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport:  MKE   Milwaukee            WI   Airport   \n",
      "Airport:  ORD   Chicago O-Hare       IL   Airport   \n",
      "Airport:  SJC   San Jose             CA   Airport   \n",
      "Airport:  LAX   Los Angeles          CA   Airport   \n",
      "Airport:  DEN   Denver               CO   Airport   \n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Create our source Dask DataFrame from an array\n",
    "\n",
    "np_airports = np.array([\n",
    "       #\n",
    "   [\"MKE\", \"Milwaukee\"     , \"WI\", \"Airport\"],\n",
    "   [\"ORD\", \"Chicago O-Hare\", \"IL\", \"Airport\"],\n",
    "   [\"SJC\", \"San Jose\"      , \"CA\", \"Airport\"],\n",
    "   [\"LAX\", \"Los Angeles\"   , \"CA\", \"Airport\"],\n",
    "   [\"DEN\", \"Denver\"        , \"CO\", \"Airport\"],\n",
    "       #\n",
    "   ], dtype=\"str\")\n",
    "\n",
    "pd_airports = pd.DataFrame(np_airports, columns = [\"airport_code\", \"airport_name\", \"state_code\", \"LABEL\"])\n",
    "   #\n",
    "dd_airports = from_pandas(pd_airports, npartitions = NUM_PARTITIONS)\n",
    "\n",
    "\n",
    "for l_each in dd_airports.itertuples():\n",
    "   print(\"Airport:  %3s   %-18s   %-2s   %-10s\" % (l_each.airport_code, l_each.airport_name, l_each.state_code, l_each.LABEL))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  Airport:  MKE   Milwaukee            WI   Airport   \n",
    "#  Airport:  ORD   Chicago O-Hare       IL   Airport   \n",
    "#  Airport:  SJC   San Jose             CA   Airport   \n",
    "#  Airport:  LAX   Los Angeles          CA   Airport   \n",
    "#  Airport:  DEN   Denver               CO   Airport  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f23d1-6559-4c0b-89c6-86c19eda8028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aba548-02b0-4290-af3f-8d39fcad0e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216ee1f-b485-4ad0-86e9-df7a65cfb12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b9e1e-86ad-4c87-94c1-7804ec7e6454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "828d62e9-1cf8-4eee-9147-f351961b95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseballhelmet\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(6, 6)\n",
      "  (0, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 5)\t1\n",
      "  (5, 2)\t1\n",
      "\n",
      "(0, 0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "Name: 0, dtype: int64)\n",
      "(1, 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "Name: 1, dtype: int64)\n",
      "(2, 0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "Name: 2, dtype: int64)\n",
      "(3, 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "Name: 3, dtype: int64)\n",
      "(4, 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    1\n",
      "Name: 4, dtype: int64)\n",
      "(5, 0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "Name: 5, dtype: int64)\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  \n",
    "\n",
    "my_cv = CountVectorizer()\n",
    "\n",
    "#  .  The list will be automatically sorted\n",
    "#  .  Words will be automatically split on whitespace, hyphens, other\n",
    "#  .  Duplicates do receive multiple entries im the output. Not certain of the effect of that.\n",
    "\n",
    "\n",
    "my_words_arr = [ \n",
    "   \"baseball\",\n",
    "   \"football\",\n",
    "   \"cricket\",\n",
    "   \"golf\",\n",
    "   \"racing\",\n",
    "   \"fencing\",\n",
    "]\n",
    "   #\n",
    "print(my_words_arr[0])\n",
    "\n",
    "my_cv_counts = my_cv.fit_transform(my_words_arr)\n",
    "# my_cv_counts = my_cv.fit_transform(dd_airports)\n",
    "\n",
    "\n",
    "print(type(my_cv_counts))\n",
    "   #\n",
    "print(my_cv_counts.shape)\n",
    "print(my_cv_counts      )\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "df_words = pd.DataFrame(my_cv_counts.toarray())\n",
    "   #\n",
    "for l_each in df_words.iterrows():\n",
    "   print(l_each)\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea72023-5366-444e-8cdf-cdb280b75e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e4b85-372f-491c-84b1-fc7714788163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f49097-92db-4c90-b76c-199b5a7ca20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
