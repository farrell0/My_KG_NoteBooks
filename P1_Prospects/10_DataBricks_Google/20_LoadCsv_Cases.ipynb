{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54fd830-1317-4a52-b610-ef9716e5d744",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Setup: Display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38ebd7-d1d9-47a8-955c-a8270b024543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7ce90-67cf-462c-94a6-3c8c9d0754b3",
   "metadata": {},
   "source": [
    "# Setup: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b75ba-c072-4111-8cca-4b4f394a0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a77f99-f11b-4105-ab43-17ce605b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f2292b8-7df0-49a0-b3da-523f56cfe4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f69a0e-451b-4679-b49c-5db1208d4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3bc00-fafb-481d-ba5a-8b52ae7d6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8ba088b-2ec5-4b2a-8171-3c87ddffb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_Graph my_graph, dcLHS6ayyAudS2cxaUPxJyrdL81NUNjRmxeaN7cdUE5, 0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  CREATE GRAPH\n",
    "#\n",
    "my_graph = my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3685a36-d987-4ad8-a209-7115d726ac03",
   "metadata": {},
   "source": [
    "# Step 01:  Process CSV files .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351b0fd-6237-4d7a-99f1-dec2150ec4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This data was sourced from,\n",
    "#     https://mtsamples.com/site/pages/browse.asp?type=96-Hematology%20-%20Oncology\n",
    "#\n",
    "\n",
    "#  Column headers,\n",
    "#     id|medical_specialty|sample_name|description|body\n",
    "#\n",
    "df_PatientVisitNodes = pd.read_csv(\"./10_Data/22_OncologyCallNotes.txt\", header = \"infer\", delimiter = \"|\")\n",
    "\n",
    "\n",
    "#  90 Real lines of data.  (Some data is multi-line, and enclosed in double quotes.)\n",
    "#\n",
    "print(\"Number of CSV input lines: %d\" % (len(df_PatientVisitNodes)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#   Above, the field titled \"body\" contains embedded new lines; remove those\n",
    "#   and place in a new field titled, \"body_1line\"\n",
    "#\n",
    "df_PatientVisitNodes[\"body_1line\"] = df_PatientVisitNodes.body.map(lambda x: str(x).replace(\"\\n\", \"\") )\n",
    "#  \n",
    "#  And add a \"LABEL\" property\n",
    "#\n",
    "df_PatientVisitNodes[\"LABEL\"]      = df_PatientVisitNodes.body.map(lambda x: \"PatientVisit\"           )\n",
    "\n",
    "\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in df_PatientVisitNodes.itertuples():\n",
    "   l_cntr += 1\n",
    "      #\n",
    "   if (l_cntr < 5):\n",
    "      print(\"Record number: %d   Sample name: %-44s   Short text: %s\" % (l_each.id, l_each.sample_name[0:43], l_each.body_1line[0:60]))\n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Number of CSV input lines: 90\n",
    "#     \n",
    "#     Record number: 4001   Sample name: 3-Dimensional Simulation                       Short text: This patient is undergoing 3-dimensionally planned radiation\n",
    "#     Record number: 4002   Sample name: Adrenalectomy & Umbilical Hernia Repair        Short text: PREOPERATIVE DIAGNOSES1. Adrenal mass, right sided.2. Umbi\n",
    "#     Record number: 4003   Sample name: Anaplastic Astrocytoma - Letter                Short text: Month DD, YYYYXYZRE: ABCMEDICAL RECORD#: 123Dear Dr. \n",
    "#     Record number: 4004   Sample name: Anemia & Leukemia Followup                     Short text: CHIEF COMPLAINT:1. Chronic lymphocytic leukemia (CLL).2. A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1c889-3b18-44f7-adcf-b9b5eca13dd5",
   "metadata": {},
   "source": [
    "#  Step 02: Enrich the above from a Google Web service .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491d824-e497-4548-8ace-659c3657662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Google has a Web service to convert text into usable UMLS codes. See,\n",
    "#        https://cloud.google.com/healthcare-api/docs/how-tos/nlp\n",
    "#\n",
    "#  In this cell, we begin to invoke this service on the text from the\n",
    "#  cell above.\n",
    "\n",
    "#  See also,\n",
    "#     https://stackoverflow.com/questions/53472429/how-to-get-a-gcp-bearer-token-programmatically-with-python\n",
    "\n",
    "#  Google:\n",
    "#\n",
    "#     .  We had to create an Auth Token, which produced a JSON file.\n",
    "#        (Instruction in Url above.)\n",
    "#\n",
    "#     .  Our JSON file is at,\n",
    "#              export GOOGLE_APPLICATION_CREDENTIALS=\"/mnt/hgfs/My.20/MyShare_1/46 Topics 2022/91 KG, All Prospects/13 KG, DataBricks, Google/10_Data/05_katana-clusters-beta-d8605ac248e7.json\"\n",
    "#              export GOOGLE_APPLICATION_CREDENTIALS=\"/home/jovyan/work/My_KG_NoteBooks/P1_Prospects/10_DataBricks_Google/10_Data/05_katana-clusters-beta-d8605ac248e7.json\"\n",
    "#\n",
    "#     .  To extract the Auth Token, set the above, then run\n",
    "#           gcloud auth application-default print-access-token\n",
    "\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "#  This token times out often; you must rerun this block from time to time\n",
    "#\n",
    "l_credentials = service_account.Credentials.from_service_account_file(\n",
    "   \"/home/jovyan/work/My_KG_NoteBooks/P1_Prospects/10_DataBricks_Google/10_Data/05_katana-clusters-beta-d8605ac248e7.json\",\n",
    "   scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
    "l_auth_req = google.auth.transport.requests.Request()\n",
    "l_credentials.refresh(l_auth_req)\n",
    "   #\n",
    "l_token = l_credentials.token\n",
    "    \n",
    "print(l_token)\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     ya29.c.b0Aa9VdylvtWgGXBZyFkW5mADfcFiyBVitZsvkoKbHpCuXU7zGkgANRcho_ax5_SWWbiXfQj6cprlobWUlHnPkYEoKBCRw6   ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c425da-e8f3-4a68-bbff-323a002693cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Cool page; convert Curl command to Python,\n",
    "#     https://reqbin.com/curl\n",
    "\n",
    "#  Run the Google Web service, capture results\n",
    "#\n",
    "\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "   #\n",
    "import json\n",
    "\n",
    "    \n",
    "#  Function, because we will loop on this below-\n",
    "#\n",
    "def f_enrich(i_arg1):\n",
    "    \n",
    "   url = \"https://healthcare.googleapis.com/v1/projects/katana-clusters-beta/locations/us-central1/services/nlp:analyzeEntities\"\n",
    "   \n",
    "   l_headers = CaseInsensitiveDict()\n",
    "      #\n",
    "   l_headers[\"Authorization\"] = \"Bearer \" + l_token\n",
    "   l_headers[\"Content-Type\"]  = \"application/json\"\n",
    "       \n",
    "    \n",
    "   l_data = \"\"\"\n",
    "      {{\n",
    "      'nlpService':'projects/katana-clusters-beta/locations/us-central1/services/nlp',\n",
    "      'documentContent':'{0}'\n",
    "      }}\n",
    "      \"\"\".format(i_arg1)\n",
    "         #\n",
    "   l_resp = requests.post(url, headers = l_headers, data = l_data)\n",
    "      #\n",
    "   return l_resp\n",
    "\n",
    "\n",
    "\n",
    "l_response = f_enrich(\"Insulin regimen human 5 units IV administered.\")\n",
    "   #\n",
    "\n",
    "print(l_response.status_code)\n",
    "print(\"\")\n",
    "   #\n",
    "l_data_asjson = json.loads(l_response.content)                       #  Get the response in json\n",
    "print(json.dumps(l_data_asjson, indent = 3))                         #  This gives us a pretty print (easier to read)\n",
    "\n",
    "\n",
    "#  Sample data after this cell-,\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8409d8-ea25-47ea-b911-d3bd7643e9a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Step 00:  Sample data from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c91100-2973-4f3f-9f3e-a28b53a1da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample data from above,\n",
    "#\n",
    "#     200\n",
    "#     \n",
    "#     {\n",
    "#        \"entityMentions\": [\n",
    "#           {\n",
    "#              \"mentionId\": \"1\",\n",
    "#              \"type\": \"MEDICINE\",\n",
    "#              \"text\": {\n",
    "#                 \"content\": \"Insulin regimen\",\n",
    "#                 \"beginOffset\": 0\n",
    "#              },\n",
    "#              \"linkedEntities\": [\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C0021641\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C0795635\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C1533581\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C3537244\"\n",
    "#                 },\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C3714501\"\n",
    "#                 }\n",
    "#              ],\n",
    "#              \"temporalAssessment\": {\n",
    "#                 \"value\": \"CURRENT\",\n",
    "#                 \"confidence\": 0.8573660850524902\n",
    "#              },\n",
    "#              \"certaintyAssessment\": {\n",
    "#                 \"value\": \"LIKELY\",\n",
    "#                 \"confidence\": 0.9751282930374146\n",
    "#              },\n",
    "#              \"subject\": {\n",
    "#                 \"value\": \"PATIENT\",\n",
    "#                 \"confidence\": 0.9995787739753723\n",
    "#              },\n",
    "#              \"confidence\": 0.6379408836364746\n",
    "#           },\n",
    "#           {\n",
    "#              \"mentionId\": \"2\",\n",
    "#              \"type\": \"MED_DOSE\",\n",
    "#              \"text\": {\n",
    "#                 \"content\": \"5 units\",\n",
    "#                 \"beginOffset\": 22\n",
    "#              },\n",
    "#              \"confidence\": 0.7443782091140747\n",
    "#           },\n",
    "#           {\n",
    "#              \"mentionId\": \"3\",\n",
    "#              \"type\": \"MED_ROUTE\",\n",
    "#              \"text\": {\n",
    "#                 \"content\": \"IV\",\n",
    "#                 \"beginOffset\": 30\n",
    "#              },\n",
    "#              \"linkedEntities\": [\n",
    "#                 {\n",
    "#                    \"entityId\": \"UMLS/C0348016\"\n",
    "#                 }\n",
    "#              ],\n",
    "#              \"confidence\": 0.779011607170105\n",
    "#           }\n",
    "#        ],\n",
    "#        \"entities\": [\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C0021641\",\n",
    "#              \"preferredTerm\": \"Insulin\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"FMA/83365\",\n",
    "#                 \"LNC/LA15805-7\",\n",
    "#                 \"LNC/LP14676-8\",\n",
    "#                 \"LNC/LP16325-0\",\n",
    "#                 \"LNC/LP32542-0\",\n",
    "#                 \"LNC/LP70329-5\",\n",
    "#                 \"LNC/MTHU002108\",\n",
    "#                 \"LNC/MTHU019392\",\n",
    "#                 \"MSH/D007328\",\n",
    "#                 \"MTH/NOCODE\"\n",
    "#              ]\n",
    "#           },\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C0348016\",\n",
    "#              \"preferredTerm\": \"Intravenous\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"LNC/LA9437-0\",\n",
    "#                 \"LNC/LP32453-0\",\n",
    "#                 \"MTH/NOCODE\",\n",
    "#                 \"NCI/C13346\"\n",
    "#              ]\n",
    "#           },\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C0795635\",\n",
    "#              \"preferredTerm\": \"insulin, regular, human\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"LNC/LP17001-6\",\n",
    "#                 \"MSH/D061386\",\n",
    "#                 \"MTH/NOCODE\",\n",
    "#                 \"NCI/C29125\",\n",
    "#                 \"RXNORM/253182\",\n",
    "#                 \"VANDF/4017559\",\n",
    "#                 \"VANDF/4017569\",\n",
    "#                 \"VANDF/4019786\"\n",
    "#              ]\n",
    "#           },\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C1533581\",\n",
    "#              \"preferredTerm\": \"Therapeutic Insulin\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"MTH/NOCODE\",\n",
    "#                 \"NCI/C581\"\n",
    "#              ]\n",
    "#           },\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C3537244\",\n",
    "#              \"preferredTerm\": \"Insulins\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"MSH/D061385\",\n",
    "#                 \"MTH/NOCODE\"\n",
    "#              ]\n",
    "#           },\n",
    "#           {\n",
    "#              \"entityId\": \"UMLS/C3714501\",\n",
    "#              \"preferredTerm\": \"Insulin Drug Class\",\n",
    "#              \"vocabularyCodes\": [\n",
    "#                 \"MTH/NOCODE\",\n",
    "#                 \"VANDF/4021631\"\n",
    "#              ]\n",
    "#           }\n",
    "#        ],\n",
    "#        \"relationships\": [\n",
    "#           {\n",
    "#              \"subjectId\": \"1\",\n",
    "#              \"objectId\": \"2\",\n",
    "#              \"confidence\": 0.9996469616889954\n",
    "#           },\n",
    "#           {\n",
    "#              \"subjectId\": \"1\",\n",
    "#              \"objectId\": \"3\",\n",
    "#              \"confidence\": 0.9995671510696411\n",
    "#           }\n",
    "#        ]\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bdf14-0a1b-48db-a0f8-9d9604c16a31",
   "metadata": {},
   "source": [
    "#  Step 02:  (continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d557b-990a-4e72-bcb1-3cbcfdcbf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Run the above Web service against our first DataFrame\n",
    "#\n",
    "\n",
    "#  Recall df_PatientVisitNodes contains,\n",
    "#\n",
    "#     id|medical_specialty|sample_name|description|body|body_1line\n",
    "#\n",
    "\n",
    "\n",
    "df_enriched = pd.DataFrame(columns = [\"id\", \"enrich_from_Google\"])\n",
    "\n",
    "\n",
    "for l_each in df_ReportNodes.itertuples():\n",
    "   print(\"Processing id: %d\" % (l_each.id))\n",
    "      #\n",
    "   l_response = f_enrich(l_each.body_1line)\n",
    "   l_data_asjson = json.loads(l_response.content) \n",
    "\n",
    "   df_enriched = df_enriched.append({\"id\" : l_each.id, \"enrich_from_Google\" : l_data_asjson}, ignore_index = True)\n",
    "    \n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in df_enriched.itertuples():\n",
    "   l_cntr += 1\n",
    "      #\n",
    "   if (l_cntr < 5):\n",
    "      print(\"Record number: %d   Short text: %s\" % (l_each.id, str(l_each.enrich_from_Google)[0:60]))\n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Processing id: 4001\n",
    "#     Processing id: 4002\n",
    "#     Processing id: 4003\n",
    "#        ...\n",
    "#         \n",
    "#     Record number: 4001   Short text: {'error': {'code': 400, 'message': \"Invalid JSON payload rec\n",
    "#     Record number: 4002   Short text: {'entityMentions': [{'mentionId': '1', 'type': 'PROBLEM', 't\n",
    "#     Record number: 4003   Short text: {'entityMentions': [{'mentionId': '1', 'type': 'PROBLEM', 't\n",
    "#     Record number: 4004   Short text: {'entityMentions': [{'mentionId': '1', 'type': 'PROBLEM', 't\n",
    "#     \n",
    "#     --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ad011-1bf5-4242-b93a-7480745e6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Write this out to a file\n",
    "#\n",
    "\n",
    "l_file = \"./10_Data/23_22_PlusGoogle.txt\"\n",
    "\n",
    "df_enriched.to_csv(l_file, sep = \"|\", encoding = \"utf-8\", index = False)\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e4efe-569f-4b16-82aa-a4ada5bfb099",
   "metadata": {},
   "source": [
    "# Step 03:  Extract actual field data from the JSON Google gave us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2583d8-e087-440c-9ffb-9916bb5e6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  The model for the df_enriched DataFrame is,\n",
    "#     id|enrich_from_Google\n",
    "#\n",
    "#     with the second column being a JSON encoded string with its own model.\n",
    "#\n",
    "#  Here we loop thru said DataFrme, and make our resultant Nodes and Edges\n",
    "#  for our graph.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "l_NumOfBadJson              = 0\n",
    "l_NumOfRootKeyNotFound      = 0\n",
    "   #\n",
    "l_UmlsEntityNodes           = []\n",
    "l_UmlsVocabularyNodes       = []\n",
    "   #\n",
    "l_PatientVisitToEntityEdge  = []\n",
    "l_EntityToVocabularyEdge    = []\n",
    "\n",
    "\n",
    "for l_each in df_enriched.itertuples():\n",
    "    \n",
    "   #  Before we cleaned up all of the JSON (random single quotes for possesive nouns,\n",
    "   #  other), we would get errors similar to,\n",
    "   #\n",
    "   #      4001|\"{'error': {'code': 400, 'message': \"\"Invalid JSON payload received. Expected , or } after key:value pair.\\naced\n",
    "   #         on the patient's skin or on the imm\\n                    ^\"\", 'status': 'INVALID_ARGUMENT'}}\"\n",
    "   #\n",
    "   #  Upon receipt of this condition, a root level key with the title \"error\" would be\n",
    "   #  present. If those return, filter those out-\n",
    "   #\n",
    "   if (\"error\" in l_each.enrich_from_Google):\n",
    "      l_NumOfBadJson += 1\n",
    "    \n",
    "   else:\n",
    "      #\n",
    "      #  \"entities\" should be a root level key to this dictionary\n",
    "      #\n",
    "      if (\"entities\" in l_each.enrich_from_Google):\n",
    "         #\n",
    "         #  Loop thru these\n",
    "         #\n",
    "         for l_entity in l_each.enrich_from_Google[\"entities\"]:\n",
    "            if (\"entityId\" in l_entity):\n",
    "               #\n",
    "               #  Build a dictionary that we will append to a set\n",
    "               #\n",
    "               l_recd1 = { \"id\": l_entity[\"entityId\"], \"entityId\" : l_entity[\"entityId\"], \"LABEL\": \"UmlsEntity\" }\n",
    "               #\n",
    "               #  If this key is present, add it to the dictionary\n",
    "               #\n",
    "               if (\"preferredTerm\" in l_entity):\n",
    "                  #\n",
    "                  #  We have both keys, build a record and add to our sets\n",
    "                  #\n",
    "                  l_recd1.update( {\"preferredTerm\": l_entity[\"preferredTerm\"]} )\n",
    "                     #\n",
    "               l_UmlsEntityNodes.append(l_recd1)\n",
    "               #\n",
    "               #  Above was our list of Nodes of LABEL \"UmlsEntity\"\n",
    "               #  \n",
    "               #  Here we make our Edge list from;  PatientVisit --> UmlsEntity\n",
    "               #\n",
    "               l_recd2a = { \"start_id\": str(l_each.id), \"end_id\":   str(l_entity[\"entityId\"])  , \"TYPE\": \"VISIT_CONTAINS\" }\n",
    "               l_recd2b = { \"end_id\":   str(l_each.id), \"start_id\": str(l_entity[\"entityId\"], \"TYPE\": \"VISIT_CONTAINS\" }\n",
    "                  #\n",
    "               l_PatientVisitToEntityEdge.append(l_recd2a)\n",
    "               l_PatientVisitToEntityEdge.append(l_recd2b)\n",
    "               #\n",
    "               #  We are done with UmlsEntity and its Edge to PatientVisit\n",
    "               #\n",
    "               #  Also in \"entities\" is another array, \"vocabularyCodes\"\n",
    "               #\n",
    "               if (\"vocabularyCodes\" in l_entity):\n",
    "                  for l_vocab in l_entity[\"vocabularyCodes\"]:\n",
    "                     #\n",
    "                     #  Add to our set of Vocabulary Nodes\n",
    "                     #\n",
    "                     l_recd3 = { \"id\": l_vocab, \"vocabularyCode\": l_vocab, \"LABEL\": \"UmlsVocabulary\" }\n",
    "                        #\n",
    "                     l_UmlsVocabularyNodes.append(l_recd3)\n",
    "                     #\n",
    "                     #  And create the Edge from UmlsEntity --> UmlsVocabulary\n",
    "                     #\n",
    "                     l_recd4a = { \"start_id\": l_entity[\"entityId\"], \"end_id\":   l_vocab, \"TYPE\": \"ALSO_CODED_AS\" }\n",
    "                     l_recd4b = { \"end_id\":   l_entity[\"entityId\"], \"start_id\": l_vocab, \"TYPE\": \"ALSO_CODED_AS\" }\n",
    "                        #\n",
    "                     l_EntityToVocabularyEdge.append(l_recd4a)\n",
    "                     l_EntityToVocabularyEdge.append(l_recd4b)\n",
    "            else:\n",
    "               #\n",
    "               #  No \"entityId\" in our record. This has never happened.\n",
    "               #  We wont report, just pass.\n",
    "               #\n",
    "               pass\n",
    "            \n",
    "      else:\n",
    "         l_NumOfRootKeyNotFound += 1\n",
    "            \n",
    "            \n",
    "   ###\n",
    "\n",
    "\n",
    "print(\"Number of 'Error' input records: %d   Number of 'No Root Key' input records: %d\" % ( l_NumOfBadJson, l_NumOfRootKeyNotFound) )\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#  l_UmlsEntityNodes, l_UmlsVocabularyNodes, l_PatientVisitToEntityEdge, and l_EntityToVocabularyEdge\n",
    "#     are currently arrays, and have duplicate records.\n",
    "#\n",
    "#  Arguably; these should have been sets(), [ then ] made into arrays or DataFrames.\n",
    "#     (Memory versus CPU. And .. .. two processing lops versus one.)\n",
    "#\n",
    "#  Convert these to DataFrames and remove duplicates\n",
    "#\n",
    "\n",
    "df_UmlsEntityNodes           = pd.DataFrame.from_records(l_UmlsEntityNodes          ).drop_duplicates()\n",
    "df_UmlsVocabularyNodes       = pd.DataFrame.from_records(l_UmlsVocabularyNodes      ).drop_duplicates()\n",
    "   #\n",
    "df_PatientVisitToEntityEdge  = pd.DataFrame.from_records(l_PatientVisitToEntityEdge ).drop_duplicates()\n",
    "df_EntityToVocabularyEdge    = pd.DataFrame.from_records(l_EntityToVocabularyEdge   ).drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"Number of PatientVisit nodes: %d   UmlsEntity nodes: %d   UmlsVocabulary nodes: %d\" % ( len(df_PatientVisitNodes), len(df_UmlsEntityNodes), len(df_UmlsVocabularyNodes) ))\n",
    "print(\"\")\n",
    "print(\"Edges PatientVisit --> UmlsEntity: %d   UmlsEntity --> UmlsVocabulary: %d\" % ( len(df_PatientVisitToEntityEdge), len(df_EntityToVocabularyEdge) ))\n",
    "print(\"\")\n",
    "\n",
    "print(\"--\")    \n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Number of 'Error' input records: 0   Number of 'No Root Key' input records: 0\n",
    "#     \n",
    "#     Number of PatientVisit nodes: 90   UmlsEntity nodes: 3115   UmlsVocabulary nodes: 8860\n",
    "#     \n",
    "#     Edges PatientVisit --> UmlsEntity: 16958   UmlsEntity --> UmlsVocabulary: 21952\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d95ad-27ae-4dfa-ad2d-27ba92d2dbb8",
   "metadata": {},
   "source": [
    "#  Step 04: Create the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0adb1735-4a5d-496a-bab4-da806a7624b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dtype for DataFrame column 'medical_specialty' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'sample_name' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'description' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'body' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'body_1line' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'LABEL' is 'object'. Will be inferred as string.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa8172a8b424a7db34aa4fe6d828206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d976a07ffd40bebb10167b621870ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dtype for DataFrame column 'entityId' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'preferredTerm' is 'object'. Will be inferred as string.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37dc6d138fa4bc48b58217eca1c1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ecdea81a954869b1b3aaacab76535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dtype for DataFrame column 'vocabularyCode' is 'object'. Will be inferred as string.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6596507a5e1a45df87c4d285d69b2ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811b7bcd09aa48d4bad9ab6b3d086b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dtype for DataFrame column 'TYPE' is 'object'. Will be inferred as string.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d8df46bd142f7ad4b3af684fc8186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Host 0 errors:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py\", line 86, in execute\n",
      "    value = function(graph)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py\", line 453, in remote_write_intermediate_parquet_files\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py\", line 208, in _write_intermediate_parquet_files\n",
      "    edge_header = \"\\n\".join(_write_dfs_to_parquet(edge_df_infos, \"edges\"))\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py\", line 201, in _write_dfs_to_parquet\n",
      "    dask.dataframe.to_parquet(\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 963, in to_parquet\n",
      "    out = out.compute(**compute_kwargs)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/base.py\", line 315, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/base.py\", line 598, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 3036, in get\n",
      "    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 2210, in gather\n",
      "    return self.sync(\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 338, in sync\n",
      "    return sync(\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 405, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py\", line 378, in f\n",
      "    result = yield future\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/distributed/client.py\", line 2073, in _gather\n",
      "    raise exception.with_traceback(traceback)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/optimization.py\", line 990, in __call__\n",
      "    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/core.py\", line 149, in get\n",
      "    result = _execute_task(task, cache)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\n",
      "    return func(*(_execute_task(a, cache) for a in args))\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 163, in __call__\n",
      "    return self.engine.write_partition(\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py\", line 686, in write_partition\n",
      "    t = cls._pandas_to_arrow_table(df, preserve_index=preserve_index, schema=schema)\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py\", line 640, in _pandas_to_arrow_table\n",
      "    df_schema = pa.Schema.from_pandas(df)\n",
      "  File \"pyarrow/types.pxi\", line 1460, in pyarrow.lib.Schema.from_pandas\n",
      "    names, types, metadata = dataframe_to_types(\n",
      "  File \"/opt/miniconda/lib/python3.8/site-packages/pyarrow/pandas_compat.py\", line 534, in dataframe_to_types\n",
      "    type_ = pa.array(c, from_pandas=True).type\n",
      "  File \"pyarrow/array.pxi\", line 311, in pyarrow.lib.array\n",
      "    return _ndarray_to_array(values, mask, type, c_from_pandas, safe,\n",
      "  File \"pyarrow/array.pxi\", line 83, in pyarrow.lib._ndarray_to_array\n",
      "    check_status(NdarrayToArrow(pool, values, mask, from_pandas,\n",
      "  File \"pyarrow/error.pxi\", line 99, in pyarrow.lib.check_status\n",
      "    raise ArrowInvalid(message)\n",
      "pyarrow.lib.ArrowInvalid: Could not convert 'UMLS/C0877488' with type str: tried to convert to int64\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not convert 'UMLS/C0877488' with type str: tried to convert to int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [118], line 55\u001b[0m\n\u001b[1;32m     46\u001b[0m    df_importer\u001b[38;5;241m.\u001b[39medges_dataframe(\n\u001b[1;32m     47\u001b[0m       df_PatientVisitToEntityEdge, \n\u001b[1;32m     48\u001b[0m       source_id_space       \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatientVisit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[38;5;28mtype\u001b[39m                  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVISIT_CONTAINS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m       )\n\u001b[1;32m     54\u001b[0m    df_importer\u001b[38;5;241m.\u001b[39mnode_id_property_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)                        \u001b[38;5;66;03m#  This line is required when you are not inserting any Nodes, only Edges\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m    df_importer\u001b[38;5;241m.\u001b[39minsert()\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m import_data\u001b[38;5;241m.\u001b[39mDataFrameImporter(my_graph) \u001b[38;5;28;01mas\u001b[39;00m df_importer:   \n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py:467\u001b[0m, in \u001b[0;36mDataFrameImporter.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exc_type:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py:457\u001b[0m, in \u001b[0;36mDataFrameImporter.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m work_fun(graph, node_df_infos, edge_df_infos)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m node_header, edge_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote_write_intermediate_parquet_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_import_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_info, node_header, edge_header)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:249\u001b[0m, in \u001b[0;36mAsyncToSync.<locals>.do_wrap.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(underlying_func)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[0;32m--> 249\u001b[0m         \u001b[43munderlying_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_self_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:176\u001b[0m, in \u001b[0;36masync_to_sync.<locals>.wrapper\u001b[0;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     registry \u001b[38;5;241m=\u001b[39m AsyncToSyncClassRegistry\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[1;32m    168\u001b[0m         wait_for(\n\u001b[1;32m    169\u001b[0m             async_func(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:147\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(coro, timeout)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(timeout_coro, loop\u001b[38;5;241m=\u001b[39mAsyncRunnerThread\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mloop)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     inner_future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/asyncio/tasks.py:455\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    450\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe loop argument is deprecated since Python 3.8, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand scheduled for removal in Python 3.10.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    458\u001b[0m     fut \u001b[38;5;241m=\u001b[39m ensure_future(fut, loop\u001b[38;5;241m=\u001b[39mloop)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:527\u001b[0m, in \u001b[0;36mGraph.run\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstdout, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstderr, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/run_result.py:21\u001b[0m, in \u001b[0;36mRunResult.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuccess\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/run_result.py:17\u001b[0m, in \u001b[0;36mRunResult.reraise_if_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise_if_error\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py:128\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/worker/worker.py:86\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py:453\u001b[0m, in \u001b[0;36mremote_write_intermediate_parquet_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MPI\u001b[38;5;241m.\u001b[39mCOMM_WORLD\u001b[38;5;241m.\u001b[39mGet_rank() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dask_integration\u001b[38;5;241m.\u001b[39mclient():\n\u001b[0;32m--> 453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m work_fun(graph, node_df_infos, edge_df_infos)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py:208\u001b[0m, in \u001b[0;36m_write_intermediate_parquet_files\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/katana_enterprise/remote/dataframe_importer/__init__.py:201\u001b[0m, in \u001b[0;36m_write_dfs_to_parquet\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:963\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/base.py:598\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/client.py:3036\u001b[0m, in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/client.py:2210\u001b[0m, in \u001b[0;36mgather\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:338\u001b[0m, in \u001b[0;36msync\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:405\u001b[0m, in \u001b[0;36msync\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/utils.py:378\u001b[0m, in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/distributed/client.py:2073\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:163\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:686\u001b[0m, in \u001b[0;36mwrite_partition\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:640\u001b[0m, in \u001b[0;36m_pandas_to_arrow_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/types.pxi:1460\u001b[0m, in \u001b[0;36mpyarrow.lib.Schema.from_pandas\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1458\u001b[0m \"\"\"\n\u001b[1;32m   1459\u001b[0m from pyarrow.pandas_compat import dataframe_to_types\n\u001b[0;32m-> 1460\u001b[0m names, types, metadata = dataframe_to_types(\n\u001b[1;32m   1461\u001b[0m     df,\n\u001b[1;32m   1462\u001b[0m     preserve_index=preserve_index\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.8/site-packages/pyarrow/pandas_compat.py:534\u001b[0m, in \u001b[0;36mdataframe_to_types\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/array.pxi:311\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m             values, type = pandas_api.compat.get_datetimetz_type(\n\u001b[1;32m    310\u001b[0m                 values, obj.dtype, type)\n\u001b[0;32m--> 311\u001b[0m         return _ndarray_to_array(values, mask, type, c_from_pandas, safe,\n\u001b[1;32m    312\u001b[0m                                  pool)\n\u001b[1;32m    313\u001b[0m else:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m     with nogil:\n\u001b[0;32m---> 83\u001b[0m         check_status(NdarrayToArrow(pool, values, mask, from_pandas,\n\u001b[1;32m     84\u001b[0m                                     c_type, cast_options, &chunked_out))\n\u001b[1;32m     85\u001b[0m \n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/error.pxi:99\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m         if status.IsInvalid():\n\u001b[0;32m---> 99\u001b[0m             raise ArrowInvalid(message)\n\u001b[1;32m    100\u001b[0m         elif status.IsIOError():\n\u001b[1;32m    101\u001b[0m             # Note: OSError constructor is\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not convert 'UMLS/C0877488' with type str: tried to convert to int64"
     ]
    }
   ],
   "source": [
    "\n",
    "#  At this point we have several Pandas DataFrames; import them into the graph-\n",
    "#\n",
    "#     Why use Pandas DataFrames versus Dask ?\n",
    "#     \n",
    "#     .  The data is small enough\n",
    "#     .  Dask DataFrames currently (beta) have to be sourced from a shared/public drive\n",
    "#\n",
    "\n",
    "\n",
    "from katana.remote import import_data\n",
    "\n",
    "\n",
    "#  Just nodes\n",
    "#\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "   df_importer.nodes_dataframe(\n",
    "      df_PatientVisitNodes,\n",
    "      id_column             = \"id\",\n",
    "      id_space              = \"PatientVisit\",  \n",
    "      label                 = \"PatientVisit\",  \n",
    "      ) \n",
    "   df_importer.insert()\n",
    "      #\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "   df_importer.nodes_dataframe(\n",
    "      df_UmlsEntityNodes,\n",
    "      id_column             = \"id\",\n",
    "      id_space              = \"UmlsEntity\",  \n",
    "      label                 = \"UmlsEntity\",  \n",
    "      ) \n",
    "   df_importer.insert()\n",
    "      #\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "   df_importer.nodes_dataframe(\n",
    "      df_UmlsVocabularyNodes,\n",
    "      id_column             = \"id\",\n",
    "      id_space              = \"UmlsVocabulary\",  \n",
    "      label                 = \"UmlsVocabulary\",  \n",
    "      ) \n",
    "   df_importer.insert()\n",
    "    \n",
    "\n",
    "#  Just edges\n",
    "#\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "   df_importer.edges_dataframe(\n",
    "      df_PatientVisitToEntityEdge, \n",
    "      source_id_space       = \"PatientVisit\", \n",
    "      destination_id_space  = \"UmlsEntity\",   \n",
    "      source_column         = \"start_id\",\n",
    "      destination_column    = \"end_id\",\n",
    "      type                  = \"VISIT_CONTAINS\"\n",
    "      )\n",
    "   df_importer.node_id_property_name(\"id\")                        #  This line is required when you are not inserting any Nodes, only Edges\n",
    "   df_importer.insert()\n",
    "      #\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "   df_importer.edges_dataframe(\n",
    "      df_EntityToVocabularyEdge, \n",
    "      source_id_space       = \"UmlsEntity\", \n",
    "      destination_id_space  = \"UmlsVocabulary\",   \n",
    "      source_column         = \"start_id\",\n",
    "      destination_column    = \"end_id\",\n",
    "      type                  = \"ALSO_CODED_AS\"\n",
    "      )\n",
    "   df_importer.node_id_property_name(\"id\")\n",
    "   df_importer.insert()\n",
    "\n",
    "\n",
    "      ###\n",
    "\n",
    "\n",
    "display(\"Number of nodes: %d   Numbers of edges: %d\" % ( my_graph.num_nodes(), my_graph.num_edges() ))\n",
    "\n",
    "\n",
    "display(\"--\")\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8940fa22-7b5e-4181-87dc-b4a871ee92b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256ddd2988e74816bb4356bc703cdce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c2942b89d644ff8cb2f7ff9e9a5775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of nodes: 12065   Numbers of edges: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30796d4e-2cba-46da-bf2d-8cf3ce54cfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fb83f5a8b243c584e32afe0078d558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f16423713b41f58a187562eea2a3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7317f58375f4f98b07a1dc1900a0409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n                <style>\\n                #jp-main-content-panel .widget-container"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  Produce a visual graph\n",
    "\n",
    "from katana_visualization_widget import GraphVisOptions, NodeVisOption, EdgeVisOption, ANY\n",
    "\n",
    "l_options = GraphVisOptions(\n",
    "   node_options = [\n",
    "      NodeVisOption(\"PatientVisit\",   label=\"sample_name\"),\n",
    "      NodeVisOption(\"UmlsEntity\",     label=\"id\"         ),\n",
    "      NodeVisOption(\"UmlsVocabulary\", label=\"id\"         ),\n",
    "   ],\n",
    "   #  edge_options = [\n",
    "   #     EdgeVisOption([\"VISIT_CONTAINS\"], label=\"start_id\"),\n",
    "   #     EdgeVisOption([\"ALSO_CODED_AS\" ], label=\"start_id\"),\n",
    "   #  ]\n",
    "   )\n",
    "    \n",
    "    \n",
    "l_result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (n) -[r]-> (m)\n",
    "   RETURN n, r, m\n",
    "   LIMIT 1000 \n",
    "   \n",
    "   \"\"\",\n",
    "   contextualize=True)\n",
    "\n",
    "l_result.view(graph_vis_options = l_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff60c8-7de5-4331-afd0-463d952c3bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599094b9-6ebe-49f2-beb2-39933e47b151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56955d-ffef-4689-a702-1021fcdb0147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3027f-9c70-482a-ae96-b0c1864a04bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4a44c-9d89-4306-b8c0-67156a79a537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337d260-8583-41fc-9300-e9994520cda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d607abb-6e9b-4dfd-9b10-302c237556d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
