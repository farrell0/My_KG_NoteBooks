{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd734fb-dcb6-4a16-ae8c-6ee9f4b05bd5",
   "metadata": {},
   "source": [
    "#  Setup: Display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da2499e-334d-496d-aa84-4fc08ce2ae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4674af-762d-43ec-9d7e-775595cee62b",
   "metadata": {},
   "source": [
    "# Setup: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f636dd5-2ed0-453c-b288-4a01b0f213ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Settings:\n",
    "#     Need a public or private accessible storage bucket on GCP or similar ..\n",
    "#\n",
    "#  From,\n",
    "#     https://stackoverflow.com/questions/36314797/write-a-pandas-dataframe-to-google-cloud-storage-or-bigquery\n",
    "#     https://stackoverflow.com/questions/29325458/dictionary-column-in-pandas-dataframe/29325954#29325954\n",
    "\n",
    "import os\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "print (\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3303c0a-12e9-4494-b639-5d29e9ce3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Setup for all work below ..\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/jovyan/work/03_MyKeys.json\"\n",
    "\n",
    "l_bucket = \"farrell-bucket\"\n",
    "\n",
    "\n",
    "g_client = storage.Client()\n",
    "   #\n",
    "g_bucket = g_client.get_bucket(l_bucket)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd9b8c-3204-4532-8fcc-0ef5fd36fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e24b74-89d3-431f-9211-fb476862852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715c6f6-137c-429e-8c17-7a1d538c543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS = 3\n",
    "   #\n",
    "DB_NAME        = \"my_db\"\n",
    "GRAPH_NAME     = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e2de2-37d5-4f7a-87ba-f3f16c4bb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c2775-1192-42dd-97e3-4a0b9a82f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE DATABASE\n",
    "#\n",
    "#  repeat execution throws error\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e99ffa-3486-4fad-ae89-f2024c92c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE GRAPH\n",
    "#\n",
    "my_graph = my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=2)\n",
    "\n",
    "print(my_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc62ca8-9ea1-4a82-82f9-743dc58e3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf0bb7-2c70-47e7-aee8-81ee7208f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19027cb8-5793-45e1-a316-fcbc0bf2bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce860d08-fc15-4273-89dc-372b22ad9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3e21b-5214-471f-8ff4-8641cfac811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We need a header/schema file to import into a graph ..\n",
    "\n",
    "df_h = pd.DataFrame([\n",
    "   [\"KATANA_DEFAULT_LABEL=Node1\"                       ],\n",
    "   [\"id:ID(Node1)|name:STRING|other:STRING|city:STRING\"],\n",
    "   [\"load_test/node.parquet\"                          ],\n",
    "   ], columns = [\"Col_A\"])\n",
    "\n",
    "l_SchemaFile = \"load_test/test_header.P.txt\"\n",
    "\n",
    "g_bucket.blob(l_SchemaFile).upload_from_string(df_h.to_csv(header=None, index=None, sep=\" \"), \"text/plain\")\n",
    "\n",
    "\n",
    "df_h = pd.DataFrame([\n",
    "   [\"KATANA_DEFAULT_LABEL=Node1\"                       ],\n",
    "   [\"id:ID(Node1)|name:STRING|other:STRING|city:STRING\"],\n",
    "   [\"load_test/node.txt\"                               ],\n",
    "   ], columns = [\"Col_A\"])\n",
    "\n",
    "l_SchemaFile = \"load_test/test_header.C.txt\"\n",
    "\n",
    "g_bucket.blob(l_SchemaFile).upload_from_string(df_h.to_csv(header=None, index=None, sep=\" \"), \"text/plain\")\n",
    "\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726ec52-c645-4bbe-81c4-9f19f6ae9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Simple data ..\n",
    "\n",
    "#  Set (i = 0) for a given data set, set to (i = 1) for a second data set\n",
    "#  (Used to test updates, after initial load, other)\n",
    "\n",
    "i = 0\n",
    "# i = 1\n",
    "\n",
    "if (i == 0):\n",
    "   df = pd.DataFrame([\n",
    "      [101, \"Abhi\"      , \"Katana\"                , 'NY'     ],\n",
    "      [102, \"Justin\"    , \"Katana\"                , 'LA'     ],\n",
    "      [103, \"Brian\"     , \"Katana\"                , 'Denver' ],\n",
    "      [104, \"Thomas\"    , \"Katana\"                , 'Denver' ],\n",
    "      [105, \"Anand\"     , \"Katana\"                , 'Denver' ],\n",
    "      [106, \"Josh\"      , \"Katana\"                , 'Denver' ],\n",
    "      [107, \"Andrew\"    , \"Katana\"                , 'Denver' ],\n",
    "      [108, \"Seb\"       , \"Katana\"                , 'Denver' ],\n",
    "      [109, \"Mary\"      , \"Katana\"                , 'Denver' ],\n",
    "      [100, \"Pahola\"    , \"Katana\"                , 'Denver' ],\n",
    "      ], columns = ['Col A', 'Col B', 'Col C', 'Col D'])\n",
    "else:\n",
    "   df = pd.DataFrame([\n",
    "      [201, \"Abhi 2\"    , \"Katana\"                , 'NY'     ],\n",
    "      [202, \"Justin 2\"  , \"Katana\"                , 'LA'     ],\n",
    "      [203, \"Brian 2\"   , \"Katana\"                , 'Denver' ],\n",
    "      [204, \"Thomas 2\"  , \"Katana\"                , 'Denver' ],\n",
    "      [205, \"Anand 2\"   , \"Katana\"                , 'Denver' ],\n",
    "      [206, \"Josh 2\"    , \"Katana\"                , 'Denver' ],\n",
    "      [207, \"Andrew 2\"  , \"Katana\"                , 'Denver' ],\n",
    "      [208, \"Seb 2\"     , \"Katana\"                , 'Denver' ],\n",
    "      [209, \"Mary 2\"    , \"Katana\"                , 'Denver' ],\n",
    "      [200, \"Pahola 2\"  , \"Katana\"                , 'Denver' ],\n",
    "      ], columns = ['Col A', 'Col B', 'Col C', 'Col D'])  \n",
    "\n",
    "\n",
    "l_file = \"load_test/node.parquet\"\n",
    "   #\n",
    "g_bucket.blob(l_file).upload_from_string(df.to_parquet(engine=\"pyarrow\", version=\"2.6\"), \"application/octet-stream\")\n",
    "\n",
    "l_file = \"load_test/node.txt\"\n",
    "   #\n",
    "g_bucket.blob(l_file).upload_from_string(df.to_csv(header=None, index=None, sep=\"|\"), \"text/plain\")\n",
    "\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23688a7-1c07-402f-b33f-eee125e989c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Simple test, read output from above ..\n",
    "\n",
    "#  Set (i = P) for Parquet, (i = C) for CSV\n",
    "\n",
    "# i = \"P\"\n",
    "i = \"C\"\n",
    "\n",
    "if (i == \"P\"):\n",
    "   l_file = \"load_test/node.parquet\"\n",
    "      #\n",
    "   l_InputFile  = \"gs://\" + l_bucket + \"/\" + l_file\n",
    "      #\n",
    "   l_df = pd.read_parquet(l_InputFile)\n",
    "else:\n",
    "   l_file = \"load_test/node.txt\"\n",
    "      #\n",
    "   l_InputFile  = \"gs://\" + l_bucket + \"/\" + l_file\n",
    "      #\n",
    "   l_df = pd.read_csv(l_InputFile, delimiter = \"|\", header = None)\n",
    "\n",
    "\n",
    "l_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953b9a5-e072-4bb9-b565-2c8a80daba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Below is the key cell ..\n",
    "#\n",
    "#   .  Upsert when new graph does work\n",
    "#      Repeat the upsert, (so now data is present) and it fails\n",
    "#\n",
    "#   .  Basically any new data only situation below works\n",
    "#      Any work on existing data will fail\n",
    "#\n",
    "#      Update on very same data (so no actual updating), works\n",
    "#\n",
    "#   .  And strangely, delete works on existing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17c13-989d-476b-a094-c9150beef16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Make a graph from all above ..\n",
    "\n",
    "\n",
    "#  Set (i = P) to load Parquet into graph, (i = C) to load from CSV \n",
    "\n",
    "# i = \"P\"\n",
    "i = \"C\"\n",
    "\n",
    "\n",
    "l_data = \"gs://\" + l_bucket \n",
    "\n",
    "\n",
    "if (i == \"P\"):\n",
    "   l_inp  = \"gs://\" + l_bucket + \"/load_test/test_header.P.txt\"\n",
    "      #\n",
    "   import_data.parquet(\n",
    "      my_graph,\n",
    "      input_node_path=l_inp,\n",
    "      input_dir=l_data,\n",
    "      schema_delimiter=\"|\",\n",
    "      ids_are_integers=True,\n",
    "      operation=import_data.Operation.Insert,\n",
    "      # operation=import_data.Operation.Delete,\n",
    "      # operation=import_data.Operation.Update,\n",
    "      # operation=import_data.Operation.Upsert,\n",
    "      )\n",
    "else:\n",
    "   l_inp  = \"gs://\" + l_bucket + \"/load_test/test_header.C.txt\"\n",
    "      #\n",
    "   import_data.csv(\n",
    "      my_graph,\n",
    "      input_node_path=l_inp,\n",
    "      input_dir=l_data,\n",
    "      schema_delimiter=\"|\",\n",
    "      data_delimiter = \"|\",\n",
    "      ids_are_integers=True,\n",
    "      files_have_headers = False,\n",
    "         #\n",
    "      # operation=import_data.Operation.Insert,\n",
    "      # operation=import_data.Operation.Delete,\n",
    "      # operation=import_data.Operation.Update,\n",
    "      operation=import_data.Operation.Upsert,\n",
    "      )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d0211-c9f0-4b77-945b-8c9e413b4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4b7c9-0f9e-474b-9992-f4d0c25cfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert my_graph.num_nodes() == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21f954-a012-45f1-be1b-18a0780e602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (n)\n",
    "   RETURN n\n",
    "   \n",
    "   \"\"\")\n",
    "\n",
    "print(l_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
