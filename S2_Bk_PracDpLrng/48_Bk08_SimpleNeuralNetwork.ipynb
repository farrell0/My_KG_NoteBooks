{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data sets ..\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Exception reporting mode: Minimal\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "#  **  You must run this cell to do much of anything in this NoteBook\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909c6ac-eef4-42ea-af33-cfda0b6d5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries are imported below, but ..\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+-----------------+\n",
      "|   sl |   sw |   pl |   pw |   class_encoded |\n",
      "|------+------+------+------+-----------------|\n",
      "|  6.8 |  2.8 |  4.8 |  1.4 |               1 |\n",
      "|  4.6 |  3.1 |  1.5 |  0.2 |               0 |\n",
      "|  5   |  2.3 |  3.3 |  1   |               1 |\n",
      "|  6.5 |  3   |  5.2 |  2   |               2 |\n",
      "|  6.5 |  2.8 |  4.6 |  1.5 |               1 |\n",
      "+------+------+------+------+-----------------+\n",
      "Number of rows: 149\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     |   sl |   sw |   pl |   pw |   class_encoded |\n",
    "#     |------+------+------+------+-----------------|\n",
    "#     |  5.5 |  2.4 |  3.8 |  1.1 |               1 |\n",
    "#     |  6.4 |  3.2 |  4.5 |  1.5 |               1 |\n",
    "#     |  6.8 |  3.2 |  5.9 |  2.3 |               2 |\n",
    "#     |  6.7 |  3.3 |  5.7 |  2.1 |               2 |\n",
    "#     |  5.5 |  2.6 |  4.4 |  1.2 |               1 |\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     Number of rows: 149\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total       rows... 149   Training rows: 119   Test rows: 30\n",
      "\n",
      "Number of total (1-2) rows... 100   Training rows: 78   Test rows: 22\n",
      "\n",
      "Train data:\n",
      "[[6.1 2.9 4.7 1.4 1]\n",
      " [7.2 3 5.8 1.6 2]\n",
      " [5.8 2.8 5.1 2.4 2]\n",
      " [6.3 2.3 4.4 1.3 1]\n",
      " [6.4 2.8 5.6 2.1 2]]\n",
      "\n",
      "Test  data:\n",
      "[[5.8 2.7 4.1 1 1]\n",
      " [6.5 3 5.5 1.8 2]\n",
      " [7.7 2.6 6.9 2.3 2]\n",
      " [5.5 2.6 4.4 1.2 1]\n",
      " [6.3 3.4 5.6 2.4 2]]\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml code we use later expect that.\n",
    "#  We only want two of the classes, 1 and 2.\n",
    "#\n",
    "#     Why this data ?  It was harder to predict; see the plot below.\n",
    "#\n",
    "\n",
    "\n",
    "#  l_dtype = {\"names\": [\"f1\", \"f2\", \"f3\", \"f4\", \"class_encoded\"],                     #  Wound up not needing this\n",
    "#     \"formats\": [float, float, float, float, float]}\n",
    "#        #\n",
    "#  np_iris[\"train\"].dtype = l_dtype\n",
    "#  np_iris[\"test\" ].dtype = l_dtype\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "\n",
    "\n",
    "np_iris[\"train_12\"] = np.copy(np_iris[\"train\"])                                       #  Copy, then filter\n",
    "np_iris[\"test_12\" ] = np.copy(np_iris[\"test\" ])\n",
    "   #\n",
    "np_iris[\"train_12\"] = np_iris[\"train\"][ ( np_iris[\"train\"][:, -1] > 0) & ( np_iris[\"train\"][:, -1] < 3) ]\n",
    "np_iris[\"test_12\" ] = np_iris[\"test\" ][ ( np_iris[\"test\" ][:, -1] > 0) & ( np_iris[\"test\" ][:, -1] < 3) ]\n",
    "\n",
    "\n",
    "\n",
    "#   a[ (-6<a[:,1]) & (a[:,1]<3) ]\n",
    "\n",
    "\n",
    "print(\"Number of total       rows... %d   Training rows: %d   Test rows: %d\" %        #  Outputs for confirmation\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "print()\n",
    "print(\"Number of total (1-2) rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  ( len(np_iris[\"train_12\"]) + len(np_iris[\"test_12\"]),\n",
    "    len(np_iris[\"train_12\"]), len(np_iris[\"test_12\"]) ) ) \n",
    "print()\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train_12\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test_12\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     Number of total       rows... 149   Training rows: 119   Test rows: 30\n",
    "#     \n",
    "#     Number of total (1-2) rows... 100   Training rows: 78   Test rows: 22\n",
    "#     \n",
    "#     Train data:\n",
    "#     [[6.1 2.9 4.7 1.4 1]\n",
    "#      [7.2 3 5.8 1.6 2]\n",
    "#      [5.8 2.8 5.1 2.4 2]\n",
    "#      [6.3 2.3 4.4 1.3 1]\n",
    "#      [6.4 2.8 5.6 2.1 2]]\n",
    "#     \n",
    "#     Test  data:\n",
    "#     [[5.8 2.7 4.1 1 1]\n",
    "#      [6.5 3 5.5 1.8 2]\n",
    "#      [7.7 2.6 6.9 2.3 2]\n",
    "#      [5.5 2.6 4.4 1.2 1]\n",
    "#      [6.3 3.4 5.6 2.4 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  Plot of just two features from the two class data set\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(np_iris[\"train_12\"][np_iris[\"train_12\"][:, -1]==1][:, 2], np_iris[\"train_12\"][np_iris[\"train_12\"][:, -1]==1][:, 3], c = \"red\"  , label = \"Class 1\", marker = \".\")\n",
    "plt.scatter(np_iris[\"train_12\"][np_iris[\"train_12\"][:, -1]==2][:, 2], np_iris[\"train_12\"][np_iris[\"train_12\"][:, -1]==2][:, 3], c = \"blue\" , label = \"Class 2\", marker = \",\")\n",
    "    \n",
    "plt.legend()\n",
    "   #\n",
    "plt.xlabel('Feature 2')\n",
    "plt.ylabel('Feature 3')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee2512-59dc-41ed-8cf2-96505468b1e7",
   "metadata": {},
   "source": [
    "<div> \n",
    "<img src=\"./01_Images/09_Results_Chart.png\" alt=\"Drawing\" style=\"width: 800px;\"/>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb4fa2-1927-4534-8ea4-1dde87fceddd",
   "metadata": {},
   "source": [
    "#  Step A2: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59cef88-7f7a-4579-922c-fc7fa9960059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df4b7d-946c-4437-8965-d67a07a089c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1202c-c630-4e27-aea8-4ed425b139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: kNN=3\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: kNN=3 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1740a-f656-4d6d-bdf3-cb2f053fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#  Naive Bayes, Gaussian\n",
    "#\n",
    "#     Gaussian usually does better than the Multinomial below because,\n",
    "#        Gaussian expects continuous values\n",
    "#        Multinomial expects discreet values\n",
    "#\n",
    "#     And our values are continuous\n",
    "#\n",
    "\n",
    "do_model(GaussianNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: GaussianNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(GaussianNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: GaussianNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e0e-31d0-44c1-bdb3-0ee3c5ca3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Naive Bayes, Multinomial\n",
    "#\n",
    "\n",
    "do_model(MultinomialNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: MultinomialNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(MultinomialNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: MultinomialNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb7874-3d2c-4f27-83db-147b953228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Decision Tree\n",
    "#\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: DecisionTree\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(DecisionTreeClassifier(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: DecisionTree Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a74fa-57c5-44ef-ade3-dd5438751064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  Random Forest\n",
    "#\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RandomForest\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RandomForest Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0262-190c-455d-b2f9-99056c1bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: SVC/Linear\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: SVC/Linear Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF 2\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF 2 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe262a-4fb5-4954-9d6f-c8cbea09d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Breast Cancer data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1)     ID number\n",
    "#     2)     Diagnosis (M = malignant, B = benign)\n",
    "#     3-32)\n",
    "#       Ten real-valued features are computed for each cell nucleus:\n",
    "#     \n",
    "#     \ta) radius (mean of distances from center to points on the perimeter)\n",
    "#     \tb) texture (standard deviation of gray-scale values)\n",
    "#     \tc) perimeter\n",
    "#     \td) area\n",
    "#     \te) smoothness (local variation in radius lengths)\n",
    "#     \tf) compactness (perimeter^2 / area - 1.0)\n",
    "#     \tg) concavity (severity of concave portions of the contour)\n",
    "#     \th) concave points (number of concave portions of the contour)\n",
    "#     \ti) symmetry \n",
    "#     \tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "#\n",
    "#  Sample data line,\n",
    "#     842302,M,\n",
    "#     17.99,    10.38,    122.8,    1001,    0.1184,    0.2776,    0.3001,    0.1471,    0.2419,    0.07871,         #  10 count\n",
    "#     1.095,    0.9053,   8.589,    153.4,   0.006399,  0.04904,   0.05373,   0.01587,   0.03003,   0.006193,\n",
    "#     25.38,    17.33,    184.6,    2019,    0.1622,    0.6656,    0.7119,    0.2654,    0.4601     ,0.1189\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"22_wdbc.data.txt\"\n",
    "\n",
    "\n",
    "pd_bc  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"id\", \"class\",\n",
    "            \"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \n",
    "            \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\", \"f20\", \n",
    "            \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "           ],\n",
    "   dtype = {\"id\": \"int\", \"class\": \"string\",\n",
    "            \"f01\": \"float\", \"f02\": \"float\", \"f03\": \"float\", \"f04\": \"float\", \"f05\": \"float\", \"f06\": \"float\", \"f07\": \"float\", \"f08\": \"float\", \"f09\": \"float\", \"f10\": \"float\", \n",
    "            \"f11\": \"float\", \"f12\": \"float\", \"f13\": \"float\", \"f14\": \"float\", \"f15\": \"float\", \"f16\": \"float\", \"f17\": \"float\", \"f18\": \"float\", \"f19\": \"float\", \"f20\": \"float\", \n",
    "            \"f21\": \"float\", \"f22\": \"float\", \"f23\": \"float\", \"f24\": \"float\", \"f25\": \"float\", \"f26\": \"float\", \"f27\": \"float\", \"f28\": \"float\", \"f29\": \"float\", \"f30\": \"float\", \n",
    "           } )\n",
    "      #\n",
    "pd_bc[\"class_encoded\"]  =  my_le.fit_transform(pd_bc[\"class\"])\n",
    "   #\n",
    "pd_bc = pd_bc.drop([\"class\", \"id\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized count of rows\n",
    "#\n",
    "print(tabulate(pd_bc.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_bc)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05409-32ac-4da0-bd05-6d97b35df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_bc = {}\n",
    "   #\n",
    "np_bc[\"train\"], np_bc[\"test\"] = train_test_split(pd_bc.to_numpy(),                    #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_bc), len(np_bc[\"train\"]), len(np_bc[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_bc[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_bc[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885ac6-db00-4fd0-9ef3-c7b5bd130542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Normalizing the data\n",
    "#\n",
    "\n",
    "def my_normalize(X, x_min, x_max):\n",
    "   nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "   denom = X.max(axis=0) - X.min(axis=0)\n",
    "   denom[denom==0] = 1\n",
    "   return x_min + nom/denom \n",
    "\n",
    "\n",
    "print(\"Number of columns in matrix: %d\" % (np_bc[\"train\"].shape[1]))\n",
    "      \n",
    "#  If we normalize the \"class\" column, we lose the categorical nature\n",
    "#  of that data. So, create a deep copy, then just normalize the non-\n",
    "#  class columns.\n",
    "#\n",
    "np_bc[\"train_norm\"] = np.copy(np_bc[\"train\"])\n",
    "np_bc[\"test_norm\" ] = np.copy(np_bc[\"test\" ])\n",
    "   #\n",
    "np_bc[\"train_norm\"][:, :30] = my_normalize(np_bc[\"train_norm\"][:, :30], 0, 1)\n",
    "np_bc[\"test_norm\" ][:, :30] = my_normalize(np_bc[\"test_norm\" ][:, :30], 0, 1)\n",
    "\n",
    "plt.boxplot(np_bc[\"train\"     ])\n",
    "plt.show()\n",
    "plt.boxplot(np_bc[\"train_norm\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36b4ec-23da-4af1-8cb4-fe5669cc5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "#  Our numpy array has many columns, with the last column being the class.\n",
    "#\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 30 columns use,\n",
    "#        np_iris[\"train\"][:, :30]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Centroid\") \n",
    "#  do_model(NearestCentroid(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Centroid Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: kNN=3\") \n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: kNN=3 Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: GaussianNB\") \n",
    "#  do_model(GaussianNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: GaussianNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: MultinomialNB\") \n",
    "#  do_model(MultinomialNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: MultinomialNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: DecisionTree\") \n",
    "#  do_model(DecisionTreeClassifier(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: DecisionTree Normalized\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Random Forest = 5\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Random Forest = 5 Normalized\") \n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: SVC/Linear\") \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: SVC/Linear Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF 2\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF 2 Normalized\") \n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb083d-60ba-4c42-b65c-f8f7c0864b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We will be using Keras, so pip install it inside the Jupyter NoteBook container ..\n",
    "#\n",
    "\n",
    "l_package1 = \"keras\"\n",
    "l_package2 = \"tensorflow\"\n",
    "    \n",
    "def my_func(arg1):\n",
    "    \n",
    "   import sys\n",
    "   import subprocess\n",
    "    \n",
    "   subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", arg1 ])\n",
    "      #\n",
    "   print(\"From each host ..\")\n",
    "      #\n",
    "   return\n",
    "\n",
    "\n",
    "   ##########################################\n",
    "    \n",
    "\n",
    "print(\"Install Python Pip packages on Jupyter container ..\")\n",
    "   #\n",
    "my_return = my_func(l_package1)\n",
    "my_return = my_func(l_package2)\n",
    "print()\n",
    "    \n",
    "\n",
    "#  Use this if installing o nthe KGIP worker nodes ..\n",
    "#\n",
    "#  print(\"Install Python Pip packages on KGIP worker node containers ..\")\n",
    "#     # \n",
    "#  my_return = my_graph.run(lambda g: my_func(l_package))\n",
    "#  print()\n",
    "    \n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a359-02b1-4bb0-aced-216eb7cad1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Intead of loading MNist from disk, we load it from the Keras library ..\n",
    "#\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "np_mnist = {}\n",
    "   #\n",
    "(np_mnist[\"train\"], np_mnist[\"train_label\"]), (np_mnist[\"test\"], np_mnist[\"test_label\"]) = mnist.load_data()\n",
    "\n",
    "\n",
    "#  train and test ccome in as an array [(n), 28, 28] where n == 60000 for train,\n",
    "#  and 100000 for test\n",
    "#\n",
    "#  We need that 28*28 as a vector, so ..\n",
    "#\n",
    "np_mnist[\"train_v\"] = np_mnist[\"train\"].reshape(-1, 28*28)\n",
    "np_mnist[\"test_v\"]  = np_mnist[\"test\" ].reshape(-1, 28*28)\n",
    "\n",
    "\n",
    "print(\"Train shape ................ %s\" % (str(np_mnist[\"train\"].shape)))\n",
    "print(\"Train label shape .......... %s\" % (str(np_mnist[\"train_label\"].shape)))\n",
    "   #\n",
    "print(\"Test  shape ................ %s\" % (str(np_mnist[\"test\"].shape)))\n",
    "print(\"Test  label shape .......... %s\" % (str(np_mnist[\"test_label\"].shape)))\n",
    "   #\n",
    "print(\"Train vector shape ......... %s\" % (str(np_mnist[\"train_v\"].shape)))\n",
    "print(\"Test  vector shape ......... %s\" % (str(np_mnist[\"test_v\" ].shape)))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "#  tabulate() displays poorly with this wide data. Straight up print() works well.\n",
    "#\n",
    "# print(tabulate(np_mnist[\"train\"][0:2], headers='keys', tablefmt='psql', showindex=False))\n",
    "print(np_mnist[\"train\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"train_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "    \n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425b03-8d9c-4208-af6b-9f6115104b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     Train shape ................ (60000, 28, 28)\n",
    "#     Train label shape .......... (60000,)\n",
    "#     Test  shape ................ (10000, 28, 28)\n",
    "#     Test  label shape .......... (10000,)\n",
    "#     Train vector shape ......... (60000, 784)\n",
    "#     Test  vector shape ......... (10000, 784)\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252 253 122   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228  47  79 255 168   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0   0   0 253 252 165   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253 196   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135 253 186  12   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165 252 173   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167  56   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [5 0]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [7 2]\n",
    "#     Number of rows: 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bcf95-6f46-448e-a618-4bf0fb15e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97564456-56d7-4f55-b4d8-94ec6ddde2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "\n",
    "#  Here we run given ML routines against the MNist data set\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Adding these to the above\n",
    "#\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e883ec4-3c77-43cd-8d71-588f58f12503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Centroid\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=3\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=7\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: GaussianNB\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: DecisionTree\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   \") \n",
    "do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  \") \n",
    "do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 \") \n",
    "do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "#  As configured, these throw warnings, never settle ..\n",
    "#\n",
    "\n",
    "#  do_model(LinearSVC(C = 0.01), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.01   \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 0.1 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.1    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 1.0 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=1.0    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 10.0), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=10.0   \") \n",
    "#  print()\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b1c44-a03b-4965-9f81-c838e23136ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     MNist: Centroid ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 2 9 0 2 9 0 1 5 9 7 3 4 7 6 4 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 0 6 6 0 1 8 8 4 5 6 7 8 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 82.0300 %\n",
    "#     \n",
    "#     MNist: kNN=3 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0500 %\n",
    "#     MNist: kNN=7 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.9400 %\n",
    "#     \n",
    "#     MNist: GaussianNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [9 2 1 0 9 1 8 9 4 9 0 6 9 0 1 0 9 7 2 9 9 6 6 8 9 0 7 9 0 1 ... 6 0 8 9 8 8 6 9 1 9 3 6 6 0 1 9 8 9 8 6 9 8 9 0 1 8 8 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 55.5800 %\n",
    "#     \n",
    "#     MNist: MultinomialNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 3 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 2 2 4 9 4 2 6 4 1 7 2 6 6 0 1 8 8 4 5 6 7 8 9 0 1 2 3 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6500 %\n",
    "#     \n",
    "#     MNist: DecisionTree ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 7 6 9 0 6 9 0 1 5 9 7 6 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 8 4 1 7 5 6 8 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.6700 %\n",
    "#     \n",
    "#     MNist: Random Forest = 5    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 8 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 91.9100 %\n",
    "#     MNist: Random Forest = 50   ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 3 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.7000 %\n",
    "#     MNist: Random Forest = 500  ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0400 %\n",
    "#     MNist: Random Forest = 5000 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.1800 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.01    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.1200 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.1     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 1 6 4 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 4 4 2 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 86.4700 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=1.0     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 2 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.9900 %\n",
    "#     \n",
    "#     MNist: LinearSVC c=10.0    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 8 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 8 8 4 5 6 7 8 9 0 1 8 3 5 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6900 %\n",
    "#     \n",
    "#     \n",
    "#     +-----------------------------+------------+\n",
    "#     | Category                    | Accuracy   |\n",
    "#     |-----------------------------+------------|\n",
    "#     |                             |            |\n",
    "#     | MNist: Centroid             | 82.03      |\n",
    "#     | MNist: kNN=3                | 97.05      |\n",
    "#     | MNist: kNN=7                | 96.94      |\n",
    "#     | MNist: GaussianNB           | 55.58      |\n",
    "#     | MNist: MultinomialNB        | 83.65      |\n",
    "#     | MNist: DecisionTree         | 87.67      |\n",
    "#     | MNist: Random Forest = 5    | 91.91      |\n",
    "#     | MNist: Random Forest = 50   | 96.7       |\n",
    "#     | MNist: Random Forest = 500  | 97.04      |\n",
    "#     | MNist: Random Forest = 5000 | 97.18      |\n",
    "#     | MNist: LinearSVC c=0.01     | 87.12      |\n",
    "#     | MNist: LinearSVC c=0.1      | 86.47      |\n",
    "#     | MNist: LinearSVC c=1.0      | 83.99      |\n",
    "#     | MNist: LinearSVC c=10.0     | 83.69      |\n",
    "#     +-----------------------------+------------+\n",
    "#     \n",
    "#     --\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612d30f-3774-4620-a843-7c04c7a6095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Regarding this,\n",
    "#\n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
    "#        Liblinear failed to converge, increase the number of iterations.\n",
    "#        warnings.warn(\n",
    "#\n",
    "#  From,\n",
    "#     https://stackoverflow.com/questions/52670012/convergencewarning-liblinear-failed-to-converge-increase-the-number-of-iterati\n",
    "#\n",
    "#      Normally when an optimization algorithm does not converge, it is usually because the problem is not well-conditioned,\n",
    "#      perhaps due to a poor scaling of the decision variables. There are a few things you can try.\n",
    "#      \n",
    "#          Normalize your training data so that the problem hopefully becomes more well conditioned, which in turn can speed up\n",
    "#          convergence. One possibility is to scale your data to 0 mean, unit standard deviation using Scikit-Learn's StandardScaler\n",
    "#          for an example.\n",
    "#\n",
    "#          Note that you have to apply the StandardScaler fitted on the training data to the test data. Also, if you have discrete\n",
    "#          features, make sure they are transformed properly so that scaling them makes sense.\n",
    "#\n",
    "#          Related to 1), make sure the other arguments such as regularization weight, C, is set appropriately. C has to be > 0.\n",
    "#          Typically one would try various values of C in a logarithmic scale (1e-5, 1e-4, 1e-3, ..., 1, 10, 100, ...) before\n",
    "#          finetuning it at finer granularity within a particular interval. These days, it probably make more sense to tune\n",
    "#          parameters using, for e.g., Bayesian Optimization using a package such as Scikit-Optimize.\n",
    "#\n",
    "#          Set max_iter to a larger value. The default is 1000. This should be your last resort. If the optimization process does\n",
    "#          not converge within the first 1000 iterations, having it converge by setting a larger max_iter typically masks other\n",
    "#          problems such as those described in 1) and 2). It might even indicate that you have some in appropriate features or\n",
    "#          strong correlations in the features. Debug those first before taking this easy way out.\n",
    "#\n",
    "#          Set dual = True if number of features > number of examples and vice versa. This solves the SVM optimization problem using\n",
    "#          the dual formulation. Thanks @Nino van Hooff for pointing this out, and @JamesKo for spotting my mistake.\n",
    "#\n",
    "#          Use a different solver, for e.g., the L-BFGS solver if you are using Logistic Regression. See @5ervant's answer.\n",
    "#      \n",
    "#      Note: One should not ignore this warning.\n",
    "#      \n",
    "#      This warning came about because\n",
    "#      \n",
    "#          Solving the linear SVM is just solving a quadratic optimization problem. The solver is typically an iterative algorithm\n",
    "#          that keeps a running estimate of the solution (i.e., the weight and bias for the SVM). It stops running when the solution\n",
    "#          corresponds to an objective value that is optimal for this convex optimization problem, or when it hits the maximum number\n",
    "#          of iterations set.\n",
    "#      \n",
    "#          If the algorithm does not converge, then the current estimate of the SVM's parameters are not guaranteed to be any good, \n",
    "#          hence the predictions can also be complete garbage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff57e71-9dc7-4e7c-9e6c-eb447e07867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Effect of randomness, moving the bits around inside each image.\n",
    "#\n",
    "#  Note; each row is randomzied by its own unique pattern.\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_mnist[\"train\"] \n",
    "#     np_mnist[\"train_label\"]\n",
    "#     np_mnist[\"test\"]\n",
    "#     np_mnist[\"test_label\"]\n",
    "#     np_mnist[\"train_v\"]           #  vectors of the two data sets above\n",
    "#     np_mnist[\"test_v\"] \n",
    "#\n",
    "\n",
    "#  Here we want to copy the two \"v\" arrays and randomize them\n",
    "#\n",
    "np_mnist[\"train_v_s\"] = np.copy(np_mnist[\"train_v\"])\n",
    "np_mnist[\"test_v_s\" ] = np.copy(np_mnist[\"test_v\" ])\n",
    "   #\n",
    "for i in range(np_mnist[\"train_v_s\"].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"train_v_s\"][i, :])\n",
    "for i in range(np_mnist[\"test_v_s\" ].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"test_v_s\" ][i, :])\n",
    "\n",
    "\n",
    "#  Looking at the non-scrambled, and yes-scrambled data\n",
    "#\n",
    "#  Currently the data lives as a vector. To look at it, copy\n",
    "#  it back to a 28*28 numpy array. We only need this for two\n",
    "#  rows we wish to view, and we choose to use test.\n",
    "#\n",
    "np_mnist[\"test_s\"] = np.zeros((2, np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2]), dtype = int)\n",
    "   #\n",
    "for i in range(np_mnist[\"test_s\"].shape[0]):\n",
    "   np_mnist[\"test_s\"][i,:,:] = np_mnist[\"test_v_s\"][i].reshape(28, 28)\n",
    "\n",
    "#  And the actual print\n",
    "#\n",
    "#  Non-randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "#  Problems with print formatting. These lines help\n",
    "#\n",
    "np.set_printoptions()\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000,  formatter = dict(int = lambda x: \"%3i\" % x))\n",
    "\n",
    "#  Randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test_s\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_s\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1983d12-36a3-42fd-83dc-3fb41fe464d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [ 61   0  38   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0 198 241   0   0   0]\n",
    "#       [  0   0   0   0   0   0 170   0 121   0 233 254   0   0   0 115   0 185 198   0   0   0   0   0 129   0   0   0]\n",
    "#       [  0   0 225   0   0   0   0   0   0   0   0   0   0 205   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [159   0   0  19   0   0   0   0   0  18   0   0   0   0  58   0  21 254   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 229   0   0   0   0 121   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0  60   0   0 238  67   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 151   0   0   0  59   0 254   0   0   0   0   0   0   0   0 207   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 209   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  67   0   0   0   0   0 254   0   0   0   0   0   0   0   0  52]\n",
    "#       [  0  57 163  77   0   0   0   0   0   0  84   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0 248]\n",
    "#       [  0   0   0   0   0   0   0   0 254   0   0   0 236   0   0   0 249   0   0   0   0   0   0   0  59   0   0   0]\n",
    "#       [  0   0   0   1   0   0   0   0 221   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 133   0   0   0   0   0   0 240   0   0   0 219   0   0   0   0]\n",
    "#       [  0 251   0   0   0   0   0  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  17]\n",
    "#       [  0   0   0  31   0   0   0 254   0 254   0   0   0   0   0   0   0 219   0  66   0   0   0   0   0   0   0   0]\n",
    "#       [166   0   0   0   0 254   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  62   0   0   3   0   0]\n",
    "#       [  0   0   0   0   0  18   0   0   0   0   0   0 254   0   0   0   0 254   0   0  83   0   0   0   0  40   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 250  75   0   0 198   0   0   0   0   0   0   0 203   0   0   0  67 114   0   0]\n",
    "#       [  0   0   0 140   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 106   0 227   0  52   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0 222]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0 182]\n",
    "#       [126   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0 242   0   0  44   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 254 198 254   0   0   0 114   0   0   0   0 133   0   0 198   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254 253   5   0   0   0 187   0   0   0   0  67   0   0   0  72 198   0  83   0   0   0   0]\n",
    "#       [  0   0 254 198   0 254 254   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0  35   0   0  22   0]\n",
    "#       [  0   0   0 255   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198   0 224]]\n",
    "#     \n",
    "#      [[  0   0 247   0   0 253  12 118  31   0 248   0   0   0   0   0 176 166   0   0   0   0   0  25   0   0   0   0]\n",
    "#       [  0   0 209   0  93   0   0   0   0   0   0   0   0   0   0 123   0   0   0   0 200   0  35  10   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 141   0 253 253   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0 253]\n",
    "#       [  0   0   0   0   0   0   0   0   0 117   0   0 206 122 253  10   0 150   0   0   0   0 253 253   0   0 253 253]\n",
    "#       [ 43   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0  32   0   0 253   0   0   0   0 253 155   0   0   0   0   0   0   0   0 198 140   0   0   0   0   0]\n",
    "#       [  0   0   0  12   0   0   0 141   0 255   0   0   0  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [249   0   0   0   0 123 166   0   0   0   0   0   0 253   0   0   0   0 210 248   0   0   0  20   0   0   0   0]\n",
    "#       [  0   0 123  18   0   0   0   0   0   0   0   0  20 253   0   0   0   0   0   0 198   0 253   0   0   0   0   0]\n",
    "#       [  0 255   0   0 253   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0  63   0   0 253   0]\n",
    "#       [  0   0   0   0 116   6   0   0   0   0  20   0   0   0 248   0   0  12 142   0   0   0   0   0 253   0 253   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0   0 150   0   0   0   0 253 234   0   0 253   0   0   0   0  78   0   0   0]\n",
    "#       [  0   0   0 253   0   0   0   0   0   0   0 169   0   0 218   0   0   0   0   0 253   0   0 253   0   0   5   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 213   0   0   0   0   0   0 253   0   0 253   0   0 231   0   0   0 253]\n",
    "#       [  0   0 253   0   0   0   0   0   0 134   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [174   0   0   0   0   0   0   0  19   0 123   0   0   0   0   0   0   0   0 171 168   0   0   0   0   0   0 128]\n",
    "#       [  0   0  20  41 253   0 253 144   0   0  76   0   0   0   0 253   0   0   0 176   0 159   0 253   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248   0  20   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [246   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0 253   0 253   0   0 253   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 253 253   0   0   0   0   0   0   0   0 123   0   0   0 117   0   0   0   0   0 125   5]\n",
    "#       [  0   0   0   0   0   0 253   0   0   0   0   0   0   0 250   0 253   0   0  52   0 122 123   0   0   0   0   0]\n",
    "#       [  0 147   0 253   0   0 169   0   0   0   0   0 253   0 253   0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 150   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0 253   0   0   0   0  77   0 253   0   0   0   0]\n",
    "#       [248  37   0   0   0   0   0  65   0   0   0   0 173 233   0   0 253   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [150   0 169 247   0   0   0   0   0  12   0   0   0   0   0   0  25   0   0   0   0  65   0   0   0   0 189   0]\n",
    "#       [  0 253   0 251   0   0   0   0   0   0   0   0 253 253   0   0   0   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [117   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253  20 210 253   0  57   0   0   0   0   0]]]\n",
    "#     Number of rows: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b208e4-2d65-4efa-9ed1-f4f51be6bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Creating a bar chart; Are these the same values ?\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image pre-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v_s\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image post-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e165c-4d92-48cb-8ee2-85782fc4119d",
   "metadata": {},
   "source": [
    "<div> \n",
    "<img src=\"./01_Images/07_Results_BarChart.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6316f92-89a4-440c-9861-090b6f6e8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Rerun ML routines now on the scrambled images\n",
    "#\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: Centroid, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: kNN=3, Scramble\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: kNN=7, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: GaussianNB, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: DecisionTree, Scramble\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000, Scramble\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf646e34-43c1-48a0-b369-7aa59aed6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  The results below were on images that were not scrambled.\n",
    "#\n",
    "#     +-----------------------------+-------------------+\n",
    "#     | Category                    | Accuracy          |\n",
    "#     |-----------------------------+-------------------|\n",
    "#     | MNist: Centroid             | 82.03             |\n",
    "#     | MNist: kNN=3                | 97.05             |\n",
    "#     | MNist: kNN=7                | 96.94             |\n",
    "#     | MNist: GaussianNB           | 55.58             |\n",
    "#     | MNist: MultinomialNB        | 83.65             |\n",
    "#     | MNist: DecisionTree         | 87.72             |\n",
    "#     | MNist: Random Forest = 5    | 92.36999999999999 |\n",
    "#     | MNist: Random Forest = 50   | 96.67999999999999 |\n",
    "#     | MNist: Random Forest = 500  | 97.15             |\n",
    "#     | MNist: Random Forest = 5000 | 97.17             |\n",
    "#     |                             |                   |\n",
    "#     +-----------------------------+-------------------+\n",
    "#\n",
    "#  The results below on images when data is entirely randomized row by row ..\n",
    "#\n",
    "#     +--------------------------------+--------------------+\n",
    "#     | Category                       | Accuracy           |\n",
    "#     |--------------------------------+--------------------|\n",
    "#     | MNist: Centroid, Scramble      | 22.03              |\n",
    "#     | MNist: kNN=3, Scramble         | 11.540000000000001 |\n",
    "#     | MNist: kNN=7, Scramble         | 11.379999999999999 |\n",
    "#     | MNist: GaussianNB, Scramble    | 21.37              |\n",
    "#     | MNist: MultinomialNB, Scramble | 9.93               |\n",
    "#     | MNist: DecisionTree, Scramble  | 12.889999999999999 |\n",
    "#     |                                |                    |\n",
    "#     +--------------------------------+--------------------+\n",
    "#\n",
    "#  Takeaway,\n",
    "#\n",
    "#     .  Our data is 256 value bits * 2-dim array of (28 * 28).\n",
    "#        28 * 28 == 784\n",
    "#        Per each 28*28 image (784 bits), 650-700 of those bits are blank/zero.\n",
    "#\n",
    "#       So, to randomize the location of order bits itself is not bad, but it\n",
    "#       does not leave us with enough training data.\n",
    "#\n",
    "#       Meaning; a totally random \"7\" [ might ] be unique enough from a \"2\" or\n",
    "#       any other number, but we'd need a lot more data.\n",
    "#\n",
    "#     .  The approach now is to randomize the bits, but on a single consistent\n",
    "#        pattern applied to each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebe7e5-79b4-4e75-8ab9-8eb30b370e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Effect of randomness, moving the bits around inside each image.\n",
    "#\n",
    "#  Note; each row is randomized by one shared pattern.\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_mnist[\"train\"] \n",
    "#     np_mnist[\"train_label\"]\n",
    "#     np_mnist[\"test\"]\n",
    "#     np_mnist[\"test_label\"]\n",
    "#     np_mnist[\"train_v\"]           #  vectors of the two data sets above\n",
    "#     np_mnist[\"test_v\"] \n",
    "#\n",
    "\n",
    "#  Here we want to copy the two \"v\" arrays \n",
    "#\n",
    "np_mnist[\"train_v_s2\"] = np.copy(np_mnist[\"train_v\"])\n",
    "np_mnist[\"test_v_s2\" ] = np.copy(np_mnist[\"test_v\" ])\n",
    "\n",
    "\n",
    "#  Make a new vector of values 0-n, randomize that, uses this as a map to\n",
    "#  consistently 'randomize' all remaining data\n",
    "#\n",
    "np_random = np.arange(0, np_mnist[\"train_v_s2\"].shape[1] -1, 1, dtype = int)\n",
    "np.random.shuffle(np_random)\n",
    "\n",
    "\n",
    "#  Apply the actual 'randomization'\n",
    "#\n",
    "for i in range(np_mnist[\"train_v_s2\"].shape[0]):\n",
    "   l_tmp = np.zeros(np_mnist[\"train_v_s2\"][i].shape[0], dtype = int)\n",
    "   for j in range(np_mnist[\"train_v_s2\"][i].shape[0] -1):\n",
    "      l_tmp[j] = np_mnist[\"train_v_s2\"][i][ np_random[j] ]\n",
    "   np_mnist[\"train_v_s2\"][i, :] = l_tmp[:]\n",
    "\n",
    "\n",
    "       #\n",
    "for i in range(np_mnist[\"test_v_s2\"].shape[0]):\n",
    "   l_tmp = np.zeros(np_mnist[\"test_v_s2\"][i].shape[0], dtype = int)\n",
    "   for j in range(np_mnist[\"test_v_s2\"][i].shape[0] - 1):\n",
    "      l_tmp[j] = np_mnist[\"test_v_s2\"][i][ np_random[j] ]\n",
    "   np_mnist[\"test_v_s2\"][i, :] = l_tmp[:]\n",
    "\n",
    "\n",
    "#  Looking at the yes-scrambled data\n",
    "#\n",
    "#  Currently the data lives as a vector. To look at it, copy\n",
    "#  it back to a 28*28 numpy array. We only need this for two\n",
    "#  rows we wish to view, and we choose to use test.\n",
    "#\n",
    "np_mnist[\"test_s\"] = np.zeros((2, np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2]), dtype = int)\n",
    "   #\n",
    "for i in range(np_mnist[\"test_s\"].shape[0]):\n",
    "   np_mnist[\"test_s\"][i,:,:] = np_mnist[\"test_v_s2\"][i].reshape(np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2])\n",
    "\n",
    "\n",
    "#  Problems with print formatting. These lines help\n",
    "#\n",
    "np.set_printoptions()\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000,  formatter = dict(int = lambda x: \"%3i\" % x))\n",
    "\n",
    "#  Randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test_s\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_s\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02b6db-d527-4398-a4c9-782dc693ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     [  7   2]\n",
    "#     [[[  0   0 133 205   0   0   0   0   0   0   0   0  18 219   0   0 254   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 198   0   0 198   0   0   0 254   0   0   0   0   0   0  57   0   0   0   0 198   0   0   0   0]\n",
    "#       [  0 151   0   0   0   0 254   0   0   0   0   0   0   0   0  75   0   0   0   0   0  17   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198   0   0   0   0   0]\n",
    "#       [  0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0 236   0   0   0   0 254   0   0 121   0   0   0]\n",
    "#       [  0   0 241   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0 255   0 254   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0 254   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   3   0   0   0 187   0  22   0 254   0 207   0   0   0  44   0   0   0  36   0   0   0  60   0 249   0]\n",
    "#       [  0   0   0   0   0 240  38   0 159   0   0   0   0 209   0 133   0   0   0   0   0   0   0  61 254   0   0   0]\n",
    "#       [  0   0   0 253   0   0 238   0 224   0   0   0   0   0   0  83   0  52   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254   0   0   0 229   0   0   0   0   0 254   0   0   0   0   0 114   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 129   0   0   0   0   0 198   0   0   0   0   0 115   0   0   0   0  58   0   0   0 221]\n",
    "#       [  0 251   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 163   0   0   0]\n",
    "#       [  0  59   9   0   0  67   0   0   0   0   0   0   0 182   0   0   0   0 198   0   0   0   0   0   0   0  35   0]\n",
    "#       [  0   0 250   0   0  19   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  52 254   0   0   5   0   0]\n",
    "#       [  0   0  66 198   0   0   0   0   0   0 126   0  52   0   0   0 140   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  67   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254]\n",
    "#       [  0   0   0   0   0   0   0 254   0 254   0   0   0 185   0   0  67   0   0   0   0   0   0   0  40 121   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 166   0   0   0   0   0   0  31   0   0   0   0 222 203   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0 254   0 254   0   0   0   0   0   0   0   0 227   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0 225   0  72   0   0   0  84   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  18   0   0   0  59   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0 219   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0 254   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  77   0 106   0   0   0   0   0   0   0   0   0  67   0 233   0 198]\n",
    "#       [  0  62   0   0   0   0   0   0  83 248   0 254   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0 242]\n",
    "#       [  0   0   0   0   0 114   0   0   0   0   0   0   0   0   1   0   0   0   0   0 254   0   0   0 254   0   0   0]]\n",
    "#     \n",
    "#      [[ 43   0   0   0   0   0 255   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   0  65   0  12   0]\n",
    "#       [  0   0   0   0 253   0 147 253 128   0   0 253   0   0   0  10   0   0   0   0   0   0   0   0   0 253   0   0]\n",
    "#       [  0 210   0   0 210  12   0 253   0 253   0 141 248 249   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0 144   0   0   0 253   0   0   0   0   0   0   0 253   0   0 142   0   0   0   0   0   0   0   0   0 253]\n",
    "#       [  0   0   0 253   0   0   0   0   0 246   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [169   0   0   0   0   0   0   5   0   0   0   0   0   0   0 253   0 198 248   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 253   0 247   0 253   0 253   0 166   0 250 253   0 143   0   0]\n",
    "#       [  0   0 253   0   0   0   0   0   0   0   0   0  12   0   0   0  25 150   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [253   0 253  20 253   0   0 253   0 176   0   0   0   0   0 125   0   0 253   0   0 169   0   0  25   0   0   0]\n",
    "#       [118   0   0   0 140   0 253   0 251 174   0  93   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 206]\n",
    "#       [  0   0   0   0   0 234   0   0 123   0   0   0   0   0   0   0   0   0   0   0   0  35   0   0   0   0   0   0]\n",
    "#       [  0 253   0 150  30   0   0   0 176   0   0 253   0   0   0   0   0   0   0 166   0   0   0   0   0   0 248   0]\n",
    "#       [  0   0   0   0 122   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0 253   0   0   0  57   0  20  20]\n",
    "#       [  0   0   0   0 123   0   0   0   0   0   0   0   0   0  41 116   0   0   0   0   0 253 141 253   0   0   0 189]\n",
    "#       [  0   0   0   0   0  63   0   0   0   0   0   0 247   0   0   0   0 253 209   0   0 123   0   0   0   0 168 253]\n",
    "#       [ 25   0  10 150   0  20   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0  76   0   0   0 122   0   0 253   0 253   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]\n",
    "#       [ 37 213 253   0   0  18   0   0   0   0 253   0 253   0   0   0   0 253 253   0   0   0   0 117   0 248   0 247]\n",
    "#       [  0 255   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0 173   0   0   0   0   0  31   0   0   0   0   0  77  32   0 253   0 117 253   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 169   0   0   0   0   0   5   0   0   0   0   0   0 123   0   0   0   0   0 253 198   0   0   0]\n",
    "#       [  0 253   0   0   0   0   0 253   0   0 253   0  20   0   0   0   0 123   0   0   0   0   0 123   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 155   0   0  78   0   0   0 253   0 117   0   0   0 200   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0]\n",
    "#       [  0   0 253   0   0 253   0 159   0   0   0   0   0   0 247   0   0   0   0   0   0   0   0   0 233   0   0   0]\n",
    "#       [  0   0 248 218   0   0 171   0   0   0   0 253   0   0   0   0 150   0   0 253   0 253   0 231  52   0   0  65]\n",
    "#       [  0   0   0   0   0   0   0  12   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0  19   0]\n",
    "#       [253   0   0   0   6   0   0   0 253   0   0   0   0   0 253   0   0   0 253   0   0   0   0   0 253   0   0   0]]]\n",
    "#     Number of rows: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346226c5-d1d2-4ee9-aa9b-192e950e22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Rerun ML routines now on the scrambled images, those randomized by one shared pattern\n",
    "#\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: Centroid, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: kNN=3, Scramble-2\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: kNN=7, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: GaussianNB, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: DecisionTree, Scramble-2\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000, Scramble\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad074-e31f-44ff-844a-2c77217929f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  The results below were on images that were not scrambled.\n",
    "#\n",
    "#     +-----------------------------+-------------------+\n",
    "#     | Category                    | Accuracy          |\n",
    "#     |-----------------------------+-------------------|\n",
    "#     | MNist: Centroid             | 82.03             |\n",
    "#     | MNist: kNN=3                | 97.05             |\n",
    "#     | MNist: kNN=7                | 96.94             |\n",
    "#     | MNist: GaussianNB           | 55.58             |\n",
    "#     | MNist: MultinomialNB        | 83.65             |\n",
    "#     | MNist: DecisionTree         | 87.72             |\n",
    "#     | MNist: Random Forest = 5    | 92.36999999999999 |\n",
    "#     | MNist: Random Forest = 50   | 96.67999999999999 |\n",
    "#     | MNist: Random Forest = 500  | 97.15             |\n",
    "#     | MNist: Random Forest = 5000 | 97.17             |\n",
    "#     |                             |                   |\n",
    "#     +-----------------------------+-------------------+\n",
    "#\n",
    "#  The results below on images when data is randomized by one shared pattern ..\n",
    "#\n",
    "#     +----------------------------------+------------+\n",
    "#     | Category                         | Accuracy   |\n",
    "#     |----------------------------------+------------|\n",
    "#     |                                  |            |\n",
    "#     | MNist: Centroid, Scramble-2      | 82.03      |\n",
    "#     | MNist: kNN=3, Scramble-2         | 97.05      |\n",
    "#     | MNist: kNN=7, Scramble-2         | 96.94      |\n",
    "#     | MNist: GaussianNB, Scramble-2    | 55.58      |\n",
    "#     | MNist: MultinomialNB, Scramble-2 | 83.65      |\n",
    "#     | MNist: DecisionTree, Scramble-2  | 87.7       |\n",
    "#     +----------------------------------+------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976e37-8702-4f53-bf97-e28a958675f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397bde-64f0-4ec9-a728-d37e4c51ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
