{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfd2274-8be4-4517-a0bb-e5bf3e9370a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Notebook overview .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f14aa-01d9-4d3c-9986-a42fa4b15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This Notebook is part of a set that demonstrate GNN using a movie dataset.\n",
    "#  About this Notebook,\n",
    "#\n",
    "#  .  There was a Kaggle GNN challenge circa 2019 detailed here,\n",
    "#        https://www.kaggle.com/c/movie-genre-classification/data\n",
    "#\n",
    "#     That data is locked down, but a similarly themed dataset also on \n",
    "#     Kaggle is here,\n",
    "#        https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
    "#\n",
    "#     The above is the data set in use here.\n",
    "#\n",
    "#  .  1 GB, plus or minus. Most of that volume comes from reviews. The\n",
    "#     movies run 30-40 MB, and the cast and crew about 190 MB.\n",
    "#\n",
    "#     The data is CSV, with embedded arrays of JSON.\n",
    "#     To remove dependencies on GS/S3 hosted data, this program expects this\n",
    "#     data to be local to the container hosting this Jupyter Notebook.\n",
    "#\n",
    "#     Since we host on GitHub, and GitHub has a 25 MB file size limit,\n",
    "#     the total data set is now split across multiple files.\n",
    "#\n",
    "#  .  The existing schema for just Movies is listed here,\n",
    "#  \n",
    "#        10_movies_metadata.csv\n",
    "#        -----------------------------------------\n",
    "#           adult                      ..   False\n",
    "#           belongs_to_collection      ..\n",
    "#           budget                     ..   2700000\n",
    "#           genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#           homepage                   ..   http://www.animalhouse.com/\n",
    "#           id                         ..   8469\n",
    "#           imdb_id                    ..   tt0077975\n",
    "#           original_language          ..   en\n",
    "#           original_title             ..   Animal House\n",
    "#           overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                            the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                            have other plans for him.\"\n",
    "#           popularity                 ..   7.525382\n",
    "#           poster_path                ..   /AuJkgAh7zAGsm7Oo3CGyDtYvzg0.jpg\n",
    "#           production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                               'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#           production_countries       ..   \"[{'iso_3166_1': 'US', 'name': 'United States of America'}]\"\n",
    "#           release_date               ..   1978-07-27\n",
    "#           revenue                    ..   141000000\n",
    "#           runtime                    ..   109.0\n",
    "#           spoken_languages           ..   \"[{'iso_639_1': 'en', 'name': 'English'}]\"\n",
    "#           status                     ..   Released\n",
    "#           tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#           title                      ..   Animal House\n",
    "#           video                      ..   False\n",
    "#           vote_average               ..   7.0\n",
    "#           vote_count                 ..   420\n",
    "#\n",
    "#     From the above, we load the following into a DataFrame of Movies nodes,\n",
    "#\n",
    "#           id                         ..   8469\n",
    "#           title                      ..   Animal House\n",
    "#           genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#           overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                            the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                            have other plans for him.\"\n",
    "#           tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#\n",
    "#           popularity                 ..   7.525382\n",
    "#           production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                               'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#           release_date               ..   1978-07-27\n",
    "#           revenue                    ..   141000000\n",
    "#           runtime                    ..   109.0\n",
    "#           spoken_languages           ..   \"[{'iso_639_1': 'en', 'name': 'English'}]\"\n",
    "#           vote_average               ..   7.0\n",
    "#           vote_count                 ..   420\n",
    "#\n",
    "#      Notice the following from above,\n",
    "#\n",
    "#         ..  genres is an array of JSON, with each genre being unique identified via a numeric.\n",
    "#             We will take the first genre and put it into a property on each node titled, primary_genre.\n",
    "#         ..  We will leave all remaining JSON untouched, stored as strings.\n",
    "\n",
    "\n",
    "#  .  The existing schema is for Keywords is listed here,\n",
    "#\n",
    "#        11_keywords.csv\n",
    "#        -----------------------------------------\n",
    "#           id                         ..   8469\n",
    "#           keywords                   ..   \"[{'id': 572, 'name': 'sex'}, {'id': 2483, 'name': 'nudity'},\n",
    "#                                             {'id': 3616, 'name': 'college'}, {'id': 157632, 'name': 'fraternity'},\n",
    "#                                             {'id': 158507, 'name': 'gross out comedy'}, {'id': 160450, 'name': 'dean'},\n",
    "#                                             {'id': 171400, 'name': 'fraternity house'}, {'id': 208983, 'name': 'probation'},\n",
    "#                                             {'id': 208992, 'name': '1960s'}, {'id': 209506, 'name': 'college freshman'},\n",
    "#                                             {'id': 236316, 'name': 'anarchic comedy'}]\"\n",
    "#\n",
    "#      From the above, the following is offered,\n",
    "#   \n",
    "#         ..  id  joins with movie.id\n",
    "#         ..  keywords.id  already enumerates keywords associated with the movies for us.\n",
    "#             Super handy.\n",
    "\n",
    "\n",
    "#  .  We also have data for,\n",
    "# \n",
    "#        ..  12_Credits  (split into; Cast, Crew)\n",
    "#        ..  14|15_Ratings\n",
    "#        ..  16|17_(External) Links\n",
    "#\n",
    "#     And will likely add these at a later date.\n",
    "\n",
    "\n",
    "#  Below we continue by loading the raw data, and performing some validations on\n",
    "#  statements made, assumptions, and similar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a2149-2554-45a3-be06-8e2ebea43932",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Load just Movies into a DataFrame, perform basic, sanity check analysis .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a874df7-993f-404d-aa53-c8ca266f40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "   #\n",
    "import json\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c62ab-efc7-44de-ac83-4a0cd23f27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Load DataFrame with raw input data\n",
    "\n",
    "l_InputFiles  = [\n",
    "   \"./02_Files/40_Movies_01.txt\",\n",
    "   \"./02_Files/41_Movies_02.txt\",\n",
    "]\n",
    "\n",
    "df_data = dd.read_csv(\n",
    "   l_InputFiles,\n",
    "   delimiter  = \",\",\n",
    "   skiprows   = 1,                                            #  Skip the first line of each file, since it's the column headers\n",
    "   dtype      = {\n",
    "      \"adult\"                     : np.dtype(str),\n",
    "      \"belongs_to_collection\"     : np.dtype(str),\n",
    "      \"budget\"                    : np.dtype(str),\n",
    "      \"genres\"                    : np.dtype(str),\n",
    "      \"homepage\"                  : np.dtype(str),\n",
    "      \"id\"                        : np.dtype(str),\n",
    "      \"imdb_id\"                   : np.dtype(str),\n",
    "      \"original_language\"         : np.dtype(str),\n",
    "      \"original_title\"            : np.dtype(str),\n",
    "      \"overview\"                  : np.dtype(str),\n",
    "      \"popularity\"                : np.dtype(str),\n",
    "      \"poster_path\"               : np.dtype(str),\n",
    "      \"production_companies\"      : np.dtype(str),\n",
    "      \"production_countries\"      : np.dtype(str),\n",
    "      \"release_date\"              : np.dtype(str),\n",
    "      \"revenue\"                   : np.dtype(str),\n",
    "      \"runtime\"                   : np.dtype(str),\n",
    "      \"spoken_languages\"          : np.dtype(str),\n",
    "      \"status\"                    : np.dtype(str),\n",
    "      \"tagline\"                   : np.dtype(str),\n",
    "      \"title\"                     : np.dtype(str),\n",
    "      \"video\"                     : np.dtype(str),\n",
    "      \"vote_average\"              : np.dtype(str),\n",
    "      \"vote_count\"                : np.dtype(str),\n",
    "      },\n",
    "   names      = [\n",
    "      \"adult\", \"belongs_to_collection\", \"budget\", \"genres\", \"homepage\", \"id\", \"imdb_id\",\n",
    "      \"original_language\", \"original_title\", \"overview\", \"popularity\", \"poster_path\",\n",
    "      \"production_companies\", \"production_countries\", \"release_date\", \"revenue\", \"runtime\",\n",
    "      \"spoken_languages\", \"status\", \"tagline\", \"title\", \"video\", \"vote_average\", \"vote_count\",\n",
    "      ]\n",
    "   )   \n",
    "\n",
    "df_data.compute()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dab9a4-76a1-400c-83d3-2ead7cfe57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Initial look at the data, sanity check-\n",
    "#\n",
    "\n",
    "#  print(len(df_data.index))\n",
    "#     #\n",
    "#  print(tabulate(df_data.head(2), headers='keys', tablefmt='psql'))\n",
    "#  \n",
    "#  print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  45466\n",
    "#\n",
    "#  +----+---------+----------------------------------------------------------------------------------------------\n",
    "#  |    | adult   | belongs_to_collection                                                                       \n",
    "#  |----+---------+--------------------------------------------------------------------------------------------\n",
    "#  |  0 | False   | {'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg',\n",
    "#     'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'} | 30000000 | [{'id': 16, 'name': 'Animation'},\n",
    "#     {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]  | http://toystory.disney.com/toy-story |  862 |\n",
    "#     tt0114709 | en                  | Toy Story        | Led by Woody, Andy's toys live happily in his room until\n",
    "#        Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots\n",
    "#        against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put\n",
    "#        aside their differences.                                                                                             \n",
    "#     |      21.9469 | /rhIRbceoE9lR4veEXuwCC2wARtG.jpg | [{'name': 'Pixar Animation Studios', 'id': 3}]                                                                                      | [{'iso_3166_1': 'US', 'name': 'United States of America'}] | 1995-10-30     | 373554033 |        81 | [{'iso_639_1': 'en', 'name': 'English'}]                                          | Released | nan                                       | Toy Story | False   |            7.7 |         5415 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a827014-0911-4eb4-ab37-4fa6bf8453b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Drop unwanted columns\n",
    "#\n",
    "df_data2 = df_data[[\"id\", \"title\", \"overview\", \"tagline\", \"budget\", \"genres\",\n",
    "   \"popularity\", \"production_companies\", \"release_date\", \"revenue\", \"runtime\",\n",
    "   \"vote_average\", \"vote_count\", ]]\n",
    "\n",
    "df_data2.compute()\n",
    "\n",
    "#  print(tabulate(df_data2.head(2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33b3bd-a47c-4261-8319-f8da65ba271e",
   "metadata": {},
   "source": [
    "#  Check just genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed1a2a-6272-4951-8774-353ef2b2e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Check column type of genres\n",
    "#\n",
    "\n",
    "#  l_cntr = 0\n",
    "#     #\n",
    "#  for l_each in df_data2.itertuples():\n",
    "#     l_cntr += 1\n",
    "#     if (l_cntr < 3):\n",
    "#        print(type(l_each.genres))\n",
    "#        print(     l_each.genres )\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     <class 'str'>\n",
    "#     [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\n",
    "#     <class 'str'>\n",
    "#     [{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86d12b-b0e7-452b-a5a5-bf105bda91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  . Save the original 'genres' string as 'genres_str'.\n",
    "#  . Save the original 'genres' string as JSON, 'genres_json'.\n",
    "#  . Save the first 'genres.name' as 'genres_primary'.\n",
    "\n",
    "def f_genres_json(i_arg1):\n",
    "   try:\n",
    "      l_str1 = str(i_arg1)                                                  #  Needed this, was getting odd  json.loads()  errors otherwise\n",
    "      l_str2 = l_str1.replace(\"'\", \"\\\"\")\n",
    "      l_str3 = json.loads(l_str2)\n",
    "      l_return = l_str3\n",
    "   except:\n",
    "      l_return = json.loads('[{\"id\": 99999999, \"name\": \"Unknown\"}]')\n",
    "   return l_return\n",
    "\n",
    "def f_genres_primary(i_arg1):\n",
    "   try:\n",
    "      l_return = i_arg1[0][\"name\"]\n",
    "   except:\n",
    "      l_return = \"Unknown\"\n",
    "   return l_return\n",
    "\n",
    "def f_genres_primary_id(i_arg1):\n",
    "   try:\n",
    "      l_return = i_arg1[0][\"id\"]\n",
    "   except:\n",
    "      l_return = -1\n",
    "   return l_return\n",
    "\n",
    "#    The reason for the if is to prevent error upon multiple\n",
    "#    executions of this code.\n",
    "#\n",
    "if (\"genres_json\" not in df_data2):\n",
    "   df_data2[\"genres_json\"      ] = df_data2.genres.map     (lambda x: f_genres_json(x)       )\n",
    "      #\n",
    "   df_data2[\"genres_primary\"   ] = df_data2.genres_json.map(lambda x: f_genres_primary   (x) )\n",
    "   df_data2[\"genres_primary_id\"] = df_data2.genres_json.map(lambda x: f_genres_primary_id(x) )\n",
    "   print(\"--\")\n",
    "    \n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "#  l_cntr = 0\n",
    "#     #\n",
    "#  for l_each in df_data2.itertuples():\n",
    "#     l_cntr += 1\n",
    "#        #\n",
    "#     if (l_cntr < 3):\n",
    "#        print(type(l_each))\n",
    "#        print(     l_each )\n",
    "#        print(\"\")\n",
    "        \n",
    "#  Sample output,\n",
    "#\n",
    "#     <class 'pandas.core.frame.Pandas'>\n",
    "#     Pandas(Index=0, id='862', title='Toy Story', overview=\"Led by Woody, Andy's toys live happily in his room until Andy's birthday\n",
    "#        brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when\n",
    "#        circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\",\n",
    "#     tagline=nan, budget='30000000', genres=\"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751,\n",
    "#        'name': 'Family'}]\", popularity='21.946943', production_companies=\"[{'name': 'Pixar Animation Studios', 'id': 3}]\",\n",
    "#     release_date='1995-10-30', revenue='373554033', runtime='81.0', vote_average='7.7', vote_count='5415', \n",
    "#     genres_json=[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}],\n",
    "#     genres_primary='Animation', genres_primary_id=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e1f19-e1cd-4668-8e5b-57c72cc3e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Analysis on just genres- How many unique values do we have ?\n",
    "#\n",
    "#     .  Copy just genres_json into a new DataFrame. \n",
    "#     .  Extract all 'genres_json.name' from the JSON string into list.\n",
    "#     .  Pivot this list of genres names into separate rows.\n",
    "#     .  Count the unique genres names.\n",
    "\n",
    "\n",
    "df_genres = df_data2[[\"genres_json\"]]\n",
    "\n",
    "\n",
    "#  Convert the genres_json array of dictionaries into an array of just genres.names\n",
    "#\n",
    "def f_genres_arr(i_arg1):\n",
    "   l_arr  = []\n",
    "      #\n",
    "   try:\n",
    "      for l_each in i_arg1:\n",
    "         l_name = l_each[\"name\"]\n",
    "         l_arr += [l_name]\n",
    "      l_return = l_arr\n",
    "   except:\n",
    "      l_return = [ \"Unknown\" ]\n",
    "   return l_return\n",
    "\n",
    "df_genres[\"genres_names\"] = df_genres.genres_json.map(lambda x: f_genres_arr(x), meta=(\"genres_json\", \"object\"))\n",
    "\n",
    "\n",
    "#  Count the above with a group by, and sort\n",
    "#\n",
    "df_genres2 = df_genres.explode(\"genres_names\")\n",
    "   #\n",
    "df_genres3 = df_genres2.groupby(\"genres_names\")[\"genres_names\"].count().compute().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False)\n",
    "    \n",
    "\n",
    "#  Output for review\n",
    "#\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in df_genres3.itertuples():\n",
    "   l_cntr += 1\n",
    "      #\n",
    "   if (l_cntr < 50):\n",
    "      print(\"Genre name: %-48s  %d\" % (l_each.genres_names, l_each.count))\n",
    "        \n",
    "print(\"Total: %d\" % (len(df_genres3.index)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#  See how the above differs from df_data2.genres_primary\n",
    "#\n",
    "df_genres4 = df_data2.groupby(\"genres_primary\")[\"genres_primary\"].count().compute().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False)\n",
    "    \n",
    "\n",
    "#  Output for review\n",
    "#\n",
    "l_cntr = 0\n",
    "   #\n",
    "for l_each in df_genres4.itertuples():\n",
    "   l_cntr += 1\n",
    "      #\n",
    "   if (l_cntr < 50):\n",
    "      print(\"Genre name: %-48s  %d\" % (l_each.genres_primary, l_each.count))\n",
    " \n",
    "print(\"Total: %d\" % (len(df_genres4.index)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Genre name: Drama                                             20265\n",
    "#     Genre name: Comedy                                            13182\n",
    "#     Genre name: Thriller                                          7624\n",
    "#     Genre name: Romance                                           6735\n",
    "#     Genre name: Action                                            6596\n",
    "#     Genre name: Horror                                            4673\n",
    "#     Genre name: Crime                                             4307\n",
    "#     Genre name: Documentary                                       3932\n",
    "#     Genre name: Adventure                                         3496\n",
    "#     Genre name: Science Fiction                                   3049\n",
    "#     Genre name: Family                                            2770\n",
    "#     Genre name: Mystery                                           2467\n",
    "#     Genre name: Fantasy                                           2313\n",
    "#     Genre name: Animation                                         1935\n",
    "#     Genre name: Foreign                                           1622\n",
    "#     Genre name: Music                                             1598\n",
    "#     Genre name: History                                           1398\n",
    "#     Genre name: War                                               1323\n",
    "#     Genre name: Western                                           1042\n",
    "#     Genre name: TV Movie                                          767\n",
    "#     Genre name: Odyssey Media                                     1\n",
    "#     Genre name: Pulser Productions                                1\n",
    "#     Genre name: Rogue State                                       1\n",
    "#     Genre name: Vision View Entertainment                         1\n",
    "#     Genre name: Mardock Scramble Production Committee             1\n",
    "#     Genre name: Telescene Film Group Productions                  1\n",
    "#     Genre name: Sentai Filmworks                                  1\n",
    "#     Genre name: GoHands                                           1\n",
    "#     Genre name: Carousel Productions                              1\n",
    "#     Genre name: BROSTA TV                                         1\n",
    "#     Genre name: Aniplex                                           1\n",
    "#     Genre name: The Cartel                                        1\n",
    "#     Total: 32\n",
    "#     \n",
    "#     Genre name: Drama                                             11966\n",
    "#     Genre name: Comedy                                            8820\n",
    "#     Genre name: Action                                            4489\n",
    "#     Genre name: Documentary                                       3415\n",
    "#     Genre name: Horror                                            2619\n",
    "#     Genre name: Unknown                                           2442\n",
    "#     Genre name: Crime                                             1685\n",
    "#     Genre name: Thriller                                          1665\n",
    "#     Genre name: Adventure                                         1514\n",
    "#     Genre name: Romance                                           1191\n",
    "#     Genre name: Animation                                         1124\n",
    "#     Genre name: Fantasy                                           704\n",
    "#     Genre name: Science Fiction                                   647\n",
    "#     Genre name: Mystery                                           554\n",
    "#     Genre name: Family                                            524\n",
    "#     Genre name: Music                                             487\n",
    "#     Genre name: Western                                           451\n",
    "#     Genre name: TV Movie                                          390\n",
    "#     Genre name: War                                               379\n",
    "#     Genre name: History                                           279\n",
    "#     Genre name: Foreign                                           118\n",
    "#     Genre name: Carousel Productions                              1\n",
    "#     Genre name: Aniplex                                           1\n",
    "#     Genre name: Odyssey Media                                     1\n",
    "#     Total: 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72810a7-ad22-40fd-9d75-68b16dc05835",
   "metadata": {},
   "source": [
    "# Further checks, corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246361a1-5c88-43e8-81e1-f055baad77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Is movies.id  present, numeric ?\n",
    "\n",
    "#  l_cntr = 0\n",
    "#  l_fail = 0\n",
    "#     #\n",
    "#  l_set  = set()\n",
    "#     #\n",
    "#  for l_each in df_data2.itertuples():\n",
    "#     l_cntr += 1\n",
    "#     try:\n",
    "#        l_xxx   = int(l_each.id)\n",
    "#     except:\n",
    "#        print(\"Movie with bad id value: %s\" % (l_each.id) )\n",
    "#        l_set.add(l_each.id)\n",
    "#        l_fail+= 1\n",
    "\n",
    "#  print(\"Number of total Movies: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "#  print(\"\")\n",
    "\n",
    "\n",
    "#  Filter out those 'bad' movie id values\n",
    "#\n",
    "df_movies = df_data2[df_data2.id.str.isnumeric()]\n",
    "\n",
    "\n",
    "#  l_cntr = 0\n",
    "#  l_fail = 0\n",
    "#     #\n",
    "#  for l_each in df_movies.itertuples():\n",
    "#     l_cntr += 1\n",
    "#     try:\n",
    "#        l_xxx   = int(l_each.id)\n",
    "#     except:\n",
    "#        print(\"Movie with bad id value: %s\" % (l_each.id) )\n",
    "#        l_fail+= 1\n",
    "\n",
    "#  print(\"Number of total Movies: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "    \n",
    "    \n",
    "#  Sample output,\n",
    "#\n",
    "#     Movie with bad id value: 1997-08-20\n",
    "#     Movie with bad id value: 2012-09-29\n",
    "#     Movie with bad id value: 2014-01-01\n",
    "#     Number of total Movies: 45466  Number with numeric id: 45463   Number with a non-numeric id: 3\n",
    "#     \n",
    "#     Number of total Movies: 45463  Number with numeric id: 45463   Number with a non-numeric id: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267771f4-fc58-4d37-9a90-095e38d749de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Delete old/past DataFrames, release memory\n",
    "\n",
    "del df_data\n",
    "del df_data2\n",
    "#\n",
    "del df_genres\n",
    "del df_genres2\n",
    "del df_genres3\n",
    "del df_genres4\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0622f8f-36bf-497d-9797-04e1f5c7ee79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Checkpoint: our current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93e39c-5cba-444f-8cb9-969308215eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We have a DataFrame titled,  df_movies  with the following features,\n",
    "#\n",
    "#     id                         ..   8469\n",
    "#     title                      ..   Animal House\n",
    "#     overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                      the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                      have other plans for him.\"\n",
    "#     tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#     budget                     ..   2700000\n",
    "#     genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#     popularity                 ..   7.525382\n",
    "#     production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                         'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#     release_date               ..   1978-07-27\n",
    "#     revenue                    ..   141000000\n",
    "#     runtime                    ..   109.0\n",
    "#     vote_average               ..   7.0\n",
    "#     vote_count                 ..   420\n",
    "#\n",
    "#     genres_json                ..   (same as above, case as JSON/dictionary)\n",
    "#     genres_primary             ..   Just the first genres.name, a string\n",
    "#     genres_primary_id          ..   Just the first genres.id, an integer\n",
    "    \n",
    "    \n",
    "#  Currently, our GNN requires a bi-partitite graph. We have additional data\n",
    "#  sets for,\n",
    "#\n",
    "#        11_keywords.csv\n",
    "#        -----------------------------------------\n",
    "#           id                         ..   8469\n",
    "#           keywords                   ..   \"[{'id': 572, 'name': 'sex'}, {'id': 2483, 'name': 'nudity'},\n",
    "#                                             {'id': 3616, 'name': 'college'}, {'id': 157632, 'name': 'fraternity'},\n",
    "#                                             {'id': 158507, 'name': 'gross out comedy'}, {'id': 160450, 'name': 'dean'},\n",
    "#                                             {'id': 171400, 'name': 'fraternity house'}, {'id': 208983, 'name': 'probation'},\n",
    "#                                             {'id': 208992, 'name': '1960s'}, {'id': 209506, 'name': 'college freshman'},\n",
    "#                                             {'id': 236316, 'name': 'anarchic comedy'}]\"\n",
    "#\n",
    "#      From the above, the following is offered,\n",
    "#   \n",
    "#         ..  id  joins with movie.id\n",
    "#         ..  keywords.id  already enumerates keywords associated with the movies for us.\n",
    "#             Super handy.\n",
    "#\n",
    "#  .  We also have data for,\n",
    "# \n",
    "#        ..  12_Credits  (split into; Cast, Crew)\n",
    "#        ..  14|15_Ratings\n",
    "#        ..  16|17_(External) Links\n",
    "\n",
    "\n",
    "#  From here, we proceed with just  keywords\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bbf87-4a79-4f91-a585-97dbf50c2f65",
   "metadata": {},
   "source": [
    "# Work on Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c206abe-b7c9-4f24-9c38-bd59fde31526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Load DataFrame with raw input data\n",
    "\n",
    "l_InputFiles  = [\n",
    "   \"./02_Files/50_Keywords_00.txt\",\n",
    "]\n",
    "\n",
    "df_data = dd.read_csv(\n",
    "   l_InputFiles,\n",
    "   delimiter  = \",\",\n",
    "   skiprows   = 1,                                            #  Skip the first line of each file, since it's the column headers\n",
    "   dtype      = {\n",
    "      \"id\"                        : np.dtype(str),\n",
    "      \"keywords\"                  : np.dtype(str),            #  In the source CSV, this column was titled 'values', a bad idea\n",
    "      },\n",
    "   names      = [\n",
    "      \"id\", \"keywords\"\n",
    "      ]\n",
    "   )   \n",
    "\n",
    "df_data.compute()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadf6da-3e86-4d23-89a2-8a7b65b2a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Initial look at the data, sanity check-\n",
    "#\n",
    "\n",
    "#  print(len(df_data.index))\n",
    "#     #\n",
    "#  print(tabulate(df_data.head(2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "#  l_cntr = 0\n",
    "#  l_fail = 0\n",
    "#     #\n",
    "#  for l_each in df_data.itertuples():\n",
    "#     l_cntr += 1\n",
    "#     try:\n",
    "#        l_xxx   = int(l_each.id)\n",
    "#     except:\n",
    "#        print(\"Keyword with bad id value: %s\" % (l_each.id) )\n",
    "#        l_fail+= 1\n",
    "\n",
    "#  print(\"\")\n",
    "#     #\n",
    "#  print(\"Number of total Keywords: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "\n",
    "#  print(\"--\")\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     46419\n",
    "#     +----+------+------------------------------------------------------------------------------------------------------------------------------------\n",
    "#     |    |   id | keywords                                                                                                                                                                                                                                                                                                                   |\n",
    "#     |----+------+--------------------------------------------------------------------------------------------------------------------------------\n",
    "#     |  0 |  862 | [{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'},  ...\n",
    "#     |  1 | 8844 | [{'id': 10090, 'name': 'board game'}, {'id': 10941, 'name': 'disappearance'}, {'id': 15101, 'name': \"based on children's book\"},  ...\n",
    "#     +----+------+------------------------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#     Number of total Keywords: 46419  Number with numeric id: 46419   Number with a non-numeric id: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bca8a-48d1-4063-8f8f-2633be1b5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  In  df_data  (our Keywords), is a column titled, 'values'.\n",
    "#  This is an array of dictionaries that we will use for many purposes.\n",
    "#  As such, here, cast and copy it out to a new column titled,\n",
    "#  'keywords_json'.\n",
    "#\n",
    "\n",
    "def f_keywords_json(i_arg1):\n",
    "   try:\n",
    "      l_str1 = str(i_arg1)                                                  #  Needed this, was getting odd  json.loads()  errors otherwise\n",
    "      l_str2 = l_str1.replace(\"'\", \"\\\"\")\n",
    "      l_str3 = json.loads(l_str2)\n",
    "      l_return = l_str3\n",
    "   except:\n",
    "      l_return = json.loads('[{\"id\": 99999999, \"name\": \"Unknown\"}]')\n",
    "   return l_return\n",
    "\n",
    "#    The reason for the if is to prevent error upon multiple\n",
    "#    executions of this code.\n",
    "#\n",
    "if (\"keywords_json\" not in df_data):\n",
    "   df_data[\"keywords_json\"] = df_data.keywords.map(lambda x: f_keywords_json(x) )\n",
    "   print(\"--\")\n",
    "    \n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffcbf7-0857-42e2-9a74-2c0c0e355728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Build a new DataFrame with the unique Keywords. \n",
    "#\n",
    "#  We'll use this to count, but also this can be our list of node for the graph\n",
    "#  of Label, Keywords.\n",
    "\n",
    "df_keywords  = df_data.explode(keywords_json)\n",
    "   #\n",
    "df_keywords2 =  dd_[[\"state_code\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  def f_genres_arr(i_arg1):\n",
    "#     l_arr  = []\n",
    "#        #\n",
    "#     try:\n",
    "#        for l_each in i_arg1:\n",
    "#           l_id   = l_each[\"name\"]\n",
    "#           l_name = l_each[\"name\"]\n",
    "#           l_arr += [l_name]\n",
    "#        l_return = l_arr\n",
    "#     except:\n",
    "#        l_return = [ \"Unknown\" ]\n",
    "#     return l_return\n",
    "#  \n",
    "#  df_genres[\"genres_names\"] = df_genres.genres_json.map(lambda x: f_genres_arr(x), meta=(\"genres_json\", \"object\"))\n",
    "#  \n",
    "#  \n",
    "#  #  Count the above with a group by, and sort\n",
    "#  #\n",
    "#  df_genres2 = df_genres.explode(\"genres_names\")\n",
    "#     #\n",
    "#  df_genres3 = df_genres2.groupby(\"genres_names\")[\"genres_names\"].count().compute().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False)\n",
    "#      \n",
    "#  \n",
    "#  #  Output for review\n",
    "#  #\n",
    "#  l_cntr = 0\n",
    "#     #\n",
    "#  for l_each in df_genres3.itertuples():\n",
    "#     l_cntr += 1\n",
    "#        #\n",
    "#     if (l_cntr < 50):\n",
    "#        print(\"Genre name: %-48s  %d\" % (l_each.genres_names, l_each.count))\n",
    "#          \n",
    "#  print(\"Total: %d\" % (len(df_genres3.index)))\n",
    "#  print(\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8074a0-0eec-49b9-9d6a-23130f0804f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac69b-a821-4e3f-b0df-b0a035bcdadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4a4fd-8cac-4df1-91c7-8fcd37f81ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969fcc8-6696-488c-9304-05941fa1f2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf181b77-904a-4e79-a2b8-da70f48bc4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b6557-384c-4dcc-8eff-117f9345c5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e94ece-8ec6-4e57-adf5-fb82b42e7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec14ebd-74bc-40ac-9259-d0c936a2df86",
   "metadata": {},
   "source": [
    "#  Building the DataFrames that will go into the graph .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba0c9b-c187-4cfa-827f-11f112c85cb8",
   "metadata": {},
   "source": [
    "#  Our standard graph, Nodes/Edges .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b0c91-fde8-4fc0-ac76-9bcba213c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Our standard graph, Nodes\n",
    "\n",
    "df_movies    = df_data[[\"release_year\", \"title\", \"wiki_url\", \"plot\"]].compute()\n",
    "print(\"Movies...... \" + str(len(df_movies.index)))\n",
    "   #\n",
    "df_genres    = df_data[[\"genre\"  ]].drop_duplicates().compute()\n",
    "print(\"Genres...... \" + str(len(df_genres.index)))\n",
    "df_countries = df_data[[\"country\"]].drop_duplicates().compute()\n",
    "print(\"Countries... \" + str(len(df_countries.index)))\n",
    "   #\n",
    "df_persons   = df_data[[\"director\"]].drop_duplicates().compute()\n",
    "print(\"Persons..... \" + str(len(df_persons.index)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Our standard graph, Edges\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bfb01-0b17-48c0-8a63-05bc49f6a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Genres looks odd at 2000+ unique entries. Look deeper at that-\n",
    "#\n",
    "#  We'll write df_genres to a file local to the Jupyter Docker container, so we can view it in an editor\n",
    "\n",
    "df_genres.to_csv(\"02_Files/40_genres.txt\", index=None, sep=\"|\")\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#  genre\n",
    "#  unknown\n",
    "#  western\n",
    "#  comedy\n",
    "#  short\n",
    "#  short action/crime western\n",
    "#  short film\n",
    "#  biographical\n",
    "#  drama\n",
    "#  adventure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037f035-2a6a-4c42-af32-a3e9730b834a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38bd3-1c7e-46ba-9e2c-13b784052efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05070e73-8c0a-4fef-8bd8-c60e83b22b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e6482-1186-4a12-91cc-91580fded193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27725cb6-5404-4132-95e4-f26ea493e899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a009883-fadd-4dfe-9f83-efd5e4ef6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc3b51-a38f-406d-b4cb-4bcd13c5f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e9e29-c90b-4ed6-9997-db56ff225fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  This section; basic graph and database setup, reset for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfb83b-fd1f-46c3-96ad-95ceed14058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04909ce0-17bc-4214-84a7-3016cdbf52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb24521-9a8d-4fad-bdec-52876bc71e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6371d-6d53-4052-b895-f61c76b0792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE A GRAPH\n",
    "\n",
    "my_graph=my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f6eb7-59ef-4c9b-813a-e8370b25b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CONNECT TO GRAPH\n",
    "\n",
    "for l_graph in my_client.get_database(name=DB_NAME).graphs_in_database():\n",
    "   if (l_graph.name == GRAPH_NAME):\n",
    "      my_graph=my_client.get_database(name=DB_NAME).get_graph_by_id(id=l_graph.graph_id)\n",
    "         #\n",
    "      break\n",
    "\n",
    "# my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedb2fa-cec7-474a-acc2-5cefbbb3660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb5a2d-bddb-4bba-9169-e5dfc1d44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Load from source CSV, in this case we are using the Neo4J Movie graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ddce-66b8-43a8-b551-3a51a6983449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259d64d-c879-4e1f-ab10-6cf663b293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Nodes/Vertices\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/24_nodes.txt\"\n",
    "\n",
    "df_all_nodes1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"id\"        : int,\n",
    "      \"id\"        : np.dtype('O'),\n",
    "      \"_labels\"   : np.dtype('O'),\n",
    "      # \"born\"      : float, \n",
    "      \"born\"      : np.dtype('O'),\n",
    "      \"name\"      : np.dtype('O'),\n",
    "      # \"released\"  : float,\n",
    "      \"released\"  : np.dtype('O'),\n",
    "      \"tagline\"   : np.dtype('O'),\n",
    "      \"title\"     : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91245c1-9a0f-455b-b9c1-f975018d98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of rows, two different ways\n",
    "\n",
    "display(len(df_all_nodes1))\n",
    "display(print(\"{} Rows\".format(df_all_nodes1.shape[0].compute())))\n",
    "\n",
    "#  Other output\n",
    "\n",
    "display(df_all_nodes1.head(10))\n",
    "display(df_all_nodes1[[\"born\", \"name\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07d63f-9c74-43e8-ba54-cdbd6099e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print all rows, subsetted columns\n",
    "\n",
    "for l_each in df_all_nodes1.iterrows():\n",
    "   print(l_each[0], \"   \", l_each[1][\"_labels\"], \"   \", l_each[1][\"name\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490285c-abad-4c3b-804d-2534515c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#   https://www.askpython.com/python/examples/subset-a-dataframe\n",
    "#   https://www.codegrepper.com/code-examples/python/convert+float+to+int+python+pandas\n",
    "#   https://docs.dask.org/en/latest/generated/dask.dataframe.DataFrame.assign.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dc5f0-3ce2-4c47-8db4-0b7438277f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We have some issues we want to change with our data\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n",
    "#  .  The label values are currently \";Person\" and \";Movie\". Let's remove those semicolons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf635-c973-4c1d-91d4-36bc47eb5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Column renames\n",
    "\n",
    "df_all_nodes2 = df_all_nodes1.rename(columns={\"_id\": \"id\", \"_labels\": \"label\"})\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc357f2-0a17-42c9-ab81-3d984a1604b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Change float values to integer, remove leading semicolon from label\n",
    "\n",
    "df_all_nodes3 = df_all_nodes2.assign(\n",
    "   # born     = lambda x: x.born.fillna(0.0).astype(int), \n",
    "   born     = lambda x: x.born.fillna(0.0).astype(str), \n",
    "   # id       = lambda x: x.id.fillna(0.0).astype(int),\n",
    "   id       = lambda x: x.id.fillna(0.0).astype(str),\n",
    "   # released = lambda x: x.released.fillna(0.0).astype(int),\n",
    "   released = lambda x: x.released.fillna(0.0).astype(str),\n",
    "   label    = lambda x: x.label.astype(str).str[1:]\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485b323-6335-4dd2-8d63-dfbf7e845f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_nodes3))\n",
    "display(df_all_nodes3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e942-6083-4ddc-a55d-104bd0cf5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83330545-9507-4cef-831a-bb1ea802029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now, populate Persons and Movies\n",
    "\n",
    "df_persons = df_all_nodes3[df_all_nodes3[\"label\"] == \"Person\"][[\"id\", \"label\", \"born\", \"name\"]]\n",
    "\n",
    "df_movies  = df_all_nodes3[df_all_nodes3[\"label\"] == \"Movie\"][[\"id\", \"label\", \"released\", \"tagline\", \"title\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c958-2366-45e6-b316-6b30198858d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_persons))\n",
    "display(df_persons.head(10))\n",
    "display(len(df_movies))\n",
    "display(df_movies.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ec1d4-2f6a-42d7-b026-6d4db9979aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Repeat the style of work from above, but now for edges\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb9803-9e7b-4471-83ad-d279bb733d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Edges\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/25_edges.txt\"\n",
    "\n",
    "df_all_edges1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"_start\"    : float,\n",
    "      \"_start\"    : np.dtype('O'),\n",
    "      # \"_end\"      : float, \n",
    "      \"_end\"      : np.dtype('O'),\n",
    "      \"_type\"     : np.dtype('O'),\n",
    "      # \"rating\"    : float,\n",
    "      \"rating\"    : np.dtype('O'),\n",
    "      \"roles\"     : np.dtype('O'),\n",
    "      \"summary\"   : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fde9ff-5304-4d2c-b351-84fe21d97f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges1))\n",
    "display(df_all_edges1.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9356971-a6d7-4cba-ae07-cc0d693e39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_edges2 = df_all_edges1.rename(columns={\"_start\": \"START_ID\", \"_end\": \"END_ID\", \"_type\": \"TYPE\",\n",
    "   \"rating\": \"RATING\", \"roles\": \"ROLES\", \"summary\": \"SUMMARY\"})\n",
    "\n",
    "df_all_edges3 = df_all_edges2.assign(\n",
    "   # START_ID = lambda x: x.START_ID.fillna(0.0).astype(int), \n",
    "   START_ID = lambda x: x.START_ID.fillna(0.0).astype(str), \n",
    "   # END_ID   = lambda x: x.END_ID.fillna(0.0).astype(int),\n",
    "   END_ID   = lambda x: x.END_ID.fillna(0.0).astype(str),\n",
    "   # RATING   = lambda x: x.RATING.fillna(0.0).astype(int)\n",
    "   RATING   = lambda x: x.RATING.fillna(0.0).astype(str)\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddde16b-d104-4e12-aac2-40d6598ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges3))\n",
    "display(df_all_edges3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a838f-d161-4898-95ca-80f608fa82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split out the various edges\n",
    "\n",
    "df_reviewed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"REVIEWED\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]]\n",
    "\n",
    "df_wrote    = df_all_edges3[df_all_edges3[\"TYPE\"] == \"WROTE\"   ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_produced = df_all_edges3[df_all_edges3[\"TYPE\"] == \"PRODUCED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_directed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"DIRECTED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_follows  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"FOLLOWS\" ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "#  \"roles\" is a string similar to  '[ \"a\", \"b\", \"c\" ]'\n",
    "#\n",
    "#  This was automatically coming in as a list-\n",
    "#  Cool\n",
    "\n",
    "df_actedin  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"ACTED_IN\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f1fa7-3ac5-4eb9-a749-6f3d89267d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_reviewed))\n",
    "display(df_reviewed.head(2))\n",
    "\n",
    "display(len(df_wrote))\n",
    "display(df_wrote.head(2))\n",
    "\n",
    "display(len(df_produced))\n",
    "display(df_produced.head(2))\n",
    "\n",
    "display(len(df_directed))\n",
    "display(df_directed.head(2))\n",
    "\n",
    "display(len(df_follows))\n",
    "display(df_follows.head(2))\n",
    "\n",
    "display(len(df_actedin))\n",
    "display(df_actedin.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e959b0-0040-4556-a486-8267ae32c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47455c-f349-4c06-be7f-214e996a33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Didn't need this; also don't know if it had any effect\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=4, threads_per_worker=2)\n",
    "\n",
    "# print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba15117-b555-4953-8580-38e4222f4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Finally now, load the vertices/nodes into a graph\n",
    "#\n",
    "#  Some hinkiness we need to work around ..\n",
    "#\n",
    "#     .  The Dask DataFrames here were loaded from CSV, and those CSV\n",
    "#        files were found, in scope.\n",
    "#        The KG DataFrame importer will reference that same file\n",
    "#        pathname, and the file will not be in scope. Basically,\n",
    "#        it was expected that these files be on S3/GS all along.\n",
    "#        I hate to have that dependency because, just one more thing\n",
    "#        to have to manage.\n",
    "#\n",
    "#     .  So, we'll copy the DataFrames to Dask arrays, then back into\n",
    "#        a Dask DataFrame.\n",
    "#        Why not just copy the DaskDataFrame ?  Currently there is only \n",
    "#        shallow copies of DataFrames.\n",
    "#\n",
    "#  See,\n",
    "#     https://stackoverflow.com/questions/52119342/how-do-i-convert-a-dask-dataframe-into-a-dask-array\n",
    "#     https://docs.dask.org/en/latest/generated/dask.dataframe.from_dask_array.html\n",
    "\n",
    "\n",
    "da_persons    = df_persons.to_dask_array()\n",
    "da_movies     = df_movies.to_dask_array()\n",
    "   #\n",
    "da_directed   = df_directed.to_dask_array()\n",
    "da_reviewed   = df_reviewed.to_dask_array()\n",
    "da_wrote      = df_wrote.to_dask_array()\n",
    "da_produced   = df_produced.to_dask_array()\n",
    "da_follows    = df_follows.to_dask_array()\n",
    "da_actedin    = df_actedin.to_dask_array()\n",
    "\n",
    "\n",
    "df_persons2   = dd.io.from_dask_array(da_persons,  columns=[\"id\", \"label\", \"born\", \"name\"]).compute()\n",
    "df_movies2    = dd.io.from_dask_array(da_movies,   columns=[\"id\", \"label\", \"released\", \"tagline\", \"title\"]).compute()\n",
    "   #\n",
    "df_directed2  = dd.io.from_dask_array(da_directed, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_reviewed2  = dd.io.from_dask_array(da_reviewed, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]).compute()\n",
    "df_wrote2     = dd.io.from_dask_array(da_wrote, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_produced2  = dd.io.from_dask_array(da_produced, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_follows2   = dd.io.from_dask_array(da_follows, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_actedin2   = dd.io.from_dask_array(da_actedin, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]).compute()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060507c-c49f-4cda-92c0-a53752091fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from katana_enterprise.remote import import_data\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737ce45-e17f-49e4-ac98-af1dc3bf8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:\n",
    "    \n",
    "   # Person\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_persons2[[\"id\", \"label\", \"born\", \"name\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Person\"\n",
    "      )\n",
    "   #  Movie\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_movies2[[\"id\", \"label\", \"title\", \"tagline\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Movie\"\n",
    "      )  \n",
    "    \n",
    "   #  DIRECTED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_directed2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"DIRECTED\"\n",
    "      )\n",
    "   #  REVIEWED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_reviewed2[[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"REVIEWED\"\n",
    "      )\n",
    "   #  WROTE\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_wrote2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"WROTE\"\n",
    "      )\n",
    "   #  PRODUCED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_produced2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"PRODUCED\"\n",
    "      )\n",
    "   #  FOLLOWS\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_follows2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"FOLLOWS\"\n",
    "      )\n",
    "   #  ACTEDIN\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_actedin2[[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"ACTEDIN\"\n",
    "      )\n",
    "\n",
    "   df_importer.execute()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d9a40-4d2e-4972-9113-3084d2258d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (a) \n",
    "   WITH DISTINCT LABELS(a) AS temp, COUNT(a) AS tempCnt\n",
    "   UNWIND temp AS label\n",
    "   RETURN label, SUM(tempCnt) AS cnt\n",
    "   ORDER BY label\n",
    "   \n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef49e4-30e4-488c-963b-bf13c44e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (m)-[r]->(n) \n",
    "   WITH DISTINCT TYPE(r) AS temp, COUNT(r) AS tempCnt\n",
    "   RETURN temp, tempCnt\n",
    "   ORDER BY temp\n",
    "\n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550017-2685-48ed-994b-5a51395ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (x) -[r]-> (a)\n",
    "   RETURN x, r AS rel, a\n",
    "   \n",
    "   \"\"\",\n",
    "   contextualize=True)\n",
    "\n",
    "result.view()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb62f6-0d3f-4d22-924f-a2630e3405a7",
   "metadata": {},
   "source": [
    "# Output a graph as a a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800b8bb-11ec-4904-9217-51e56a5b9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Formatting could use a little work, but the concept is here ..\n",
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "   MATCH (n: Person) \n",
    "   RETURN n\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result1))\n",
    "\n",
    "l_result2 = my_graph.query(\"\"\"\n",
    "   MATCH (n) - [r: WROTE] -> (m)\n",
    "   RETURN r\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd62f55-1b27-43f1-bdc4-e1b79de25609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_nodes = []\n",
    "   #\n",
    "for l_node in l_result1.iterrows():\n",
    "   l_nodes.append(l_node)\n",
    "\n",
    "l_file = open(\"nodes.txt\", \"w\")\n",
    "l_file.write(str(l_nodes))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "l_edges = []\n",
    "   #\n",
    "for l_edge in l_result2.iterrows():\n",
    "   l_edges.append(l_edge)\n",
    "\n",
    "l_file = open(\"edges.txt\", \"w\")\n",
    "l_file.write(str(l_edges))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
