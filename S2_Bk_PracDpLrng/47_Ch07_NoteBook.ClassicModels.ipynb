{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data swets ..\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {},
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Exception reporting mode: Minimal\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "   ###\n",
    "\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "\n",
    "#  We use this object to store the history of results; display only\n",
    "#\n",
    "class MyHistory:\n",
    "  \n",
    "   __my_history = []\n",
    "    \n",
    "   def append(self, i_str):\n",
    "      self.__my_history.append(i_str)\n",
    "        \n",
    "   def clear(self):\n",
    "      self.__my_history = []\n",
    "        \n",
    "   def __str__(self):\n",
    "      return(str(self.__my_history))\n",
    "   \n",
    "\n",
    "l_history = MyHistory() \n",
    "\n",
    "\n",
    "#  The sklearn ML routines follow a very consistent pattern. As such, we\n",
    "#  put these in a function, reduce redundant code below-\n",
    "#\n",
    "\n",
    "def do_model(i_routine, i_train_data, i_train_labels, i_test_data, i_test_labels, i_name_of_test):\n",
    "\n",
    "   #  Train whatever model\n",
    "   #\n",
    "   i_routine.fit(i_train_data, i_train_labels)\n",
    "   \n",
    "   #  Predict on the test data\n",
    "   #\n",
    "   l_predicted_labels = i_routine.predict(i_test_data)\n",
    "   \n",
    "   #  Output results\n",
    "   #\n",
    "   print(\"   Actual    labels from test......... %s\" % (i_test_labels     ) )\n",
    "   print(\"   Predicted labels from test......... %s\" % (l_predicted_labels) )\n",
    "      #\n",
    "   print(\"      ###\")\n",
    "   print(\"   Accuracy: %0.4f %%\" % (i_routine.score(i_test_data, i_test_labels) * 100) )\n",
    "      #\n",
    "   print()\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d35158-a18a-47e5-8f6b-230f4a7f16a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c14ab-aed3-497b-be47-b92e1a44065b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e6d56-0c24-42be-b613-785a4fcc74de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {},
   "source": [
    "#  Step 01: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+-----------------+\n",
      "|   sl |   sw |   pl |   pw |   class_encoded |\n",
      "|------+------+------+------+-----------------|\n",
      "|  4.8 |  3   |  1.4 |  0.3 |               0 |\n",
      "|  4.9 |  3.1 |  1.5 |  0.1 |               0 |\n",
      "|  6.4 |  2.8 |  5.6 |  2.2 |               2 |\n",
      "|  6.7 |  3.1 |  4.7 |  1.5 |               1 |\n",
      "|  5.6 |  2.7 |  4.2 |  1.3 |               1 |\n",
      "+------+------+------+------+-----------------+\n",
      "Number of rows: 149\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows: 149   Training rows: 119   Test rows: 30\n",
      "\n",
      "Train data:\n",
      "[[6.1 2.9 4.7 1.4 1]\n",
      " [4.8 3.4 1.9 0.2 0]\n",
      " [5.2 3.5 1.5 0.2 0]\n",
      " [5 3.3 1.4 0.2 0]\n",
      " [4.6 3.1 1.5 0.2 0]]\n",
      "\n",
      "Test  data:\n",
      "[[5.1 3.4 1.5 0.2 0]\n",
      " [5.8 2.7 4.1 1 1]\n",
      " [6.5 3 5.5 1.8 2]\n",
      " [7.7 2.6 6.9 2.3 2]\n",
      " [5.5 2.6 4.4 1.2 1]]\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642d7fa-e89f-47c8-90c4-13e33fc2106c",
   "metadata": {},
   "source": [
    "#  Step 02: Iris Data train, test .. NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2d15b429-f361-434a-a3c4-f91f48d61824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual    labels from test......... [0 1 2 2 1 2 1 1 1 0 1 0 0 2 1 2 2 2 1 1 2 2 1 0 1 0 0 2 0 1]\n",
      "   Predicted labels from test......... [0 1 2 2 1 2 1 1 1 0 1 0 0 2 1 2 2 2 2 1 2 1 1 0 1 0 0 2 0 1]\n",
      "      ###\n",
      "   Accuracy: 93.3333 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model( NearestCentroid(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: Centroid\" ) \n",
    "    \n",
    "print(\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25a3d4-cf32-4503-8c86-e14146b7fa9d",
   "metadata": {},
   "source": [
    "#  Step 03: Iris Data train, test .. kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1202c-c630-4e27-aea8-4ed425b139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "#  The only line that differs between this cell and the one above, is\n",
    "#  the first line\n",
    "#\n",
    "\n",
    "my_model = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "\n",
    "#  train the model\n",
    "#\n",
    "my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "\n",
    "#  predict on the test data\n",
    "#\n",
    "l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "\n",
    "print(\"Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "print(\"Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "   #\n",
    "print()\n",
    "print(\"Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5328044-4f54-41b6-a37a-0f96a11e2250",
   "metadata": {},
   "source": [
    "#  Step 04: Iris Data train, test .. Naive Bayes, Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1740a-f656-4d6d-bdf3-cb2f053fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#  Naive Bayes, Gaussian\n",
    "#\n",
    "#     Gaussian does better than the Multinomial below because,\n",
    "#        Gaussian expects continuous values\n",
    "#        Multinomial expects discreet values\n",
    "#\n",
    "#     And our values are continuous\n",
    "#\n",
    "\n",
    "my_model = GaussianNB()\n",
    "\n",
    "\n",
    "#  train the model\n",
    "#\n",
    "my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "\n",
    "#  predict on the test data\n",
    "#\n",
    "l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "\n",
    "print(\"Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "print(\"Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "   #\n",
    "print()\n",
    "print(\"Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f815d9-6eb7-4aaa-863c-3c7ce613d127",
   "metadata": {},
   "source": [
    "#  Step 05: Iris Data train, test .. Naive Bayes, Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e0e-31d0-44c1-bdb3-0ee3c5ca3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Naive Bayes, Multinomial\n",
    "#\n",
    "\n",
    "my_model = MultinomialNB()\n",
    "\n",
    "\n",
    "#  train the model\n",
    "#\n",
    "my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "\n",
    "#  predict on the test data\n",
    "#\n",
    "l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "\n",
    "print(\"Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "print(\"Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "   #\n",
    "print()\n",
    "print(\"Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662897e8-2b96-4d7a-bf24-74aa2da5c006",
   "metadata": {},
   "source": [
    "#  Step 06: Iris Data train, test .. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb7874-3d2c-4f27-83db-147b953228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Decision Tree\n",
    "#\n",
    "\n",
    "my_model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "#  train the model\n",
    "#\n",
    "my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "\n",
    "#  predict on the test data\n",
    "#\n",
    "l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "\n",
    "print(\"Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "print(\"Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "   #\n",
    "print()\n",
    "print(\"Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5d6be-ecfa-4ca1-b518-0b37274c04de",
   "metadata": {},
   "source": [
    "#  Step 07: Iris Data train, test .. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a74fa-57c5-44ef-ade3-dd5438751064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  Random Forest\n",
    "#\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "my_model = RandomForestClassifier(n_estimators = 5)\n",
    "\n",
    "\n",
    "#  train the model\n",
    "#\n",
    "my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "\n",
    "#  predict on the test data\n",
    "#\n",
    "l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "\n",
    "print(\"Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "print(\"Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "   #\n",
    "print()\n",
    "print(\"Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7973bf-5a1a-4999-810d-91e52c13bd0b",
   "metadata": {},
   "source": [
    "#  Step 08: Iris Data train, test .. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0262-190c-455d-b2f9-99056c1bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "\n",
    "def do_model(arg1):\n",
    "\n",
    "   #  train the model\n",
    "   #\n",
    "   my_model.fit(np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1])\n",
    "   \n",
    "   #  predict on the test data\n",
    "   #\n",
    "   l_predicted_labels = my_model.predict( np_iris[\"test\" ][:, :4])\n",
    "   \n",
    "   print(\"   Actual    labels from test......... %s\" % (np_iris[\"test\" ][:, -1]) )\n",
    "   print(\"   Predicted labels from test......... %s\" % (l_predicted_labels)      )\n",
    "      #\n",
    "   print(\"      ###\")\n",
    "   print(\"   Accuracy: %0.4f %%\" % (my_model.score(np_iris[\"test\" ][:, :4], np_iris[\"test\" ][:, -1]) * 100) )\n",
    "      #\n",
    "   print()\n",
    "    \n",
    "    \n",
    "       ############################\n",
    "        \n",
    "\n",
    "#  C      ==  margin constant\n",
    "#  gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "my_model = SVC(kernel = \"linear\", C = 1.0)\n",
    "   #\n",
    "print(\"Linear...\")\n",
    "do_model(my_model)\n",
    "\n",
    "my_model = SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25 )\n",
    "   #\n",
    "print(\"RBF......\")\n",
    "do_model(my_model)\n",
    "\n",
    "my_model = SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001)\n",
    "   #\n",
    "print(\"RBF 2....\")\n",
    "do_model(my_model)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45c758-b0db-43dd-9aa7-832598413085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n",
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4cf6a-434a-4fcf-bfdb-edc3308c5252",
   "metadata": {},
   "source": [
    "#  Step 09:  Breast Cancer Data load, encode, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe262a-4fb5-4954-9d6f-c8cbea09d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Breast Cancer data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1)     ID number\n",
    "#     2)     Diagnosis (M = malignant, B = benign)\n",
    "#     3-32)\n",
    "#       Ten real-valued features are computed for each cell nucleus:\n",
    "#     \n",
    "#     \ta) radius (mean of distances from center to points on the perimeter)\n",
    "#     \tb) texture (standard deviation of gray-scale values)\n",
    "#     \tc) perimeter\n",
    "#     \td) area\n",
    "#     \te) smoothness (local variation in radius lengths)\n",
    "#     \tf) compactness (perimeter^2 / area - 1.0)\n",
    "#     \tg) concavity (severity of concave portions of the contour)\n",
    "#     \th) concave points (number of concave portions of the contour)\n",
    "#     \ti) symmetry \n",
    "#     \tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized count of rows\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05409-32ac-4da0-bd05-6d97b35df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd0d81-78de-444f-8d29-2b58552ec119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "\ta) radius (mean of distances from center to points on the perimeter)\n",
    "\tb) texture (standard deviation of gray-scale values)\n",
    "\tc) perimeter\n",
    "\td) area\n",
    "\te) smoothness (local variation in radius lengths)\n",
    "\tf) compactness (perimeter^2 / area - 1.0)\n",
    "\tg) concavity (severity of concave portions of the contour)\n",
    "\th) concave points (number of concave portions of the contour)\n",
    "\ti) symmetry \n",
    "\tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37e56f-cca5-4af4-9bb5-89be55420d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff57e71-9dc7-4e7c-9e6c-eb447e07867a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
