{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfd2274-8be4-4517-a0bb-e5bf3e9370a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Part 00: Notebook overview .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f14aa-01d9-4d3c-9986-a42fa4b15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This Notebook is part of a set that demonstrate GNN using a movie dataset.\n",
    "#  About this Notebook,\n",
    "#\n",
    "#  .  There was a Kaggle GNN challenge circa 2019 detailed here,\n",
    "#        https://www.kaggle.com/c/movie-genre-classification/data\n",
    "#\n",
    "#     That data is locked down, but a similarly themed dataset also on \n",
    "#     Kaggle is here,\n",
    "#        https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
    "#\n",
    "#     The above is the data set in use here.\n",
    "#\n",
    "#     Basically we mung input data, and create graphs.\n",
    "#\n",
    "#\n",
    "#  .  1 GB, plus or minus. Most of that volume comes from reviews. The\n",
    "#     movies run 30-40 MB, and the cast and crew about 190 MB.\n",
    "#\n",
    "#     The data is CSV, with embedded arrays of JSON.\n",
    "#     To remove dependencies on GS/S3 hosted data, this program expects this\n",
    "#     data to be local to the container hosting this Jupyter Notebook.\n",
    "#\n",
    "#     Since we host on GitHub, and GitHub has a 25 MB file size limit,\n",
    "#     the total data set is now split across multiple files.\n",
    "#\n",
    "#  .  The existing schema for just Movies is listed here,\n",
    "#  \n",
    "#        10_movies_metadata.csv\n",
    "#        -----------------------------------------\n",
    "#           adult                      ..   False\n",
    "#           belongs_to_collection      ..\n",
    "#           budget                     ..   2700000\n",
    "#           genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#           homepage                   ..   http://www.animalhouse.com/\n",
    "#           id                         ..   8469\n",
    "#           imdb_id                    ..   tt0077975\n",
    "#           original_language          ..   en\n",
    "#           original_title             ..   Animal House\n",
    "#           overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                            the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                            have other plans for him.\"\n",
    "#           popularity                 ..   7.525382\n",
    "#           poster_path                ..   /AuJkgAh7zAGsm7Oo3CGyDtYvzg0.jpg\n",
    "#           production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                               'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#           production_countries       ..   \"[{'iso_3166_1': 'US', 'name': 'United States of America'}]\"\n",
    "#           release_date               ..   1978-07-27\n",
    "#           revenue                    ..   141000000\n",
    "#           runtime                    ..   109.0\n",
    "#           spoken_languages           ..   \"[{'iso_639_1': 'en', 'name': 'English'}]\"\n",
    "#           status                     ..   Released\n",
    "#           tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#           title                      ..   Animal House\n",
    "#           video                      ..   False\n",
    "#           vote_average               ..   7.0\n",
    "#           vote_count                 ..   420\n",
    "#\n",
    "#     From the above, we load the following into a DataFrame of Movies nodes,\n",
    "#\n",
    "#           id                         ..   8469\n",
    "#           title                      ..   Animal House\n",
    "#           genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#           overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                            the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                            have other plans for him.\"\n",
    "#           tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#\n",
    "#           popularity                 ..   7.525382\n",
    "#           production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                               'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#           release_date               ..   1978-07-27\n",
    "#           revenue                    ..   141000000\n",
    "#           runtime                    ..   109.0\n",
    "#           spoken_languages           ..   \"[{'iso_639_1': 'en', 'name': 'English'}]\"\n",
    "#           vote_average               ..   7.0\n",
    "#           vote_count                 ..   420\n",
    "#\n",
    "#      Notice the following from above,\n",
    "#\n",
    "#         ..  genres is an array of JSON, with each genre being unique identified via a numeric.\n",
    "#             We will take the first genre and put it into a property on each node titled, primary_genre.\n",
    "#         ..  We will leave all remaining JSON untouched, stored as strings.\n",
    "\n",
    "\n",
    "#  .  The existing schema is for Keywords is listed here,\n",
    "#\n",
    "#        11_keywords.csv\n",
    "#        -----------------------------------------\n",
    "#           id                         ..   8469\n",
    "#           keywords                   ..   \"[{'id': 572, 'name': 'sex'}, {'id': 2483, 'name': 'nudity'},\n",
    "#                                             {'id': 3616, 'name': 'college'}, {'id': 157632, 'name': 'fraternity'},\n",
    "#                                             {'id': 158507, 'name': 'gross out comedy'}, {'id': 160450, 'name': 'dean'},\n",
    "#                                             {'id': 171400, 'name': 'fraternity house'}, {'id': 208983, 'name': 'probation'},\n",
    "#                                             {'id': 208992, 'name': '1960s'}, {'id': 209506, 'name': 'college freshman'},\n",
    "#                                             {'id': 236316, 'name': 'anarchic comedy'}]\"\n",
    "#\n",
    "#      From the above, the following is offered,\n",
    "#   \n",
    "#         ..  id  joins with  movie.id\n",
    "#         ..  keywords.id  already enumerates keywords associated with the movies for us.\n",
    "#             Super handy.\n",
    "\n",
    "\n",
    "#  .  We also have data for,\n",
    "# \n",
    "#        ..  12_Credits  (split into; Cast, Crew)\n",
    "#        ..  14|15_Ratings\n",
    "#        ..  16|17_(External) Links\n",
    "#\n",
    "#     And will likely add these at a later date.\n",
    "\n",
    "\n",
    "#  Below we continue by loading the raw data, and performing some validations on\n",
    "#  statements made, assumptions, and similar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a2149-2554-45a3-be06-8e2ebea43932",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Part 01: Load just Movies into a DataFrame, perform basic/sanity-check analysis \n",
    "\n",
    "Enter:  \n",
    "   (Nothing)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be86887d-60ed-489b-89f6-3591d7c0cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "MY_DEBUG = True\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a874df7-993f-404d-aa53-c8ca266f40a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "   #\n",
    "import json\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338c62ab-efc7-44de-ac83-4a0cd23f27da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Load DataFrame with raw input data associated with Movies\n",
    "\n",
    "l_InputFiles  = [\n",
    "   \"./02_Files/40_Movies_01.txt\",\n",
    "   \"./02_Files/41_Movies_02.txt\",\n",
    "]\n",
    "\n",
    "df_data = dd.read_csv(\n",
    "   l_InputFiles,\n",
    "   delimiter  = \",\",\n",
    "   skiprows   = 1,                                            #  Skip the first line of each file, since it's the column headers\n",
    "   dtype      = {\n",
    "      \"adult\"                     : np.dtype(str),\n",
    "      \"belongs_to_collection\"     : np.dtype(str),\n",
    "      \"budget\"                    : np.dtype(str),\n",
    "      \"genres\"                    : np.dtype(str),\n",
    "      \"homepage\"                  : np.dtype(str),\n",
    "      \"id\"                        : np.dtype(str),\n",
    "      \"imdb_id\"                   : np.dtype(str),\n",
    "      \"original_language\"         : np.dtype(str),\n",
    "      \"original_title\"            : np.dtype(str),\n",
    "      \"overview\"                  : np.dtype(str),\n",
    "      \"popularity\"                : np.dtype(str),\n",
    "      \"poster_path\"               : np.dtype(str),\n",
    "      \"production_companies\"      : np.dtype(str),\n",
    "      \"production_countries\"      : np.dtype(str),\n",
    "      \"release_date\"              : np.dtype(str),\n",
    "      \"revenue\"                   : np.dtype(str),\n",
    "      \"runtime\"                   : np.dtype(str),\n",
    "      \"spoken_languages\"          : np.dtype(str),\n",
    "      \"status\"                    : np.dtype(str),\n",
    "      \"tagline\"                   : np.dtype(str),\n",
    "      \"title\"                     : np.dtype(str),\n",
    "      \"video\"                     : np.dtype(str),\n",
    "      \"vote_average\"              : np.dtype(str),\n",
    "      \"vote_count\"                : np.dtype(str),\n",
    "      },\n",
    "   names      = [\n",
    "      \"adult\", \"belongs_to_collection\", \"budget\", \"genres\", \"homepage\", \"id\", \"imdb_id\",\n",
    "      \"original_language\", \"original_title\", \"overview\", \"popularity\", \"poster_path\",\n",
    "      \"production_companies\", \"production_countries\", \"release_date\", \"revenue\", \"runtime\",\n",
    "      \"spoken_languages\", \"status\", \"tagline\", \"title\", \"video\", \"vote_average\", \"vote_count\",\n",
    "      ]\n",
    "   )   \n",
    "\n",
    "df_data.compute()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55dab9a4-76a1-400c-83d3-2ead7cfe57e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Movies: 45466\n",
      "+----+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------------------------------------------------------------------------------------------------+--------------------------------------+------+-----------+---------------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------------+-----------+-----------+-----------------------------------------------------------------------------------+----------+-------------------------------------------+-----------+---------+----------------+--------------+\n",
      "|    | adult   | belongs_to_collection                                                                                                                                 |   budget | genres                                                                                            | homepage                             |   id | imdb_id   | original_language   | original_title   | overview                                                                                                                                                                                                                                                                                                                                                                                                    |   popularity | poster_path                      | production_companies                                                                                                                | production_countries                                       | release_date   |   revenue |   runtime | spoken_languages                                                                  | status   | tagline                                   | title     | video   |   vote_average |   vote_count |\n",
      "|----+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------------------------------------------------------------------------------------------------+--------------------------------------+------+-----------+---------------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------------+-----------+-----------+-----------------------------------------------------------------------------------+----------+-------------------------------------------+-----------+---------+----------------+--------------|\n",
      "|  0 | False   | {'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg', 'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'} | 30000000 | [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]  | http://toystory.disney.com/toy-story |  862 | tt0114709 | en                  | Toy Story        | Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.                                                                                             |      21.9469 | /rhIRbceoE9lR4veEXuwCC2wARtG.jpg | [{'name': 'Pixar Animation Studios', 'id': 3}]                                                                                      | [{'iso_3166_1': 'US', 'name': 'United States of America'}] | 1995-10-30     | 373554033 |        81 | [{'iso_639_1': 'en', 'name': 'English'}]                                          | Released | nan                                       | Toy Story | False   |            7.7 |         5415 |\n",
      "|  1 | False   | nan                                                                                                                                                   | 65000000 | [{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}] | nan                                  | 8844 | tt0113497 | en                  | Jumanji          | When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures. |      17.0155 | /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg | [{'name': 'TriStar Pictures', 'id': 559}, {'name': 'Teitler Film', 'id': 2550}, {'name': 'Interscope Communications', 'id': 10201}] | [{'iso_3166_1': 'US', 'name': 'United States of America'}] | 1995-12-15     | 262797249 |       104 | [{'iso_639_1': 'en', 'name': 'English'}, {'iso_639_1': 'fr', 'name': 'FranÃ§ais'}] | Released | Roll the dice and unleash the excitement! | Jumanji   | False   |            6.9 |         2413 |\n",
      "+----+---------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------+---------------------------------------------------------------------------------------------------+--------------------------------------+------+-----------+---------------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------------+-----------+-----------+-----------------------------------------------------------------------------------+----------+-------------------------------------------+-----------+---------+----------------+--------------+\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Initial look at the data, sanity check-\n",
    "#\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   print(\"Count of Movies: %d\" % (len(df_data.index)))\n",
    "      #\n",
    "   print(tabulate(df_data.head(2), headers='keys', tablefmt='psql'))\n",
    "   \n",
    "   print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  Count of Movies: 45466\n",
    "#\n",
    "#  +----+---------+----------------------------------------------------------------------------------------------\n",
    "#  |    | adult   | belongs_to_collection                                                                       \n",
    "#  |----+---------+--------------------------------------------------------------------------------------------\n",
    "#  |  0 | False   | {'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg',\n",
    "#     'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'} | 30000000 | [{'id': 16, 'name': 'Animation'},\n",
    "#     {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]  | http://toystory.disney.com/toy-story |  862 |\n",
    "#     tt0114709 | en                  | Toy Story        | Led by Woody, Andy's toys live happily in his room until\n",
    "#        Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots\n",
    "#        against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put\n",
    "#        aside their differences.                                                                                             \n",
    "#     |      21.9469 | /rhIRbceoE9lR4veEXuwCC2wARtG.jpg | [{'name': 'Pixar Animation Studios', 'id': 3}]                                                                                      | [{'iso_3166_1': 'US', 'name': 'United States of America'}] | 1995-10-30     | 373554033 |        81 | [{'iso_639_1': 'en', 'name': 'English'}]                                          | Released | nan                                       | Toy Story | False   |            7.7 |         5415 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a827014-0911-4eb4-ab37-4fa6bf8453b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['title', 'overview', 'tagline', 'budget', 'genres', 'popularity', 'production_companies', 'release_date', 'revenue', 'runtime', 'vote_average', 'vote_count'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#  Drop unwanted columns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m \u001b[43mdf_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtagline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbudget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpopularity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduction_companies\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelease_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrevenue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruntime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvote_average\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvote_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m df_movies\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m      9\u001b[0m    \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py:4486\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4480\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m   4482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   4483\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_dask_collection(key) \u001b[38;5;129;01mand\u001b[39;00m (is_series_like(key) \u001b[38;5;129;01mor\u001b[39;00m is_index_like(key))\n\u001b[1;32m   4484\u001b[0m ):\n\u001b[1;32m   4485\u001b[0m     \u001b[38;5;66;03m# error is raised from pandas\u001b[39;00m\n\u001b[0;32m-> 4486\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4488\u001b[0m     dsk \u001b[38;5;241m=\u001b[39m partitionwise_graph(operator\u001b[38;5;241m.\u001b[39mgetitem, name, \u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m   4489\u001b[0m     graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(name, dsk, dependencies\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3464\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3463\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3464\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3466\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[1;32m   1318\u001b[0m ):\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['title', 'overview', 'tagline', 'budget', 'genres', 'popularity', 'production_companies', 'release_date', 'revenue', 'runtime', 'vote_average', 'vote_count'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "#  Drop unwanted columns\n",
    "#\n",
    "\n",
    "df_movies = df_data[[\"id\", \"title\", \"overview\", \"tagline\", \"budget\", \"genres\",\n",
    "   \"popularity\", \"production_companies\", \"release_date\", \"revenue\", \"runtime\",\n",
    "   \"vote_average\", \"vote_count\", ]]\n",
    "\n",
    "df_movies.compute()\n",
    "   #\n",
    "del df_data\n",
    "\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   print(tabulate(df_movies.head(2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33b3bd-a47c-4261-8319-f8da65ba271e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Part 02: Check just Genres, a column in Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ed1a2a-6272-4951-8774-353ef2b2e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\n",
      "<class 'str'>\n",
      "[{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Check column type of genres\n",
    "#\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "      #\n",
    "   for l_each in df_movies.itertuples():\n",
    "      l_cntr += 1\n",
    "      if (l_cntr < 3):\n",
    "         print(type(l_each.genres))\n",
    "         print(     l_each.genres )\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     <class 'str'>\n",
    "#     [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\n",
    "#     <class 'str'>\n",
    "#     [{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c86d12b-b0e7-452b-a5a5-bf105bda91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.Pandas'>\n",
      "Pandas(Index=0, id='862', title='Toy Story', overview=\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\", tagline=nan, budget='30000000', genres=\"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\", popularity='21.946943', production_companies=\"[{'name': 'Pixar Animation Studios', 'id': 3}]\", release_date='1995-10-30', revenue='373554033', runtime='81.0', vote_average='7.7', vote_count='5415', genres_json=[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}], genres_primary='Animation', genres_primary_id=16)\n",
      "\n",
      "<class 'pandas.core.frame.Pandas'>\n",
      "Pandas(Index=1, id='8844', title='Jumanji', overview=\"When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.\", tagline='Roll the dice and unleash the excitement!', budget='65000000', genres=\"[{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]\", popularity='17.015539', production_companies=\"[{'name': 'TriStar Pictures', 'id': 559}, {'name': 'Teitler Film', 'id': 2550}, {'name': 'Interscope Communications', 'id': 10201}]\", release_date='1995-12-15', revenue='262797249', runtime='104.0', vote_average='6.9', vote_count='2413', genres_json=[{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}], genres_primary='Adventure', genres_primary_id=12)\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  . Save the original 'genres' string as JSON, 'genres_json'.\n",
    "#  . Save the first 'genres.name' as 'genres_primary'.\n",
    "#  . Save the first 'genres.id'   as 'genres_primary_id'.\n",
    "\n",
    "\n",
    "def f_genres_json(i_arg1):\n",
    "   try:\n",
    "      l_str1 = str(i_arg1)                                                  #  Needed this, was getting odd  json.loads()  errors otherwise\n",
    "      l_str2 = l_str1.replace(\"'\", \"\\\"\")\n",
    "      l_str3 = json.loads(l_str2)\n",
    "      l_return = l_str3\n",
    "   except:\n",
    "      l_return = json.loads('[{\"id\": 99999999, \"name\": \"Unknown\"}]')\n",
    "   return l_return\n",
    "\n",
    "\n",
    "def f_genres_primary(i_arg1):\n",
    "   try:\n",
    "      l_return = i_arg1[0][\"name\"]\n",
    "   except:\n",
    "      l_return = \"Unknown\"\n",
    "   return l_return\n",
    "\n",
    "\n",
    "def f_genres_primary_id(i_arg1):\n",
    "   try:\n",
    "      l_return = i_arg1[0][\"id\"]\n",
    "   except:\n",
    "      l_return = -1\n",
    "   return l_return\n",
    "\n",
    "\n",
    "df_movies[\"genres_json\"      ] = df_movies.genres.map     (lambda x: f_genres_json(x)       )\n",
    "   #\n",
    "df_movies[\"genres_primary\"   ] = df_movies.genres_json.map(lambda x: f_genres_primary   (x) )\n",
    "df_movies[\"genres_primary_id\"] = df_movies.genres_json.map(lambda x: f_genres_primary_id(x) )\n",
    "    \n",
    "    \n",
    "if (MY_DEBUG):\n",
    "\n",
    "   l_cntr = 0\n",
    "      #\n",
    "   for l_each in df_movies.itertuples():\n",
    "      l_cntr += 1\n",
    "         #\n",
    "      if (l_cntr < 3):\n",
    "         print(type(l_each))\n",
    "         print(     l_each )\n",
    "         print(\"\")\n",
    "        \n",
    "#  Sample output,\n",
    "#\n",
    "#     <class 'pandas.core.frame.Pandas'>\n",
    "#     Pandas(Index=0, id='862', title='Toy Story', overview=\"Led by Woody, Andy's toys live happily in his room until Andy's birthday\n",
    "#        brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when\n",
    "#        circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\",\n",
    "#     tagline=nan, budget='30000000', genres=\"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751,\n",
    "#        'name': 'Family'}]\", popularity='21.946943', production_companies=\"[{'name': 'Pixar Animation Studios', 'id': 3}]\",\n",
    "#     release_date='1995-10-30', revenue='373554033', runtime='81.0', vote_average='7.7', vote_count='5415', \n",
    "#     genres_json=[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}],\n",
    "#     genres_primary='Animation', genres_primary_id=16)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8e1f19-e1cd-4668-8e5b-57c72cc3e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All   Genre entries for all movies ..\n",
      "-------------------------------\n",
      "Genre name: Drama                                             20265\n",
      "Genre name: Comedy                                            13182\n",
      "Genre name: Thriller                                          7624\n",
      "Genre name: Romance                                           6735\n",
      "Total: 32\n",
      "\n",
      "First Genre entry   for all movies ..\n",
      "-------------------------------\n",
      "Genre name: Drama                                             11966\n",
      "Genre name: Comedy                                            8820\n",
      "Genre name: Action                                            4489\n",
      "Genre name: Documentary                                       3415\n",
      "Total: 24\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Analysis on just genres- How many unique values do we have ?\n",
    "#\n",
    "#     .  Copy just  Movies.genres_json  into a new DataFrame. \n",
    "#     .  Extract all  'Movies.genres_json.name'  from the JSON string into list.\n",
    "#     .  Pivot this list of genres names into separate rows.\n",
    "#     .  Count the unique genres names.\n",
    "\n",
    "\n",
    "df_genres = df_movies[[\"genres_json\"]]\n",
    "\n",
    "\n",
    "#  Convert the genres_json array of dictionaries into an array of just genres.names\n",
    "#\n",
    "def f_genres_arr(i_arg1):\n",
    "   l_arr  = []\n",
    "      #\n",
    "   try:\n",
    "      for l_each in i_arg1:\n",
    "         l_name = l_each[\"name\"]\n",
    "         l_arr += [l_name]\n",
    "      l_return = l_arr\n",
    "   except:\n",
    "      l_return = [ \"Unknown\" ]\n",
    "   return l_return\n",
    "\n",
    "df_genres[\"genres_names\"] = df_genres.genres_json.map(lambda x: f_genres_arr(x), meta=(\"genres_json\", \"object\"))\n",
    "\n",
    "\n",
    "#  Count the above with a group by, and sort\n",
    "#\n",
    "df_genres2 = df_genres.explode(\"genres_names\")\n",
    "   #\n",
    "df_genres3 = df_genres2.groupby(\"genres_names\")[\"genres_names\"].count().compute().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False)\n",
    "    \n",
    "\n",
    "#  Output for review\n",
    "#\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "   print(\"All   Genre entries for all movies ..\")\n",
    "   print(\"-------------------------------\")\n",
    "      #\n",
    "   for l_each in df_genres3.itertuples():\n",
    "      l_cntr += 1\n",
    "         #\n",
    "      if (l_cntr < 5):\n",
    "         print(\"Genre name: %-48s  %d\" % (l_each.genres_names, l_each.count))\n",
    "           \n",
    "   print(\"Total: %d\" % (len(df_genres3.index)))\n",
    "   print(\"\")\n",
    "\n",
    "\n",
    "      ########################################\n",
    "\n",
    "\n",
    "#  See how the above differs from df_data2.genres_primary\n",
    "#\n",
    "df_genres4 = df_movies.groupby(\"genres_primary\")[\"genres_primary\"].count().compute().reset_index(name=\"count\").sort_values(by=\"count\", ascending=False)\n",
    "    \n",
    "\n",
    "#  Output for review\n",
    "#\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "   print(\"First Genre entry   for all movies ..\")\n",
    "   print(\"-------------------------------\")\n",
    "      #\n",
    "   for l_each in df_genres4.itertuples():\n",
    "      l_cntr += 1\n",
    "         #\n",
    "      if (l_cntr < 5):\n",
    "         print(\"Genre name: %-48s  %d\" % (l_each.genres_primary, l_each.count))\n",
    "    \n",
    "   print(\"Total: %d\" % (len(df_genres4.index)))\n",
    "   print(\"\")\n",
    "    \n",
    "    \n",
    "del df_genres\n",
    "del df_genres2\n",
    "del df_genres3\n",
    "del df_genres4\n",
    "   #\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Genre name: Drama                                             20265\n",
    "#     Genre name: Comedy                                            13182\n",
    "#     Genre name: Thriller                                          7624\n",
    "#     Genre name: Romance                                           6735\n",
    "#     Genre name: Action                                            6596\n",
    "#     Genre name: Horror                                            4673\n",
    "#     Genre name: Crime                                             4307\n",
    "#     Genre name: Documentary                                       3932\n",
    "#     Genre name: Adventure                                         3496\n",
    "#     Genre name: Science Fiction                                   3049\n",
    "#     Genre name: Family                                            2770\n",
    "#     Genre name: Mystery                                           2467\n",
    "#     Genre name: Fantasy                                           2313\n",
    "#     Genre name: Animation                                         1935\n",
    "#     Genre name: Foreign                                           1622\n",
    "#     Genre name: Music                                             1598\n",
    "#     Genre name: History                                           1398\n",
    "#     Genre name: War                                               1323\n",
    "#     Genre name: Western                                           1042\n",
    "#     Genre name: TV Movie                                          767\n",
    "#     Genre name: Odyssey Media                                     1\n",
    "#     Genre name: Pulser Productions                                1\n",
    "#     Genre name: Rogue State                                       1\n",
    "#     Genre name: Vision View Entertainment                         1\n",
    "#     Genre name: Mardock Scramble Production Committee             1\n",
    "#     Genre name: Telescene Film Group Productions                  1\n",
    "#     Genre name: Sentai Filmworks                                  1\n",
    "#     Genre name: GoHands                                           1\n",
    "#     Genre name: Carousel Productions                              1\n",
    "#     Genre name: BROSTA TV                                         1\n",
    "#     Genre name: Aniplex                                           1\n",
    "#     Genre name: The Cartel                                        1\n",
    "#     Total: 32\n",
    "#     \n",
    "#     Genre name: Drama                                             11966\n",
    "#     Genre name: Comedy                                            8820\n",
    "#     Genre name: Action                                            4489\n",
    "#     Genre name: Documentary                                       3415\n",
    "#     Genre name: Horror                                            2619\n",
    "#     Genre name: Unknown                                           2442\n",
    "#     Genre name: Crime                                             1685\n",
    "#     Genre name: Thriller                                          1665\n",
    "#     Genre name: Adventure                                         1514\n",
    "#     Genre name: Romance                                           1191\n",
    "#     Genre name: Animation                                         1124\n",
    "#     Genre name: Fantasy                                           704\n",
    "#     Genre name: Science Fiction                                   647\n",
    "#     Genre name: Mystery                                           554\n",
    "#     Genre name: Family                                            524\n",
    "#     Genre name: Music                                             487\n",
    "#     Genre name: Western                                           451\n",
    "#     Genre name: TV Movie                                          390\n",
    "#     Genre name: War                                               379\n",
    "#     Genre name: History                                           279\n",
    "#     Genre name: Foreign                                           118\n",
    "#     Genre name: Carousel Productions                              1\n",
    "#     Genre name: Aniplex                                           1\n",
    "#     Genre name: Odyssey Media                                     1\n",
    "#     Total: 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72810a7-ad22-40fd-9d75-68b16dc05835",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 03: Further checks, corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246361a1-5c88-43e8-81e1-f055baad77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with bad id value: 1997-08-20\n",
      "Movie with bad id value: 2012-09-29\n",
      "Movie with bad id value: 2014-01-01\n",
      "\n",
      "Number of total Movies: 45466  Number with numeric id: 45463   Number with a non-numeric id: 3\n",
      "\n",
      "Number of total Movies: 45463  Number with numeric id: 45463   Number with a non-numeric id: 0\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Is movies.id  present, numeric ?\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "   l_fail = 0\n",
    "      #\n",
    "   for l_each in df_movies.itertuples():\n",
    "      l_cntr += 1\n",
    "      try:\n",
    "         l_xxx   = int(l_each.id)\n",
    "      except:\n",
    "         print(\"Movie with bad id value: %s\" % (l_each.id) )\n",
    "         l_fail+= 1\n",
    "\n",
    "   print(\"\")\n",
    "   print(\"Number of total Movies: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "   print(\"\")\n",
    "\n",
    "\n",
    "#  Filter out those 'bad' movie id values\n",
    "#\n",
    "df_movies = df_movies[df_movies.id.str.isnumeric()]\n",
    "\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "   l_fail = 0\n",
    "      #\n",
    "   for l_each in df_movies.itertuples():\n",
    "      l_cntr += 1\n",
    "      try:\n",
    "         l_xxx   = int(l_each.id)\n",
    "      except:\n",
    "         print(\"Movie with bad id value: %s\" % (l_each.id) )\n",
    "         l_fail+= 1\n",
    "\n",
    "   print(\"Number of total Movies: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "    \n",
    "    \n",
    "#  Sample output,\n",
    "#\n",
    "#     Movie with bad id value: 1997-08-20\n",
    "#     Movie with bad id value: 2012-09-29\n",
    "#     Movie with bad id value: 2014-01-01\n",
    "#\n",
    "#     Number of total Movies: 45466  Number with numeric id: 45463   Number with a non-numeric id: 3\n",
    "#     \n",
    "#     Number of total Movies: 45463  Number with numeric id: 45463   Number with a non-numeric id: 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0622f8f-36bf-497d-9797-04e1f5c7ee79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Part 00: Checkpoint our current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93e39c-5cba-444f-8cb9-969308215eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We have a DataFrame titled,  df_movies  with the following features,\n",
    "#\n",
    "#     id                         ..   8469\n",
    "#     title                      ..   Animal House\n",
    "#     overview                   ..   \"At a 1962 College, Dean Vernon Wormer is determined to expel\n",
    "#                                      the entire Delta Tau Chi Fraternity, but those troublemakers\n",
    "#                                      have other plans for him.\"\n",
    "#     tagline                    ..   It was the Deltas against the rules... the rules lost!\n",
    "#     budget                     ..   2700000\n",
    "#     genres                     ..   \"[{'id': 35, 'name': 'Comedy'}]\"\n",
    "#     popularity                 ..   7.525382\n",
    "#     production_companies       ..   \"[{'name': 'Universal Pictures', 'id': 33}, {'name': 'Oregon Film Factory',\n",
    "#                                         'id': 13298}, {'name': 'Stage III Productions', 'id': 13300}]\"\n",
    "#     release_date               ..   1978-07-27\n",
    "#     revenue                    ..   141000000\n",
    "#     runtime                    ..   109.0\n",
    "#     vote_average               ..   7.0\n",
    "#     vote_count                 ..   420\n",
    "#\n",
    "#     genres_json                ..   (same as above, case as JSON/dictionary)\n",
    "#     genres_primary             ..   Just the first genres.name, a string\n",
    "#     genres_primary_id          ..   Just the first genres.id, an integer\n",
    "    \n",
    "    \n",
    "#  Currently, one use case for GNN requires a bi-partitite graph. We have additional data\n",
    "#  sets for,\n",
    "#\n",
    "#        11_keywords.csv\n",
    "#        -----------------------------------------\n",
    "#           id                         ..   8469\n",
    "#           keywords                   ..   \"[{'id': 572, 'name': 'sex'}, {'id': 2483, 'name': 'nudity'},\n",
    "#                                             {'id': 3616, 'name': 'college'}, {'id': 157632, 'name': 'fraternity'},\n",
    "#                                             {'id': 158507, 'name': 'gross out comedy'}, {'id': 160450, 'name': 'dean'},\n",
    "#                                             {'id': 171400, 'name': 'fraternity house'}, {'id': 208983, 'name': 'probation'},\n",
    "#                                             {'id': 208992, 'name': '1960s'}, {'id': 209506, 'name': 'college freshman'},\n",
    "#                                             {'id': 236316, 'name': 'anarchic comedy'}]\"\n",
    "#\n",
    "#      From the above, the following is offered,\n",
    "#   \n",
    "#         ..  id  joins with movie.id\n",
    "#         ..  keywords.id  already enumerates keywords associated with the movies for us.\n",
    "#             Super handy.\n",
    "#\n",
    "#  .  We also have data for,\n",
    "# \n",
    "#        ..  12_Credits  (split into; Cast, Crew)\n",
    "#        ..  14|15_Ratings\n",
    "#        ..  16|17_(External) Links\n",
    "\n",
    "\n",
    "#  From here, we proceed with just  keywords\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bbf87-4a79-4f91-a585-97dbf50c2f65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 04: Work on Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c206abe-b7c9-4f24-9c38-bd59fde31526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Load DataFrame with raw input data\n",
    "\n",
    "l_InputFiles  = [\n",
    "   \"./02_Files/50_Keywords_00.txt\",\n",
    "]\n",
    "\n",
    "df_data = dd.read_csv(\n",
    "   l_InputFiles,\n",
    "   delimiter  = \",\",\n",
    "   skiprows   = 1,                                            #  Skip the first line of each file, since it's the column headers\n",
    "   dtype      = {\n",
    "      \"id\"                        : np.dtype(str),\n",
    "      \"keywords\"                  : np.dtype(str),            #  In the source CSV, this column was titled 'values', a bad idea\n",
    "      },\n",
    "   names      = [\n",
    "      \"id\", \"keywords\"\n",
    "      ]\n",
    "   )   \n",
    "\n",
    "df_data.compute()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fadf6da-3e86-4d23-89a2-8a7b65b2a661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keywords: 46419\n",
      "+----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    |   id | keywords                                                                                                                                                                                                                                                                                                                   |\n",
      "|----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 |  862 | [{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'}, {'id': 9713, 'name': 'friends'}, {'id': 9823, 'name': 'rivalry'}, {'id': 165503, 'name': 'boy next door'}, {'id': 170722, 'name': 'new toy'}, {'id': 187065, 'name': 'toy comes to life'}] |\n",
      "|  1 | 8844 | [{'id': 10090, 'name': 'board game'}, {'id': 10941, 'name': 'disappearance'}, {'id': 15101, 'name': \"based on children's book\"}, {'id': 33467, 'name': 'new home'}, {'id': 158086, 'name': 'recluse'}, {'id': 158091, 'name': 'giant insect'}]                                                                             |\n",
      "+----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "Number of total Keywords: 46419  Number with numeric id: 46419   Number with a non-numeric id: 0\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Initial look at the data, sanity check-\n",
    "#\n",
    "\n",
    "if(MY_DEBUG):\n",
    "   print(\"Number of keywords: %d\" % len(df_data.index))\n",
    "      #\n",
    "   print(tabulate(df_data.head(2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "   l_cntr = 0\n",
    "   l_fail = 0\n",
    "      #\n",
    "   for l_each in df_data.itertuples():\n",
    "      l_cntr += 1\n",
    "      try:\n",
    "         l_xxx   = int(l_each.id)\n",
    "      except:\n",
    "         print(\"Keyword with bad id value: %s\" % (l_each.id) )\n",
    "         l_fail+= 1\n",
    "\n",
    "   print(\"\")\n",
    "      #\n",
    "   print(\"Number of total Keywords: %d  Number with numeric id: %d   Number with a non-numeric id: %d\" % (l_cntr, (l_cntr - l_fail), l_fail ))\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     46419\n",
    "#     +----+------+------------------------------------------------------------------------------------------------------------------------------------\n",
    "#     |    |   id | keywords                                                                                                                                                                                                                                                                                                                   |\n",
    "#     |----+------+--------------------------------------------------------------------------------------------------------------------------------\n",
    "#     |  0 |  862 | [{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'},  ...\n",
    "#     |  1 | 8844 | [{'id': 10090, 'name': 'board game'}, {'id': 10941, 'name': 'disappearance'}, {'id': 15101, 'name': \"based on children's book\"},  ...\n",
    "#     +----+------+------------------------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#     Number of total Keywords: 46419  Number with numeric id: 46419   Number with a non-numeric id: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159bca8a-48d1-4063-8f8f-2633be1b5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  In  df_data  (our Keywords), is a column titled, 'keywords'.\n",
    "#  This is an array of dictionaries that we will use for many purposes.\n",
    "#  As such, here, cast and copy it out to a new column titled,\n",
    "#  'keywords_json'.\n",
    "#\n",
    "\n",
    "def f_keywords_json(i_arg1):\n",
    "   try:\n",
    "      l_str1 = str(i_arg1)                                                  #  Needed this, was getting odd  json.loads()  errors otherwise\n",
    "      l_str2 = l_str1.replace(\"'\", \"\\\"\")\n",
    "      l_str3 = json.loads(l_str2)\n",
    "      l_return = l_str3\n",
    "   except:\n",
    "      l_return = json.loads('[{\"id\": 99999999, \"name\": \"Unknown\"}]')\n",
    "   return l_return\n",
    "\n",
    "df_data[\"keywords_json\"] = df_data.keywords.map(lambda x: f_keywords_json(x) )\n",
    "    \n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ffcbf7-0857-42e2-9a74-2c0c0e355728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input records: 46419      When pivoted out: 168018     When de-duplicated: 19424   \n",
      "\n",
      "Pandas(Index=0, keywords_str=\"{'id': 931, 'name': 'jealousy'}\")\n",
      "Pandas(Index=0, keywords_str=\"{'id': 4290, 'name': 'toy'}\")\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Build a new DataFrame with the unique Keywords. \n",
    "#\n",
    "#  We'll use this to count, but also this can be our list of nodes for the graph\n",
    "#  of Label, Keywords.\n",
    "\n",
    "\n",
    "#  Here is our pivot\n",
    "#\n",
    "df_keywords  = df_data[[\"keywords_json\"]]\n",
    "df_keywords2 = df_keywords.explode(\"keywords_json\")\n",
    "   #\n",
    "df_keywords2[\"keywords_str\"] = df_keywords2.keywords_json.map(lambda x: str(x) )\n",
    "   #\n",
    "df_keywords3 =  df_keywords2[[\"keywords_str\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"Number of input records: %-8d   When pivoted out: %-8d   When de-duplicated: %-8d\" % ( len(df_keywords.index), len(df_keywords2.index), len(df_keywords3.index) ))\n",
    "\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "   print(\"\")\n",
    "      #\n",
    "   for l_each in df_keywords3.itertuples():\n",
    "      l_cntr += 1\n",
    "         #\n",
    "      if (l_cntr < 3):\n",
    "         print(l_each)\n",
    "\n",
    "del  df_keywords\n",
    "del  df_keywords2\n",
    "del  df_keywords3\n",
    "    \n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     Number of input records: 46419      When pivoted out: 168018     When de-duplicated: 19424   \n",
    "#     \n",
    "#     Pandas(Index=0, keywords_str=\"{'id': 931, 'name': 'jealousy'}\")\n",
    "#     Pandas(Index=0, keywords_str=\"{'id': 4290, 'name': 'toy'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac69b-a821-4e3f-b0df-b0a035bcdadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We need a different pivot to build the edge between Movies and Keywords\n",
    "#\n",
    "\n",
    "df_edge  = df_data[[\"id\", \"keywords_json\"]]\n",
    "   #\n",
    "df_edge2 = df_edge.explode(\"keywords_json\")\n",
    "\n",
    "\n",
    "if (MY_DEBUG):\n",
    "   l_cntr = 0\n",
    "      #\n",
    "   for l_each in df_edge2.itertuples():\n",
    "      l_cntr += 1\n",
    "      if (l_cntr < 40):\n",
    "         print(l_each)\n",
    "    \n",
    "#  Sample output,\n",
    "#\n",
    "#     Pandas(Index=0, id='862', keywords_json={'id': 931, 'name': 'jealousy'})\n",
    "#     Pandas(Index=0, id='862', keywords_json={'id': 4290, 'name': 'toy'})\n",
    "#        ...\n",
    "#     Pandas(Index=0, id='862', keywords_json={'id': 187065, 'name': 'toy comes to life'})\n",
    "#     Pandas(Index=1, id='8844', keywords_json={'id': 99999999, 'name': 'Unknown'})\n",
    "#     Pandas(Index=2, id='15602', keywords_json={'id': 1495, 'name': 'fishing'})\n",
    "#     Pandas(Index=2, id='15602', keywords_json={'id': 12392, 'name': 'best friend'})\n",
    "#        ...\n",
    "#     Pandas(Index=2, id='15602', keywords_json={'id': 208510, 'name': 'old men'})\n",
    "#     Pandas(Index=3, id='31357', keywords_json={'id': 818, 'name': 'based on novel'})\n",
    "#     Pandas(Index=3, id='31357', keywords_json={'id': 10131, 'name': 'interracial relationship'})\n",
    "\n",
    "\n",
    "def f_keyword_id(i_arg1):\n",
    "   try:\n",
    "      l_str1 = str(i_arg1) \n",
    "      l_str2 = l_str1.replace(\"'\", \"\\\"\")\n",
    "      l_str3 = json.loads(l_str2)\n",
    "         #\n",
    "      l_return = l_str3[\"id\"]\n",
    "   except:\n",
    "      l_return = -1\n",
    "          \n",
    "   return l_return\n",
    "\n",
    "\n",
    "df_edge2[\"movie_id\"  ] = df_edge2.id.map(lambda x: x)\n",
    "   #\n",
    "df_edge2[\"keyword_id\"] = df_edge2.keywords_json.map(lambda x: f_keyword_id(x) )\n",
    "   #\n",
    "df_edge3 = df_edge2[[\"movie_id\", \"keyword_id\"]]\n",
    "   #\n",
    "df_edge4 = df_edge3.drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"Number of input records: %-8d   When pivoted out: %-8d   When de-duplicated: %-8d\" % ( len(df_edge.index), len(df_edge2.index), len(df_edge4.index) ))\n",
    "print(\"\")\n",
    "\n",
    "#  l_cntr = 0\n",
    "#     #\n",
    "#  for l_each in df_edge3.itertuples():\n",
    "#     l_cntr += 1\n",
    "#        #\n",
    "#     if (l_cntr < 3):\n",
    "#        print(l_each)\n",
    "        \n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "# Sample output,\n",
    "#\n",
    "#     Number of input records: 46419      When pivoted out: 168018     When de-duplicated: 165494  \n",
    "#\n",
    "#     Pandas(Index=0, movie_id='862', keyword_id=931)\n",
    "#     Pandas(Index=0, movie_id='862', keyword_id=4290)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724f0c5-1669-4ede-9648-0f497c45cfc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 00: Checkpoint our current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8074a0-0eec-49b9-9d6a-23130f0804f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  df_movies  is our Movie DataFrame\n",
    "#\n",
    "print(\"Number of Movies: %d\" % (len(df_movies.index) ))\n",
    "   #\n",
    "print(tabulate(df_movies.head(2), headers='keys', tablefmt='psql'))\n",
    "print(\"\")\n",
    "\n",
    "#  df_keywords2  is our Keywords DataFrame\n",
    "#\n",
    "print(\"Number of Keywords: %d\" % (len(df_keywords2.index) ))\n",
    "   #\n",
    "print(tabulate(df_keywords2.head(2), headers='keys', tablefmt='psql'))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9417163-054c-4b1b-be69-04af4b48d147",
   "metadata": {},
   "source": [
    "#  Prepare for Graph DataFrame import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4a4fd-8cac-4df1-91c7-8fcd37f81ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Delete old/past DataFrames, release memory\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969fcc8-6696-488c-9304-05941fa1f2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf181b77-904a-4e79-a2b8-da70f48bc4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b6557-384c-4dcc-8eff-117f9345c5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e94ece-8ec6-4e57-adf5-fb82b42e7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec14ebd-74bc-40ac-9259-d0c936a2df86",
   "metadata": {},
   "source": [
    "#  Building the DataFrames that will go into the graph .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba0c9b-c187-4cfa-827f-11f112c85cb8",
   "metadata": {},
   "source": [
    "#  Our standard graph, Nodes/Edges .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b0c91-fde8-4fc0-ac76-9bcba213c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Our standard graph, Nodes\n",
    "\n",
    "df_movies    = df_data[[\"release_year\", \"title\", \"wiki_url\", \"plot\"]].compute()\n",
    "print(\"Movies...... \" + str(len(df_movies.index)))\n",
    "   #\n",
    "df_genres    = df_data[[\"genre\"  ]].drop_duplicates().compute()\n",
    "print(\"Genres...... \" + str(len(df_genres.index)))\n",
    "df_countries = df_data[[\"country\"]].drop_duplicates().compute()\n",
    "print(\"Countries... \" + str(len(df_countries.index)))\n",
    "   #\n",
    "df_persons   = df_data[[\"director\"]].drop_duplicates().compute()\n",
    "print(\"Persons..... \" + str(len(df_persons.index)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Our standard graph, Edges\n",
    "\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bfb01-0b17-48c0-8a63-05bc49f6a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Genres looks odd at 2000+ unique entries. Look deeper at that-\n",
    "#\n",
    "#  We'll write df_genres to a file local to the Jupyter Docker container, so we can view it in an editor\n",
    "\n",
    "df_genres.to_csv(\"02_Files/40_genres.txt\", index=None, sep=\"|\")\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#  genre\n",
    "#  unknown\n",
    "#  western\n",
    "#  comedy\n",
    "#  short\n",
    "#  short action/crime western\n",
    "#  short film\n",
    "#  biographical\n",
    "#  drama\n",
    "#  adventure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037f035-2a6a-4c42-af32-a3e9730b834a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38bd3-1c7e-46ba-9e2c-13b784052efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05070e73-8c0a-4fef-8bd8-c60e83b22b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e6482-1186-4a12-91cc-91580fded193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27725cb6-5404-4132-95e4-f26ea493e899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a009883-fadd-4dfe-9f83-efd5e4ef6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc3b51-a38f-406d-b4cb-4bcd13c5f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e9e29-c90b-4ed6-9997-db56ff225fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  This section; basic graph and database setup, reset for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfb83b-fd1f-46c3-96ad-95ceed14058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04909ce0-17bc-4214-84a7-3016cdbf52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb24521-9a8d-4fad-bdec-52876bc71e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6371d-6d53-4052-b895-f61c76b0792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE A GRAPH\n",
    "\n",
    "my_graph=my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f6eb7-59ef-4c9b-813a-e8370b25b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CONNECT TO GRAPH\n",
    "\n",
    "for l_graph in my_client.get_database(name=DB_NAME).graphs_in_database():\n",
    "   if (l_graph.name == GRAPH_NAME):\n",
    "      my_graph=my_client.get_database(name=DB_NAME).get_graph_by_id(id=l_graph.graph_id)\n",
    "         #\n",
    "      break\n",
    "\n",
    "# my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedb2fa-cec7-474a-acc2-5cefbbb3660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb5a2d-bddb-4bba-9169-e5dfc1d44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Load from source CSV, in this case we are using the Neo4J Movie graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ddce-66b8-43a8-b551-3a51a6983449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259d64d-c879-4e1f-ab10-6cf663b293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Nodes/Vertices\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/24_nodes.txt\"\n",
    "\n",
    "df_all_nodes1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"id\"        : int,\n",
    "      \"id\"        : np.dtype('O'),\n",
    "      \"_labels\"   : np.dtype('O'),\n",
    "      # \"born\"      : float, \n",
    "      \"born\"      : np.dtype('O'),\n",
    "      \"name\"      : np.dtype('O'),\n",
    "      # \"released\"  : float,\n",
    "      \"released\"  : np.dtype('O'),\n",
    "      \"tagline\"   : np.dtype('O'),\n",
    "      \"title\"     : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91245c1-9a0f-455b-b9c1-f975018d98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of rows, two different ways\n",
    "\n",
    "display(len(df_all_nodes1))\n",
    "display(print(\"{} Rows\".format(df_all_nodes1.shape[0].compute())))\n",
    "\n",
    "#  Other output\n",
    "\n",
    "display(df_all_nodes1.head(10))\n",
    "display(df_all_nodes1[[\"born\", \"name\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07d63f-9c74-43e8-ba54-cdbd6099e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print all rows, subsetted columns\n",
    "\n",
    "for l_each in df_all_nodes1.iterrows():\n",
    "   print(l_each[0], \"   \", l_each[1][\"_labels\"], \"   \", l_each[1][\"name\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490285c-abad-4c3b-804d-2534515c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#   https://www.askpython.com/python/examples/subset-a-dataframe\n",
    "#   https://www.codegrepper.com/code-examples/python/convert+float+to+int+python+pandas\n",
    "#   https://docs.dask.org/en/latest/generated/dask.dataframe.DataFrame.assign.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dc5f0-3ce2-4c47-8db4-0b7438277f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We have some issues we want to change with our data\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n",
    "#  .  The label values are currently \";Person\" and \";Movie\". Let's remove those semicolons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf635-c973-4c1d-91d4-36bc47eb5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Column renames\n",
    "\n",
    "df_all_nodes2 = df_all_nodes1.rename(columns={\"_id\": \"id\", \"_labels\": \"label\"})\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc357f2-0a17-42c9-ab81-3d984a1604b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Change float values to integer, remove leading semicolon from label\n",
    "\n",
    "df_all_nodes3 = df_all_nodes2.assign(\n",
    "   # born     = lambda x: x.born.fillna(0.0).astype(int), \n",
    "   born     = lambda x: x.born.fillna(0.0).astype(str), \n",
    "   # id       = lambda x: x.id.fillna(0.0).astype(int),\n",
    "   id       = lambda x: x.id.fillna(0.0).astype(str),\n",
    "   # released = lambda x: x.released.fillna(0.0).astype(int),\n",
    "   released = lambda x: x.released.fillna(0.0).astype(str),\n",
    "   label    = lambda x: x.label.astype(str).str[1:]\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485b323-6335-4dd2-8d63-dfbf7e845f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_nodes3))\n",
    "display(df_all_nodes3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e942-6083-4ddc-a55d-104bd0cf5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83330545-9507-4cef-831a-bb1ea802029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now, populate Persons and Movies\n",
    "\n",
    "df_persons = df_all_nodes3[df_all_nodes3[\"label\"] == \"Person\"][[\"id\", \"label\", \"born\", \"name\"]]\n",
    "\n",
    "df_movies  = df_all_nodes3[df_all_nodes3[\"label\"] == \"Movie\"][[\"id\", \"label\", \"released\", \"tagline\", \"title\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c958-2366-45e6-b316-6b30198858d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_persons))\n",
    "display(df_persons.head(10))\n",
    "display(len(df_movies))\n",
    "display(df_movies.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ec1d4-2f6a-42d7-b026-6d4db9979aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Repeat the style of work from above, but now for edges\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb9803-9e7b-4471-83ad-d279bb733d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load a DataFrame from CSV, Edges\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/25_edges.txt\"\n",
    "\n",
    "df_all_edges1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"_start\"    : float,\n",
    "      \"_start\"    : np.dtype('O'),\n",
    "      # \"_end\"      : float, \n",
    "      \"_end\"      : np.dtype('O'),\n",
    "      \"_type\"     : np.dtype('O'),\n",
    "      # \"rating\"    : float,\n",
    "      \"rating\"    : np.dtype('O'),\n",
    "      \"roles\"     : np.dtype('O'),\n",
    "      \"summary\"   : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fde9ff-5304-4d2c-b351-84fe21d97f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges1))\n",
    "display(df_all_edges1.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9356971-a6d7-4cba-ae07-cc0d693e39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_edges2 = df_all_edges1.rename(columns={\"_start\": \"START_ID\", \"_end\": \"END_ID\", \"_type\": \"TYPE\",\n",
    "   \"rating\": \"RATING\", \"roles\": \"ROLES\", \"summary\": \"SUMMARY\"})\n",
    "\n",
    "df_all_edges3 = df_all_edges2.assign(\n",
    "   # START_ID = lambda x: x.START_ID.fillna(0.0).astype(int), \n",
    "   START_ID = lambda x: x.START_ID.fillna(0.0).astype(str), \n",
    "   # END_ID   = lambda x: x.END_ID.fillna(0.0).astype(int),\n",
    "   END_ID   = lambda x: x.END_ID.fillna(0.0).astype(str),\n",
    "   # RATING   = lambda x: x.RATING.fillna(0.0).astype(int)\n",
    "   RATING   = lambda x: x.RATING.fillna(0.0).astype(str)\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddde16b-d104-4e12-aac2-40d6598ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges3))\n",
    "display(df_all_edges3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a838f-d161-4898-95ca-80f608fa82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split out the various edges\n",
    "\n",
    "df_reviewed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"REVIEWED\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]]\n",
    "\n",
    "df_wrote    = df_all_edges3[df_all_edges3[\"TYPE\"] == \"WROTE\"   ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_produced = df_all_edges3[df_all_edges3[\"TYPE\"] == \"PRODUCED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_directed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"DIRECTED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_follows  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"FOLLOWS\" ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "#  \"roles\" is a string similar to  '[ \"a\", \"b\", \"c\" ]'\n",
    "#\n",
    "#  This was automatically coming in as a list-\n",
    "#  Cool\n",
    "\n",
    "df_actedin  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"ACTED_IN\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f1fa7-3ac5-4eb9-a749-6f3d89267d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_reviewed))\n",
    "display(df_reviewed.head(2))\n",
    "\n",
    "display(len(df_wrote))\n",
    "display(df_wrote.head(2))\n",
    "\n",
    "display(len(df_produced))\n",
    "display(df_produced.head(2))\n",
    "\n",
    "display(len(df_directed))\n",
    "display(df_directed.head(2))\n",
    "\n",
    "display(len(df_follows))\n",
    "display(df_follows.head(2))\n",
    "\n",
    "display(len(df_actedin))\n",
    "display(df_actedin.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e959b0-0040-4556-a486-8267ae32c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47455c-f349-4c06-be7f-214e996a33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Didn't need this; also don't know if it had any effect\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=4, threads_per_worker=2)\n",
    "\n",
    "# print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba15117-b555-4953-8580-38e4222f4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Finally now, load the vertices/nodes into a graph\n",
    "#\n",
    "#  Some hinkiness we need to work around ..\n",
    "#\n",
    "#     .  The Dask DataFrames here were loaded from CSV, and those CSV\n",
    "#        files were found, in scope.\n",
    "#        The KG DataFrame importer will reference that same file\n",
    "#        pathname, and the file will not be in scope. Basically,\n",
    "#        it was expected that these files be on S3/GS all along.\n",
    "#        I hate to have that dependency because, just one more thing\n",
    "#        to have to manage.\n",
    "#\n",
    "#     .  So, we'll copy the DataFrames to Dask arrays, then back into\n",
    "#        a Dask DataFrame.\n",
    "#        Why not just copy the DaskDataFrame ?  Currently there is only \n",
    "#        shallow copies of DataFrames.\n",
    "#\n",
    "#  See,\n",
    "#     https://stackoverflow.com/questions/52119342/how-do-i-convert-a-dask-dataframe-into-a-dask-array\n",
    "#     https://docs.dask.org/en/latest/generated/dask.dataframe.from_dask_array.html\n",
    "\n",
    "\n",
    "da_persons    = df_persons.to_dask_array()\n",
    "da_movies     = df_movies.to_dask_array()\n",
    "   #\n",
    "da_directed   = df_directed.to_dask_array()\n",
    "da_reviewed   = df_reviewed.to_dask_array()\n",
    "da_wrote      = df_wrote.to_dask_array()\n",
    "da_produced   = df_produced.to_dask_array()\n",
    "da_follows    = df_follows.to_dask_array()\n",
    "da_actedin    = df_actedin.to_dask_array()\n",
    "\n",
    "\n",
    "df_persons2   = dd.io.from_dask_array(da_persons,  columns=[\"id\", \"label\", \"born\", \"name\"]).compute()\n",
    "df_movies2    = dd.io.from_dask_array(da_movies,   columns=[\"id\", \"label\", \"released\", \"tagline\", \"title\"]).compute()\n",
    "   #\n",
    "df_directed2  = dd.io.from_dask_array(da_directed, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_reviewed2  = dd.io.from_dask_array(da_reviewed, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]).compute()\n",
    "df_wrote2     = dd.io.from_dask_array(da_wrote, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_produced2  = dd.io.from_dask_array(da_produced, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_follows2   = dd.io.from_dask_array(da_follows, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_actedin2   = dd.io.from_dask_array(da_actedin, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]).compute()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060507c-c49f-4cda-92c0-a53752091fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from katana_enterprise.remote import import_data\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737ce45-e17f-49e4-ac98-af1dc3bf8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:\n",
    "    \n",
    "   # Person\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_persons2[[\"id\", \"label\", \"born\", \"name\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Person\"\n",
    "      )\n",
    "   #  Movie\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_movies2[[\"id\", \"label\", \"title\", \"tagline\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Movie\"\n",
    "      )  \n",
    "    \n",
    "   #  DIRECTED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_directed2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"DIRECTED\"\n",
    "      )\n",
    "   #  REVIEWED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_reviewed2[[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"REVIEWED\"\n",
    "      )\n",
    "   #  WROTE\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_wrote2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"WROTE\"\n",
    "      )\n",
    "   #  PRODUCED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_produced2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"PRODUCED\"\n",
    "      )\n",
    "   #  FOLLOWS\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_follows2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"FOLLOWS\"\n",
    "      )\n",
    "   #  ACTEDIN\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_actedin2[[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"ACTEDIN\"\n",
    "      )\n",
    "\n",
    "   df_importer.execute()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d9a40-4d2e-4972-9113-3084d2258d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (a) \n",
    "   WITH DISTINCT LABELS(a) AS temp, COUNT(a) AS tempCnt\n",
    "   UNWIND temp AS label\n",
    "   RETURN label, SUM(tempCnt) AS cnt\n",
    "   ORDER BY label\n",
    "   \n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef49e4-30e4-488c-963b-bf13c44e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (m)-[r]->(n) \n",
    "   WITH DISTINCT TYPE(r) AS temp, COUNT(r) AS tempCnt\n",
    "   RETURN temp, tempCnt\n",
    "   ORDER BY temp\n",
    "\n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550017-2685-48ed-994b-5a51395ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (x) -[r]-> (a)\n",
    "   RETURN x, r AS rel, a\n",
    "   \n",
    "   \"\"\",\n",
    "   contextualize=True)\n",
    "\n",
    "result.view()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb62f6-0d3f-4d22-924f-a2630e3405a7",
   "metadata": {},
   "source": [
    "# Output a graph as a a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800b8bb-11ec-4904-9217-51e56a5b9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Formatting could use a little work, but the concept is here ..\n",
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "   MATCH (n: Person) \n",
    "   RETURN n\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result1))\n",
    "\n",
    "l_result2 = my_graph.query(\"\"\"\n",
    "   MATCH (n) - [r: WROTE] -> (m)\n",
    "   RETURN r\n",
    "   \"\"\")\n",
    "      #\n",
    "# display(print(l_result2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd62f55-1b27-43f1-bdc4-e1b79de25609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_nodes = []\n",
    "   #\n",
    "for l_node in l_result1.iterrows():\n",
    "   l_nodes.append(l_node)\n",
    "\n",
    "l_file = open(\"nodes.txt\", \"w\")\n",
    "l_file.write(str(l_nodes))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "l_edges = []\n",
    "   #\n",
    "for l_edge in l_result2.iterrows():\n",
    "   l_edges.append(l_edge)\n",
    "\n",
    "l_file = open(\"edges.txt\", \"w\")\n",
    "l_file.write(str(l_edges))\n",
    "l_file.close()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
