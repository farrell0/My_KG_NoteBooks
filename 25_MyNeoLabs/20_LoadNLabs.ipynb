{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f14aa-01d9-4d3c-9986-a42fa4b15d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Notebook to load CSV into graph using DataFrame method\n",
    "#\n",
    "#  .  Data is the Neo4J Movie graph\n",
    "#  .  Incidentally includes teaching methods relative to Dask DataFrame manipulation\n",
    "#\n",
    "#  .  I haven't fully checked all results below; there may be issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a009883-fadd-4dfe-9f83-efd5e4ef6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "from katana.remote import import_data\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc3b51-a38f-406d-b4cb-4bcd13c5f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e9e29-c90b-4ed6-9997-db56ff225fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  This section; basic graph and database setup, reset for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15cfb83b-fd1f-46c3-96ad-95ceed14058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04909ce0-17bc-4214-84a7-3016cdbf52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb24521-9a8d-4fad-bdec-52876bc71e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf6371d-6d53-4052-b895-f61c76b0792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_Graph my_graph, 2euC6kymsQ5R2G8KFxTWw6gfELkZV6enfgrkxT2NvAng, 0>\n"
     ]
    }
   ],
   "source": [
    "#  CREATE A GRAPH\n",
    "\n",
    "my_graph=my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f6eb7-59ef-4c9b-813a-e8370b25b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CONNECT TO GRAPH\n",
    "\n",
    "for l_graph in my_client.get_database(name=DB_NAME).graphs_in_database():\n",
    "   if (l_graph.name == GRAPH_NAME):\n",
    "      my_graph=my_client.get_database(name=DB_NAME).get_graph_by_id(id=l_graph.graph_id)\n",
    "         #\n",
    "      break\n",
    "\n",
    "# my_graph, *_ = my_client.get_database(name=DB_NAME).find_graphs_by_name(GRAPH_NAME)\n",
    "\n",
    "print(my_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedb2fa-cec7-474a-acc2-5cefbbb3660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb5a2d-bddb-4bba-9169-e5dfc1d44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Load from source CSV, in this case we are using the Neo4J Movie graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ddce-66b8-43a8-b551-3a51a6983449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1259d64d-c879-4e1f-ab10-6cf663b293e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Load a DataFrame from CSV, Nodes/Vertices\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/24_nodes.txt\"\n",
    "\n",
    "df_all_nodes1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"id\"        : int,\n",
    "      \"id\"        : np.dtype('O'),\n",
    "      \"_labels\"   : np.dtype('O'),\n",
    "      # \"born\"      : float, \n",
    "      \"born\"      : np.dtype('O'),\n",
    "      \"name\"      : np.dtype('O'),\n",
    "      # \"released\"  : float,\n",
    "      \"released\"  : np.dtype('O'),\n",
    "      \"tagline\"   : np.dtype('O'),\n",
    "      \"title\"     : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91245c1-9a0f-455b-b9c1-f975018d98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of rows, two different ways\n",
    "\n",
    "display(len(df_all_nodes1))\n",
    "display(print(\"{} Rows\".format(df_all_nodes1.shape[0].compute())))\n",
    "\n",
    "#  Other output\n",
    "\n",
    "display(df_all_nodes1.head(10))\n",
    "display(df_all_nodes1[[\"born\", \"name\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07d63f-9c74-43e8-ba54-cdbd6099e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print all rows, subsetted columns\n",
    "\n",
    "for l_each in df_all_nodes1.iterrows():\n",
    "   print(l_each[0], \"   \", l_each[1][\"_labels\"], \"   \", l_each[1][\"name\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490285c-abad-4c3b-804d-2534515c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#   https://www.askpython.com/python/examples/subset-a-dataframe\n",
    "#   https://www.codegrepper.com/code-examples/python/convert+float+to+int+python+pandas\n",
    "#   https://docs.dask.org/en/latest/generated/dask.dataframe.DataFrame.assign.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dc5f0-3ce2-4c47-8db4-0b7438277f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We have some issues we want to change with our data\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n",
    "#  .  The label values are currently \";Person\" and \";Movie\". Let's remove those semicolons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cfbf635-c973-4c1d-91d4-36bc47eb5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Column renames\n",
    "\n",
    "df_all_nodes2 = df_all_nodes1.rename(columns={\"_id\": \"id\", \"_labels\": \"label\"})\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc357f2-0a17-42c9-ab81-3d984a1604b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Change float values to integer, remove leading semicolon from label\n",
    "\n",
    "df_all_nodes3 = df_all_nodes2.assign(\n",
    "   # born     = lambda x: x.born.fillna(0.0).astype(int), \n",
    "   born     = lambda x: x.born.fillna(0.0).astype(str), \n",
    "   # id       = lambda x: x.id.fillna(0.0).astype(int),\n",
    "   id       = lambda x: x.id.fillna(0.0).astype(str),\n",
    "   # released = lambda x: x.released.fillna(0.0).astype(int),\n",
    "   released = lambda x: x.released.fillna(0.0).astype(str),\n",
    "   label    = lambda x: x.label.astype(str).str[1:]\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485b323-6335-4dd2-8d63-dfbf7e845f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_nodes3))\n",
    "display(df_all_nodes3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e942-6083-4ddc-a55d-104bd0cf5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83330545-9507-4cef-831a-bb1ea802029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Now, populate Persons and Movies\n",
    "\n",
    "df_persons = df_all_nodes3[df_all_nodes3[\"label\"] == \"Person\"][[\"id\", \"label\", \"born\", \"name\"]]\n",
    "\n",
    "df_movies  = df_all_nodes3[df_all_nodes3[\"label\"] == \"Movie\"][[\"id\", \"label\", \"released\", \"tagline\", \"title\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c958-2366-45e6-b316-6b30198858d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_persons))\n",
    "display(df_persons.head(10))\n",
    "display(len(df_movies))\n",
    "display(df_movies.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ec1d4-2f6a-42d7-b026-6d4db9979aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Repeat the style of work from above, but now for edges\n",
    "#\n",
    "#  .  Some of the property names have a leading underscore. Change those.\n",
    "#  .  Some values which should be integer, are float.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26bb9803-9e7b-4471-83ad-d279bb733d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Load a DataFrame from CSV, Edges\n",
    "\n",
    "l_InputFile  = \"./10_NMovieDB/25_edges.txt\"\n",
    "\n",
    "df_all_edges1 = dd.read_csv(\n",
    "   l_InputFile,\n",
    "   delimiter = \",\",\n",
    "   dtype = {\n",
    "      # \"_start\"    : float,\n",
    "      \"_start\"    : np.dtype('O'),\n",
    "      # \"_end\"      : float, \n",
    "      \"_end\"      : np.dtype('O'),\n",
    "      \"_type\"     : np.dtype('O'),\n",
    "      # \"rating\"    : float,\n",
    "      \"rating\"    : np.dtype('O'),\n",
    "      \"roles\"     : np.dtype('O'),\n",
    "      \"summary\"   : np.dtype('O')\n",
    "      })\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fde9ff-5304-4d2c-b351-84fe21d97f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges1))\n",
    "display(df_all_edges1.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9356971-a6d7-4cba-ae07-cc0d693e39f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "df_all_edges2 = df_all_edges1.rename(columns={\"_start\": \"START_ID\", \"_end\": \"END_ID\", \"_type\": \"TYPE\",\n",
    "   \"rating\": \"RATING\", \"roles\": \"ROLES\", \"summary\": \"SUMMARY\"})\n",
    "\n",
    "df_all_edges3 = df_all_edges2.assign(\n",
    "   # START_ID = lambda x: x.START_ID.fillna(0.0).astype(int), \n",
    "   START_ID = lambda x: x.START_ID.fillna(0.0).astype(str), \n",
    "   # END_ID   = lambda x: x.END_ID.fillna(0.0).astype(int),\n",
    "   END_ID   = lambda x: x.END_ID.fillna(0.0).astype(str),\n",
    "   # RATING   = lambda x: x.RATING.fillna(0.0).astype(int)\n",
    "   RATING   = lambda x: x.RATING.fillna(0.0).astype(str)\n",
    "   )\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddde16b-d104-4e12-aac2-40d6598ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_all_edges3))\n",
    "display(df_all_edges3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "137a838f-d161-4898-95ca-80f608fa82a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "#  Split out the various edges\n",
    "\n",
    "df_reviewed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"REVIEWED\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]]\n",
    "\n",
    "df_wrote    = df_all_edges3[df_all_edges3[\"TYPE\"] == \"WROTE\"   ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_produced = df_all_edges3[df_all_edges3[\"TYPE\"] == \"PRODUCED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_directed = df_all_edges3[df_all_edges3[\"TYPE\"] == \"DIRECTED\"][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "df_follows  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"FOLLOWS\" ][[\"START_ID\", \"END_ID\", \"TYPE\"]]\n",
    "\n",
    "#  \"roles\" is a string similar to  '[ \"a\", \"b\", \"c\" ]'\n",
    "#\n",
    "#  This was automatically coming in as a list-\n",
    "#  Cool\n",
    "\n",
    "df_actedin  = df_all_edges3[df_all_edges3[\"TYPE\"] == \"ACTED_IN\"][[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]]\n",
    "\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f1fa7-3ac5-4eb9-a749-6f3d89267d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(len(df_reviewed))\n",
    "display(df_reviewed.head(2))\n",
    "\n",
    "display(len(df_wrote))\n",
    "display(df_wrote.head(2))\n",
    "\n",
    "display(len(df_produced))\n",
    "display(df_produced.head(2))\n",
    "\n",
    "display(len(df_directed))\n",
    "display(df_directed.head(2))\n",
    "\n",
    "display(len(df_follows))\n",
    "display(df_follows.head(2))\n",
    "\n",
    "display(len(df_actedin))\n",
    "display(df_actedin.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e959b0-0040-4556-a486-8267ae32c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47455c-f349-4c06-be7f-214e996a33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Didn't need this; also don't know if it had any effect\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=4, threads_per_worker=2)\n",
    "\n",
    "# print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bba15117-b555-4953-8580-38e4222f4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "# ##################################################################\n",
    "#\n",
    "#  Finally now, load the vertices/nodes into a graph\n",
    "#\n",
    "#  Some hinkiness we need to work around ..\n",
    "#\n",
    "#     .  The Dask DataFrames here were loaded from CSV, and those CSV\n",
    "#        files were found, in scope.\n",
    "#        The KG DataFrame importer will reference that same file\n",
    "#        pathname, and the file will not be in scope. Basically,\n",
    "#        it was expected that these files be on S3/GS all along.\n",
    "#        I hate to have that dependency because, just one more thing\n",
    "#        to have to manage.\n",
    "#\n",
    "#     .  So, we'll copy the DataFrames to Dask arrays, then back into\n",
    "#        a Dask DataFrame.\n",
    "#        Why not just copy the DaskDataFrame ?  Currently there is only \n",
    "#        shallow copies of DataFrames.\n",
    "#\n",
    "#  See,\n",
    "#     https://stackoverflow.com/questions/52119342/how-do-i-convert-a-dask-dataframe-into-a-dask-array\n",
    "#     https://docs.dask.org/en/latest/generated/dask.dataframe.from_dask_array.html\n",
    "\n",
    "\n",
    "da_persons    = df_persons.to_dask_array()\n",
    "da_movies     = df_movies.to_dask_array()\n",
    "   #\n",
    "da_directed   = df_directed.to_dask_array()\n",
    "da_reviewed   = df_reviewed.to_dask_array()\n",
    "da_wrote      = df_wrote.to_dask_array()\n",
    "da_produced   = df_produced.to_dask_array()\n",
    "da_follows    = df_follows.to_dask_array()\n",
    "da_actedin    = df_actedin.to_dask_array()\n",
    "\n",
    "\n",
    "df_persons2   = dd.io.from_dask_array(da_persons,  columns=[\"id\", \"label\", \"born\", \"name\"]).compute()\n",
    "df_movies2    = dd.io.from_dask_array(da_movies,   columns=[\"id\", \"label\", \"released\", \"tagline\", \"title\"]).compute()\n",
    "   #\n",
    "df_directed2  = dd.io.from_dask_array(da_directed, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_reviewed2  = dd.io.from_dask_array(da_reviewed, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]).compute()\n",
    "df_wrote2     = dd.io.from_dask_array(da_wrote, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_produced2  = dd.io.from_dask_array(da_produced, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_follows2   = dd.io.from_dask_array(da_follows, columns=[\"START_ID\", \"END_ID\", \"TYPE\"]).compute()\n",
    "df_actedin2   = dd.io.from_dask_array(da_actedin, columns=[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]).compute()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0060507c-c49f-4cda-92c0-a53752091fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "from katana_enterprise.remote import import_data\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7737ce45-e17f-49e4-ac98-af1dc3bf8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: dtype for DataFrame column 'label' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'born' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'name' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'title' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'tagline' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'TYPE' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'RATING' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'SUMMARY' is 'object'. Will be inferred as string.\n",
      "UserWarning: dtype for DataFrame column 'ROLES' is 'object'. Will be inferred as string.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0cc759feb847fdb4b8461f7e37a7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83870f65b2544cf9bfa77eaa492f891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5fc5eb2448458b94b741268dc2d9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8249a84b66e049b6a39886e108ce5fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:\n",
    "    \n",
    "   # Person\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_persons2[[\"id\", \"label\", \"born\", \"name\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Person\"\n",
    "      )\n",
    "   #  Movie\n",
    "   #\n",
    "   df_importer.nodes_dataframe(\n",
    "      df_movies2[[\"id\", \"label\", \"title\", \"tagline\"]],\n",
    "      id_column  = \"id\",\n",
    "      id_space   = \"Movie\"\n",
    "      )  \n",
    "    \n",
    "   #  DIRECTED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_directed2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"DIRECTED\"\n",
    "      )\n",
    "   #  REVIEWED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_reviewed2[[\"START_ID\", \"END_ID\", \"TYPE\", \"RATING\", \"SUMMARY\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"REVIEWED\"\n",
    "      )\n",
    "   #  WROTE\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_wrote2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"WROTE\"\n",
    "      )\n",
    "   #  PRODUCED\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_produced2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"PRODUCED\"\n",
    "      )\n",
    "   #  FOLLOWS\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_follows2[[\"START_ID\", \"END_ID\", \"TYPE\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"FOLLOWS\"\n",
    "      )\n",
    "   #  ACTEDIN\n",
    "   #\n",
    "   df_importer.edges_dataframe(\n",
    "      df_actedin2[[\"START_ID\", \"END_ID\", \"TYPE\", \"ROLES\"]],\n",
    "      source_id_space      = \"Person\",\n",
    "      destination_id_space = \"Movie\",\n",
    "      source_column        = \"START_ID\",\n",
    "      destination_column   = \"END_ID\",\n",
    "      type                 = \"ACTEDIN\"\n",
    "      )\n",
    "\n",
    "   df_importer.execute()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d9a40-4d2e-4972-9113-3084d2258d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (a) \n",
    "   WITH DISTINCT LABELS(a) AS temp, COUNT(a) AS tempCnt\n",
    "   UNWIND temp AS label\n",
    "   RETURN label, SUM(tempCnt) AS cnt\n",
    "   ORDER BY label\n",
    "   \n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef49e4-30e4-488c-963b-bf13c44e12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (m)-[r]->(n) \n",
    "   WITH DISTINCT TYPE(r) AS temp, COUNT(r) AS tempCnt\n",
    "   RETURN temp, tempCnt\n",
    "   ORDER BY temp\n",
    "\n",
    "   \"\"\")\n",
    "\n",
    "display(print(l_result1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550017-2685-48ed-994b-5a51395ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = my_graph.query(\"\"\"\n",
    "\n",
    "   MATCH (x) -[r]-> (a)\n",
    "   RETURN x, r AS rel, a\n",
    "   \n",
    "   \"\"\",\n",
    "   contextualize=True)\n",
    "\n",
    "result.view()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb62f6-0d3f-4d22-924f-a2630e3405a7",
   "metadata": {},
   "source": [
    "# Output a graph as a a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f800b8bb-11ec-4904-9217-51e56a5b9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4086fca37b284547b1a4458b5114521b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OperationError",
     "evalue": "5YPQygeez4PBcgtSfjKC9UghaeCmdq8fWTVH3GttktqL-3DqkGvjMhUGXpvdZo backtrace (QueryClient.cpp:637): unable to translate openCypher parse tree to internal IR (OpGraph.cpp:224): Syntax error: The query cannot be recognized by openCypher. (CypherOpGraphBuilder.cpp:70): TCK = SyntaxError:UnexpectedSyntax\nKatana = SyntaxError:ParserError: TCK = SyntaxError:UnexpectedSyntax\nKatana = SyntaxError:ParserError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m l_result1 \u001b[38;5;241m=\u001b[39m my_graph\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m   MATCH (n:Person) \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m   \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m       \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m display(\u001b[38;5;28mprint\u001b[39m(l_result1))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:249\u001b[0m, in \u001b[0;36mAsyncToSync.<locals>.do_wrap.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(underlying_func)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[0;32m--> 249\u001b[0m         \u001b[43munderlying_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_self_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:176\u001b[0m, in \u001b[0;36masync_to_sync.<locals>.wrapper\u001b[0;34m(timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     registry \u001b[38;5;241m=\u001b[39m AsyncToSyncClassRegistry\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registry\u001b[38;5;241m.\u001b[39masync_to_sync(\n\u001b[1;32m    168\u001b[0m         wait_for(\n\u001b[1;32m    169\u001b[0m             async_func(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/async_to_sync.py:147\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(coro, timeout)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(timeout_coro, loop\u001b[38;5;241m=\u001b[39mAsyncRunnerThread\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mloop)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     inner_future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/asyncio/tasks.py:455\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    450\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe loop argument is deprecated since Python 3.8, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand scheduled for removal in Python 3.10.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    458\u001b[0m     fut \u001b[38;5;241m=\u001b[39m ensure_future(fut, loop\u001b[38;5;241m=\u001b[39mloop)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:299\u001b[0m, in \u001b[0;36mGraph.query\u001b[0;34m(self, query, memory_usage_factor, contextualize, **parameters)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m memory_usage_factor:\n\u001b[1;32m    297\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__katana_internal_match_batch_limit_scale_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m memory_usage_factor\n\u001b[0;32m--> 299\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_query(query, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[1;32m    300\u001b[0m rows \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    301\u001b[0m columns \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/graph.py:277\u001b[0m, in \u001b[0;36mGraph._run_query\u001b[0;34m(self, query, parameters, parquet)\u001b[0m\n\u001b[1;32m    273\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcypher\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_operation_metadata(data)\n\u001b[0;32m--> 277\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_run_on_graph_and_wait(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/client.py:319\u001b[0m, in \u001b[0;36mDatabase._run_on_graph_and_wait\u001b[0;34m(self, graph, data)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_on_graph_and_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: Graph, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_graph_from_myself(graph)\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_op(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_on_graph(graph, data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/remote/aio/client.py:261\u001b[0m, in \u001b[0;36mDatabase._wait_op\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m _progress_bar() \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m wait_fn(operation_id) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[0;32m--> 261\u001b[0m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m    262\u001b[0m             status \u001b[38;5;241m=\u001b[39m update[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m update\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/asyncstdlib/builtins.py:445\u001b[0m, in \u001b[0;36mmap\u001b[0;34m(function, *iterable)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_iter:\n\u001b[1;32m    444\u001b[0m     result \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/asyncstdlib/_core.py:134\u001b[0m, in \u001b[0;36mforce_async.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/katana_enterprise/rpc/client.py:166\u001b[0m, in \u001b[0;36m_OperationClient._event_stream.<locals>.parse_stream\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    163\u001b[0m status \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOperationError(operation_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanceled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mCanceledError()\n",
      "\u001b[0;31mOperationError\u001b[0m: 5YPQygeez4PBcgtSfjKC9UghaeCmdq8fWTVH3GttktqL-3DqkGvjMhUGXpvdZo backtrace (QueryClient.cpp:637): unable to translate openCypher parse tree to internal IR (OpGraph.cpp:224): Syntax error: The query cannot be recognized by openCypher. (CypherOpGraphBuilder.cpp:70): TCK = SyntaxError:UnexpectedSyntax\nKatana = SyntaxError:ParserError: TCK = SyntaxError:UnexpectedSyntax\nKatana = SyntaxError:ParserError"
     ]
    }
   ],
   "source": [
    "\n",
    "l_result1 = my_graph.query(\"\"\"\n",
    "   MATCH (n:Person) \n",
    "   \"\"\")\n",
    "      #\n",
    "display(print(l_result1))\n",
    "\n",
    "l_result2 = my_graph.query(\"\"\"\n",
    "   MATCH (n) - [r: WROTE] -> (m)\n",
    "   \"\"\")\n",
    "      #\n",
    "display(print(l_result2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd62f55-1b27-43f1-bdc4-e1b79de25609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a48b-eff6-4c4b-b704-a08db017c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fda229-0015-475b-baea-82b8bee46f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
