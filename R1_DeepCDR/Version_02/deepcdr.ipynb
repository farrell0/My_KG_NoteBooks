{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6f3e40-04bd-4c3a-a3ab-065f042aed5a",
   "metadata": {},
   "source": [
    "## Drug Repurposing: A Hybrid Graph Convolutional Network for Predicting Cancer Drug Response\n",
    "\n",
    "The goal of this pipeline is to implement a Cancer Drug Response Prediction pipeline. The model chosen is called DeepCDR which is a Cancer Drug Response Prediction model via a Hybrid Graph Convolutional Network. This model was published in the journal Bioinformatics.\n",
    "\n",
    "<center><img src=\"./images/model.png\" style=\"width:70%;\"></center>\n",
    "\n",
    "DeepCDR takes a pair of drug and cancer cell profiles as inputs and predicts the drug sensitivity (IC50) (regression). The drug will be represented as a graph based on the chemical structure before being transformed into a high-level latent representation by the GNN model. Omics features learned by subnetworks will be concatenated to the drug feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6bfda6",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "The [README](README.md) file accompanying this notebook includes additional information about the research behind this model and how to run this pipeline with your own data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a386f-6a70-4498-9eba-d2cff983cfff",
   "metadata": {},
   "source": [
    "## Katana AI Pipeline for End to End Drug Repurposing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f499e-4c45-43d6-91bf-234374e99406",
   "metadata": {},
   "source": [
    "<img src=\"images/pipeline_full.png\" style=\"width: 1500px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "There are four distinct steps:\n",
    "\n",
    "* **[Step 1: Set up a Katana `Client` and create a Distributed Graph](#step-1)**\n",
    "* **[Step 2: Extract ML-ready Data](#step-2)**\n",
    "* **[Step 3: AI Training Pipeline](#step-3)**\n",
    "* **[Step 4: Trained model inference](#step-4)**\n",
    "\n",
    "<a id='step-1'></a>\n",
    "## Step 1: Set up a Katana `Client` and load a Distributed Graph\n",
    "\n",
    "<img src=\"images/pipeline_dask.png\" style=\"width: 1500px;\"/>\n",
    "\n",
    "### Set up a Katana `Client`\n",
    "\n",
    "Starting a Katana remote Client is required to interface with the Katana remote service and schedule distributed operations. First we set Jupyter to automatically reload changed code and we import some standard Katana modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de96290-d64c-4c82-bd6d-fe69fcc1dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0+20230322T224759Z.73f024927.dev'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from katana import remote\n",
    "from katana.remote import export_data, import_data\n",
    "\n",
    "client = remote.Client()\n",
    "client.server_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab20d54-7095-4134-998f-47eba135904d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Input configuration\n",
    "\n",
    "The input configuration, which is stored in the `hyperparams` file, defines the specifications of the graph use for the recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89769fd-629e-419f-bb3f-55a0d60b0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InputConfig:\n",
       "    num_partitions = 8,\n",
       "    use_train_rdg = False,\n",
       "    trained_rdg_path = gs://hls-dataset-bucket/DeepCDR_trained,\n",
       "    cell_lines_path = gs://bucket-farrell/DeepCDR/cell_lines.csv,\n",
       "    drugs_path = gs://bucket-farrell/DeepCDR/drugs.csv,\n",
       "    gdsc_path = gs://bucket-farrell/DeepCDR/gdsc.csv,\n",
       "    genes_path = gs://bucket-farrell/DeepCDR/genes.csv,\n",
       "    gdsc_cell_line_path = gs://bucket-farrell/DeepCDR/gdsc_cell_line_edges.csv,\n",
       "    gdsc_drug_path = gs://bucket-farrell/DeepCDR/gdsc_drug_edges.csv,\n",
       "    cell_line_gene_expression_path = gs://bucket-farrell/DeepCDR/cell_line_gene_expression_edges.csv,\n",
       "    cell_line_gene_methylation_path = gs://bucket-farrell/DeepCDR/cell_line_gene_methylation_edges.csv,\n",
       "    cell_line_gene_mutation_path = gs://bucket-farrell/DeepCDR/cell_line_gene_mutation_edges.csv,\n",
       "    test_size = 0.05,\n",
       "    random_state = 42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import hyperparams\n",
    "\n",
    "input_config = hyperparams.load_input_config()\n",
    "input_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a37bd9-686c-453e-a8b4-10513fa286c5",
   "metadata": {},
   "source": [
    "### Create a Distributed Graph\n",
    "\n",
    "Create a Katana Distributed graph with `input_config.num_partitions` partitions and import data used to train the DeepCDR model into the Distributed Graph. The entire recipe will be distributed among `input_config.num_partitions` hosts.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can choose to change the number of partition using <a href=\"./config/hyperparams.py\" class=\"alert-link\">num_partitions</a> parameter.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can choose to import a graph with the features already generated and a model already trained and saved in the graph or create your graph from csv files with Dask by setting <a href=\"./config/hyperparams.py\" class=\"alert-link\">use_train_rdg</a> parameter. \n",
    "    \n",
    "If you choose to use the pretrained model you can skip the following two steps,\n",
    "* **[Step 2: Extract ML-ready Data](#step-2)**\n",
    "* **[Step 3: AI Training Pipeline](#step-3)**\n",
    "\n",
    "and go directly to:\n",
    "* **[Step 4: Trained model inference](#step-4)**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885f5f2f-d988-4f60-bb56-9d430efd77e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate the graph with data from source\n",
      "***Loading nodes dataframe***\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "b/bucket-farrell/o/DeepCDR%2Fcell_lines.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate the graph with data from source\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mdask_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_deepcdr_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My_KG_NoteBooks/R1_DeepCDR/Version_02/src/dask_ingestion.py:69\u001b[0m, in \u001b[0;36mgenerate_deepcdr_graph\u001b[0;34m(graph, input_dir_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate DeepCDR graph from csv files\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***Loading nodes dataframe***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m nodes_dd \u001b[38;5;241m=\u001b[39m \u001b[43mnodes_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***Loading edges dataframe***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m edges_dd \u001b[38;5;241m=\u001b[39m edges_dataframe(input_dir_path)\n",
      "File \u001b[0;32m~/My_KG_NoteBooks/R1_DeepCDR/Version_02/src/dask_ingestion.py:15\u001b[0m, in \u001b[0;36mnodes_dataframe\u001b[0;34m(input_config)\u001b[0m\n\u001b[1;32m     12\u001b[0m node_dd \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     14\u001b[0m node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCELL_LINE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m node_dd[node_type] \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_lines_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstring\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m node_dd[node_type] \u001b[38;5;241m=\u001b[39m node_dd[node_type][node_dd[node_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtcga_code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(utils\u001b[38;5;241m.\u001b[39mTCGA_label_set)]\n\u001b[1;32m     18\u001b[0m node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGDSC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/io/csv.py:744\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[0;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    732\u001b[0m     urlpath,\n\u001b[1;32m    733\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    743\u001b[0m ):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_path_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/io/csv.py:548\u001b[0m, in \u001b[0;36mread_pandas\u001b[0;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     sample \u001b[38;5;241m=\u001b[39m blocksize\n\u001b[1;32m    547\u001b[0m b_lineterminator \u001b[38;5;241m=\u001b[39m lineterminator\u001b[38;5;241m.\u001b[39mencode()\n\u001b[0;32m--> 548\u001b[0m b_out \u001b[38;5;241m=\u001b[39m \u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_lineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_path_column:\n\u001b[1;32m    559\u001b[0m     b_sample, values, paths \u001b[38;5;241m=\u001b[39m b_out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/bytes/core.py:109\u001b[0m, in \u001b[0;36mread_bytes\u001b[0;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m comp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot do chunked reads on compressed files. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo read, set blocksize=None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBacking filesystem couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt determine file size, cannot \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo chunked reads. To read, set blocksize=None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fsspec/asyn.py:115\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fsspec/asyn.py:100\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/fsspec/asyn.py:55\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     53\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     57\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:797\u001b[0m, in \u001b[0;36mGCSFileSystem._info\u001b[0;34m(self, path, generation, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    796\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Force to true for info\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ls(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    798\u001b[0m out0 \u001b[38;5;241m=\u001b[39m [o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m o[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m path]\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out0:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# exact hit\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:834\u001b[0m, in \u001b[0;36mGCSFileSystem._ls\u001b[0;34m(self, path, detail, prefix, versions, **kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_objects(\n\u001b[1;32m    835\u001b[0m         path, prefix\u001b[38;5;241m=\u001b[39mprefix, versions\u001b[38;5;241m=\u001b[39mversions\n\u001b[1;32m    836\u001b[0m     ):\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m versions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m entry:\n\u001b[1;32m    838\u001b[0m             entry \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:549\u001b[0m, in \u001b[0;36mGCSFileSystem._list_objects\u001b[0;34m(self, path, prefix, versions)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (items \u001b[38;5;241m+\u001b[39m pseudodirs):\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[0;32m--> 549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object(path)]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:491\u001b[0m, in \u001b[0;36mGCSFileSystem._get_object\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# Work around various permission settings. Prefer an object get (storage.objects.get), but\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# fall back to a bucket list + filter to object name (storage.objects.list).\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/o/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, bucket, key, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, generation\u001b[38;5;241m=\u001b[39mgeneration\n\u001b[1;32m    493\u001b[0m     )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForbidden\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:418\u001b[0m, in \u001b[0;36mGCSFileSystem._call\u001b[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, path, \u001b[38;5;241m*\u001b[39margs, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m     status, headers, info, contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    419\u001b[0m         method, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_out:\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(contents)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/decorator.py:221\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    220\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/retry.py:114\u001b[0m, in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (retry \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m     HttpError,\n\u001b[1;32m    117\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     aiohttp\u001b[38;5;241m.\u001b[39mclient_exceptions\u001b[38;5;241m.\u001b[39mClientError,\n\u001b[1;32m    121\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, HttpError)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequester pays\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    126\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/core.py:411\u001b[0m, in \u001b[0;36mGCSFileSystem._request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m info \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrequest_info  \u001b[38;5;66;03m# for debug only\u001b[39;00m\n\u001b[1;32m    409\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 411\u001b[0m \u001b[43mvalidate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status, headers, info, contents\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gcsfs/retry.py:83\u001b[0m, in \u001b[0;36mvalidate_response\u001b[0;34m(status, content, path, args)\u001b[0m\n\u001b[1;32m     81\u001b[0m     path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m[quote(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m args])\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[1;32m     85\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(content, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: b/bucket-farrell/o/DeepCDR%2Fcell_lines.csv"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "# Import the module that uses Dask to import drug data\n",
    "from src import dask_ingestion\n",
    "\n",
    "graph = client.create_graph(num_partitions=input_config.num_partitions)\n",
    "\n",
    "if input_config.use_train_rdg:\n",
    "    print(f\"Import pretrained graph from: {input_config.trained_rdg_path}\")\n",
    "    import_data.rdg(graph, input_config.trained_rdg_path)\n",
    "else:\n",
    "    print(\"Generate the graph with data from source\")\n",
    "    dask_ingestion.generate_deepcdr_graph(graph, input_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbd83-ef7e-4f45-a050-39ea7ed1ae79",
   "metadata": {},
   "source": [
    "### Inspect the Graph Schema\n",
    "\n",
    "Import the module with pipeline utility functions, create a `RecipePipeline` instance to store relevant information, and display a visual representation of the graph's schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99d580-f5b1-471b-b540-d24fab04a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import katana_pipeline\n",
    "\n",
    "rec_pipeline = katana_pipeline.RecipePipeline(graph)\n",
    "rec_pipeline.graph.schema().view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5ed07-bbfc-45fd-a0ba-70cb68a5a53d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='step-2'></a>\n",
    "## Step 2: Extract ML-ready Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adb855-cb4a-4cde-a9fa-bee51c095ca9",
   "metadata": {},
   "source": [
    "<img src=\"images/pipeline_preprocess.png\" style=\"width: 1500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036bfac-aa1d-48be-9580-7200c588282d",
   "metadata": {},
   "source": [
    "### Feature Generation\n",
    "\n",
    "- Collect genomics data from edges between `CELL_LINE` and `GENE` and store the results in the `rec_pipeline` graph. \n",
    "- Remove unused nodes in the graph. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can see, add or remove preprocessing functions in the <a href=\"./src/preprocessing.py\" class=\"alert-link\">preprocessing.py</a> file, where they are typically implemented with simple OpenCypher queries.\n",
    "</div>\n",
    "\n",
    "The featurization of a `DRUG` into its graph representation is happening on-the-fly during the training-test-inference cycle. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can see or change the featurization of DRUG in the smiles_to_pyg function of the <a href=\"./src/utils.py\" class=\"alert-link\">utils.py</a> file. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1cca9-74b9-4e43-aa2e-aac854a9275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = default_timer()\n",
    "rec_pipeline.feature_generator()\n",
    "print(f\"***Took {default_timer() - start_time} seconds to generate the features.***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44c2f0-6359-4d8f-b249-9a9cae9d4fd6",
   "metadata": {},
   "source": [
    "### Statistics of the graph\n",
    "\n",
    "Compute basics statistics to get the number of nodes in the graph. The number of pairs between a drug and a cell line is the data used to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc94fa-4b49-46c8-a6cc-3a4b9033b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = rec_pipeline.stats()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d082f63-c5d7-4194-856b-4762ff4bbdf8",
   "metadata": {},
   "source": [
    "### Split Generation\n",
    "\n",
    "Based on the known drug–cell line interactions across cancer cell lines  and drugs, we randomly\n",
    "selected 95% of instances of each TCGA cancer type as the training set and the remaining 5% of the instances as the testing set for model evaluation.\n",
    "\n",
    "We create new edges in our `rec_pipeline` graph with `SPLIT` labels between `DRUG` and `CELL_LINE` nodes. The old split will be deleted.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can choose to change the train-test fraction or the seeds used for the split using the <a href=\"./config/hyperparams.py\" class=\"alert-link\">test_size</a> and <a href=\"./config/hyperparams.py\" class=\"alert-link\">random_state</a> parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30ac93-1a4c-4099-b7e2-44949827d890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = default_timer()\n",
    "rec_pipeline.split_generator(input_config)\n",
    "print(f\"***Took {default_timer() - start_time} seconds to generate the split.***\")\n",
    "rec_pipeline.graph.schema().view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086603e-d2d4-45af-8afd-f91849e32f9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='step-3'></a>\n",
    "## AI Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6ce75-84ea-4c86-9420-ea0d4f7668e9",
   "metadata": {},
   "source": [
    "<img src=\"images/pipeline_gnn.png\" style=\"width: 1500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6bb1a-7c59-43eb-b5a2-d9c06183bf29",
   "metadata": {},
   "source": [
    "### Initialize model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3de5b0-5f66-4dc6-8f30-3e66d789ecb7",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/model.png\" style=\"width:70%;\"></center>\n",
    "\n",
    "DeepCDR is a hybrid graph convolutional network model that predicts the IC50 value, which denotes the effectiveness of a drug in inhibiting the growth of a specific cancer cell line.\n",
    "\n",
    "On the one hand, the graph neural network (GNN) takes the adjacent information of atoms in a drug into consideration by aggregating the features of neighboring atoms together. On the other hand, the subnetworks extract high-level features of cancer omics profiles from a certain cancer cell line (i.e., genomic data, transcriptomic data and epigenomic data). Then the high-level features of drug and multiple omics data get concatenated and fed to a 1-D\n",
    "convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8394f5c-c3d8-4782-b34b-5d330c8c414a",
   "metadata": {},
   "source": [
    "### Load Model configuration\n",
    "\n",
    "The model configuration defines the specifications of the model that will be used to train on the graph.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can change the model configuration in the <a href=\"./config/hyperparams.py\" class=\"alert-link\">hyperparams.py</a> file. By default the model is using genomics, epigenomics and transcriptomics data.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can change the model architecture in the <a href=\"./src/model.py\" class=\"alert-link\">model.py</a> file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e70ffb-3c7c-49ef-baa9-f4aff238e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = hyperparams.load_model_config()\n",
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247df214-0c2a-4787-b97f-ca6d9b5f457f",
   "metadata": {},
   "source": [
    "### Load Training configuration\n",
    "\n",
    "The training configuration specify details of the training pipeline.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "You can change the training configuration in the <a href=\"./config/hyperparams.py\" class=\"alert-link\">hyperparams.py</a> file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b3bae-5feb-482a-9baa-ecdbb8b1915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = hyperparams.load_training_config()\n",
    "training_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dd293-1f51-4040-ba2b-44e130f67951",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Distributed training of the model. The trained model and its configuration will be saved in the `rec_pipeline` graph using the `experiment_name` graph property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9faa3bf-3b43-4d26-a069-09f7bb342808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = default_timer()\n",
    "\n",
    "validation_metric = rec_pipeline.train(model_config, training_config)\n",
    "\n",
    "print(f\"***Took {default_timer() - start_time} seconds to train the model.***\")\n",
    "print(\"Validation metric: \", validation_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350f3c1-27aa-40e6-811d-7a57a05abdea",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Test the trained model on the test data and compare the results with other achitecture baselines. We compare three different metrics:\n",
    "- [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient): a measure of linear correlation between two sets of data. A value closer to 1 is better.\n",
    "- [Spearman correlation coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient): how well the relationship between two variables can be described using a monotonic function. A value closer to 1 is better.\n",
    "- [Root mean square error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation): a measure of the differences between values predicted by a model and the values observed. A lower value is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cb014-1302-4bac-b55f-3c86ba61436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = default_timer()\n",
    "metrics, predictions, labels = rec_pipeline.test(training_config)\n",
    "print(f\"***Took {default_timer() - start_time} seconds to test the model.***\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce573cf-65ab-4c2c-ba13-8cf30d4e595a",
   "metadata": {},
   "source": [
    "### Plot Predictions\n",
    "\n",
    "Create a scatter plot of the `IC50` predicted by the trained model in function of `IC50` real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec43d5c-07d9-456c-9aa6-c3d230b64991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = default_timer()\n",
    "rec_pipeline.plot(labels, predictions)\n",
    "print(f\"***Took {default_timer() - start_time} seconds to plot figures.***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1411c92-b3ca-4340-94d6-2f3296607c31",
   "metadata": {},
   "source": [
    "<a id='step-4'></a>\n",
    "## Trained model inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50716925-45aa-426b-adde-f79946d387ec",
   "metadata": {},
   "source": [
    "<img src=\"images/pipeline_inference.png\" style=\"width: 1500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4d9c2-ccda-4ce1-b480-a109e492ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_pipeline.infer(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e3750-0856-4a72-a332-a8bab0a7230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bortezomib = \"B(C(CC(C)C)NC(=O)C(CC1=CC=CC=C1)NC(=O)C2=NC=CN=C2)(O)O\"\n",
    "cell_line = \"ACH-000001\"\n",
    "rec_pipeline.infer(training_config, drug=bortezomib, cell_line=cell_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97320404-c952-4b8d-94e9-ba6424c155ce",
   "metadata": {},
   "source": [
    "## Run trained model to save node embeddings\n",
    "\n",
    "Save the trained model embeddings as a node property. `drug_embeddings`, `epigenomics_embeddings`, `genomics_embeddings` and `transcriptomics_embeddings` will be created and saved. Those embeddings can be use for a future downstream task with a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fadc229-457e-40f5-a0df-b1fd36a772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = default_timer()\n",
    "rec_pipeline.infer_embeddings(model_config)\n",
    "print(f\"***Took {default_timer() - start_time} seconds to save node embeddings.***\")\n",
    "rec_pipeline.graph.schema().view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e058913-fc3e-4c06-888b-b7fd9e167698",
   "metadata": {},
   "source": [
    "## Save Graph\n",
    "\n",
    "Save the graph created to the bucket location named in the `save_graph_path` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc1319-b49e-4f07-aef0-a140ff354344",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_config.save_graph_path:\n",
    "    export_data.rdg(graph, input_config.save_graph_path)"
   ]
  }
 ],
 "metadata": {
  "katana": {
   "component": "AI",
   "max_num_hosts": 4
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
