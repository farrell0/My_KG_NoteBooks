{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cde52-a7e1-486e-a7c4-3ce3aaaa01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This NoteBook contains code to run classic ML routines against a \n",
    "#  number of familiar data sets ..\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bb83-5f71-406e-ab1c-1b0ef02583f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step 00: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7589c-6f1e-4f5c-a37b-21f8944c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Largely code to control how print statements and related work\n",
    "#\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%xmode Minimal\n",
    "\n",
    "\n",
    "#  Setting display options \n",
    "#\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 640)\n",
    "   #\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000, \n",
    "   formatter = dict(float = lambda x: \"%.3g\" % x))\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "   ###\n",
    "    \n",
    "from tabulate import tabulate\n",
    "#\n",
    "#  How to use tabulate-\n",
    "#\n",
    "#  l_result = [{ \"col1\": 20, \"col2\": 30}]\n",
    "#  #\n",
    "#  print(tabulate(l_result, headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a747a0-4aec-4cd2-bf38-8849deee7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Helper functions for what we want to do below-\n",
    "#\n",
    "#  **  You must run this cell to do much of anything in this NoteBook\n",
    "\n",
    "#  We use these objects to store the history of results; display only\n",
    "#\n",
    "class HistoryIterator:\n",
    "   def __init__(self, history):\n",
    "       self._history = history\n",
    "       self._index = 0\n",
    "\n",
    "   def __next__(self):\n",
    "       if (self._index < len(self._history._events)):\n",
    "           result = (self._history._events[self._index][\"event\"] , self._history._events[self._index][\"measure\"])\n",
    "           self._index +=1\n",
    "           return result\n",
    "       raise StopIteration\n",
    "\n",
    "class History:\n",
    "   def __init__(self):\n",
    "      self._events = list()\n",
    "\n",
    "   def clear(self):\n",
    "      self._events = list()\n",
    "    \n",
    "   def add(self, event, measure):\n",
    "      self._events.append({\"event\": event, \"measure\": measure})\n",
    "\n",
    "   def __iter__(self):\n",
    "      return HistoryIterator(self)\n",
    "\n",
    "\n",
    "l_history = History()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a137-2d39-411c-9316-aff11a9b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909c6ac-eef4-42ea-af33-cfda0b6d5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries are imported below, but ..\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2979-c711-419c-91b4-e035bafbe79c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Step A1: Iris Data load, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1be95-f9df-4435-ab56-add6aa68b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Iris data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1. sepal length in cm\n",
    "#     2. sepal width in cm\n",
    "#     3. petal length in cm\n",
    "#     4. petal width in cm\n",
    "#     5. class: \n",
    "#        Iris-setosa\n",
    "#        Iris-versicolour\n",
    "#        Iris-virginica\n",
    "#\n",
    "#  To convert class into a numeric, we use sklearn.preprocessing.LabelEncoder\n",
    "#  See,\n",
    "#     https://www.turing.com/kb/convert-categorical-data-in-pandas-and-scikit-learn\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"11_iris.data.txt\"\n",
    "\n",
    "\n",
    "pd_iris  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"sl\", \"sw\", \"pl\", \"pw\", \"class\"],\n",
    "   dtype = {\"sl\": \"float\", \"sw\": \"float\", \"pl\": \"float\", \"pw\": \"float\", \"class\": \"string\"} )\n",
    "      #\n",
    "pd_iris[\"class_encoded\"]  =  my_le.fit_transform(pd_iris[\"class\"])\n",
    "   #\n",
    "pd_iris = pd_iris.drop([\"class\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized set of rows, versus\n",
    "#  say head(), which always returns the first n ..\n",
    "#\n",
    "print(tabulate(pd_iris.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_iris)))\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     |   sl |   sw |   pl |   pw |   class_encoded |\n",
    "#     |------+------+------+------+-----------------|\n",
    "#     |  5.5 |  2.4 |  3.8 |  1.1 |               1 |\n",
    "#     |  6.4 |  3.2 |  4.5 |  1.5 |               1 |\n",
    "#     |  6.8 |  3.2 |  5.9 |  2.3 |               2 |\n",
    "#     |  6.7 |  3.3 |  5.7 |  2.1 |               2 |\n",
    "#     |  5.5 |  2.6 |  4.4 |  1.2 |               1 |\n",
    "#     +------+------+------+------+-----------------+\n",
    "#     Number of rows: 149\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd64b3f-30aa-4680-b983-462d5da51304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#  We only want two of the classes, 0 and 1\n",
    "#\n",
    "\n",
    "#  l_dtype = {\"names\": [\"f1\", \"f2\", \"f3\", \"f4\", \"class_encoded\"],                     #  Wound up not needing this\n",
    "#     \"formats\": [float, float, float, float, float]}\n",
    "#        #\n",
    "#  np_iris[\"train\"].dtype = l_dtype\n",
    "#  np_iris[\"test\" ].dtype = l_dtype\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_iris = {}\n",
    "   #\n",
    "np_iris[\"train\"], np_iris[\"test\"] = train_test_split(pd_iris.to_numpy(),              #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "\n",
    "\n",
    "np_iris[\"train_01\"] = np.copy(np_iris[\"train\"])                                       #  Copy, then filter\n",
    "np_iris[\"test_01\" ] = np.copy(np_iris[\"test\" ])\n",
    "   #\n",
    "np_iris[\"train_01\"] = np_iris[\"train\"][ ( np_iris[\"train\"][:, -1] < 2) ]\n",
    "np_iris[\"test_01\" ] = np_iris[\"test\" ][ ( np_iris[\"test\" ][:, -1] < 2) ]\n",
    "\n",
    "\n",
    "print(\"Number of total       rows... %d   Training rows: %d   Test rows: %d\" %        #  Outputs for confirmation\n",
    "  (len(pd_iris), len(np_iris[\"train\"]), len(np_iris[\"test\"])) )\n",
    "print()\n",
    "print(\"Number of total (0-1) rows... %d   Training rows: %d   Test rows: %d\" %\n",
    "  ( len(np_iris[\"train_01\"]) + len(np_iris[\"test_01\"]),\n",
    "    len(np_iris[\"train_01\"]), len(np_iris[\"test_01\"]) ) ) \n",
    "print()\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_iris[\"train_01\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_iris[\"test_01\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     Number of total       rows... 149   Training rows: 119   Test rows: 30\n",
    "#     \n",
    "#     Number of total (0-1) rows... 99   Training rows: 79   Test rows: 20\n",
    "#     \n",
    "#     Train data:\n",
    "#     [[6.1 2.9 4.7 1.4 1]\n",
    "#      [4.8 3.4 1.9 0.2 0]\n",
    "#      [5.2 3.5 1.5 0.2 0]\n",
    "#      [5 3.3 1.4 0.2 0]\n",
    "#      [4.6 3.1 1.5 0.2 0]]\n",
    "#     \n",
    "#     Test  data:\n",
    "#     [[5.1 3.4 1.5 0.2 0]\n",
    "#      [5.8 2.7 4.1 1 1]\n",
    "#      [5.5 2.6 4.4 1.2 1]\n",
    "#      [5.6 2.5 3.9 1.1 1]\n",
    "#      [5.7 3 4.2 1.2 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62191e70-57c7-49d1-ba47-cca3517b0d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  Plot of just two features from the two class data set\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(np_iris[\"train_01\"][np_iris[\"train_01\"][:, -1]==0][:, 0], np_iris[\"train_01\"][np_iris[\"train_01\"][:, -1]==0][:, 1], c = \"red\"       , label = \"Class 1\")\n",
    "plt.scatter(np_iris[\"train_01\"][np_iris[\"train_01\"][:, -1]==1][:, 0], np_iris[\"train_01\"][np_iris[\"train_01\"][:, -1]==1][:, 1], c = \"blue\"      , label = \"Class 2\")\n",
    "    \n",
    "plt.legend()\n",
    "   #\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fff5bc-0e4e-45db-ba85-693e7930cbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92602b-310a-4c0d-85a7-5ebcf3ec86f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59cef88-7f7a-4579-922c-fc7fa9960059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df4b7d-946c-4437-8965-d67a07a089c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1202c-c630-4e27-aea8-4ed425b139ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#  Our numpy array has 5 columns, with the last column being the class.\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 4 columns use,\n",
    "#        np_iris[\"train\"][:, :4]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: kNN=3\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: kNN=3 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1740a-f656-4d6d-bdf3-cb2f053fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#  Naive Bayes, Gaussian\n",
    "#\n",
    "#     Gaussian usually does better than the Multinomial below because,\n",
    "#        Gaussian expects continuous values\n",
    "#        Multinomial expects discreet values\n",
    "#\n",
    "#     And our values are continuous\n",
    "#\n",
    "\n",
    "do_model(GaussianNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: GaussianNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(GaussianNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: GaussianNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e0e-31d0-44c1-bdb3-0ee3c5ca3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#  Naive Bayes, Multinomial\n",
    "#\n",
    "\n",
    "do_model(MultinomialNB(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: MultinomialNB\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(MultinomialNB(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: MultinomialNB Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb7874-3d2c-4f27-83db-147b953228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Decision Tree\n",
    "#\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: DecisionTree\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(DecisionTreeClassifier(), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: DecisionTree Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a74fa-57c5-44ef-ade3-dd5438751064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  Random Forest\n",
    "#\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RandomForest\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RandomForest Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0262-190c-455d-b2f9-99056c1bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: SVC/Linear\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: SVC/Linear Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "             \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.25), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "             \n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train\"][:, :4], np_iris[\"train\"][:, -1], np_iris[\"test\"][:, :4], np_iris[\"test\"][:, -1], \"Iris: RBF 2\" ) \n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_iris[\"train_norm\"][:, :4], np_iris[\"train_norm\"][:, -1], np_iris[\"test_norm\"][:, :4], np_iris[\"test_norm\"][:, -1], \"Iris: RBF 2 Normalized\" ) \n",
    "#  print()\n",
    "#  print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "#  print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe262a-4fb5-4954-9d6f-c8cbea09d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Read the Breast Cancer data into a Pandas Dataframe\n",
    "#\n",
    "#     Features\n",
    "#     1)     ID number\n",
    "#     2)     Diagnosis (M = malignant, B = benign)\n",
    "#     3-32)\n",
    "#       Ten real-valued features are computed for each cell nucleus:\n",
    "#     \n",
    "#     \ta) radius (mean of distances from center to points on the perimeter)\n",
    "#     \tb) texture (standard deviation of gray-scale values)\n",
    "#     \tc) perimeter\n",
    "#     \td) area\n",
    "#     \te) smoothness (local variation in radius lengths)\n",
    "#     \tf) compactness (perimeter^2 / area - 1.0)\n",
    "#     \tg) concavity (severity of concave portions of the contour)\n",
    "#     \th) concave points (number of concave portions of the contour)\n",
    "#     \ti) symmetry \n",
    "#     \tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "#\n",
    "#  Sample data line,\n",
    "#     842302,M,\n",
    "#     17.99,    10.38,    122.8,    1001,    0.1184,    0.2776,    0.3001,    0.1471,    0.2419,    0.07871,         #  10 count\n",
    "#     1.095,    0.9053,   8.589,    153.4,   0.006399,  0.04904,   0.05373,   0.01587,   0.03003,   0.006193,\n",
    "#     25.38,    17.33,    184.6,    2019,    0.1622,    0.6656,    0.7119,    0.2654,    0.4601     ,0.1189\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "my_le = LabelEncoder()\n",
    "   #\n",
    "l_folder = \"20_Data\"\n",
    "l_file   = \"22_wdbc.data.txt\"\n",
    "\n",
    "\n",
    "pd_bc  = pd.read_csv((l_folder + \"/\" + l_file), header = 0, sep = \",\",\n",
    "   names = [\"id\", \"class\",\n",
    "            \"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \n",
    "            \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\", \"f20\", \n",
    "            \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "           ],\n",
    "   dtype = {\"id\": \"int\", \"class\": \"string\",\n",
    "            \"f01\": \"float\", \"f02\": \"float\", \"f03\": \"float\", \"f04\": \"float\", \"f05\": \"float\", \"f06\": \"float\", \"f07\": \"float\", \"f08\": \"float\", \"f09\": \"float\", \"f10\": \"float\", \n",
    "            \"f11\": \"float\", \"f12\": \"float\", \"f13\": \"float\", \"f14\": \"float\", \"f15\": \"float\", \"f16\": \"float\", \"f17\": \"float\", \"f18\": \"float\", \"f19\": \"float\", \"f20\": \"float\", \n",
    "            \"f21\": \"float\", \"f22\": \"float\", \"f23\": \"float\", \"f24\": \"float\", \"f25\": \"float\", \"f26\": \"float\", \"f27\": \"float\", \"f28\": \"float\", \"f29\": \"float\", \"f30\": \"float\", \n",
    "           } )\n",
    "      #\n",
    "pd_bc[\"class_encoded\"]  =  my_le.fit_transform(pd_bc[\"class\"])\n",
    "   #\n",
    "pd_bc = pd_bc.drop([\"class\", \"id\"], axis = 1)\n",
    "    \n",
    "    \n",
    "#  Pandas.Dataframe.sample() returns a randomized count of rows\n",
    "#\n",
    "print(tabulate(pd_bc.sample(5), headers='keys', tablefmt='psql', showindex=False))\n",
    "print(\"Number of rows: %d\" % (len(pd_bc)))\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe05409-32ac-4da0-bd05-6d97b35df9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Split data into training and test.\n",
    "#  Convert the data into numpy arrays, since the ml libraries we use later expect that.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_bc = {}\n",
    "   #\n",
    "np_bc[\"train\"], np_bc[\"test\"] = train_test_split(pd_bc.to_numpy(),                    #  random_state calls to shuffle the data,\n",
    "   test_size = 0.20, random_state = 40)                                               #    which had arrived sorted\n",
    "                                                                                      #  10% yields way too high of an accuracy\n",
    "                                                                                      #    far below\n",
    "print(\"Number of total rows: %d   Training rows: %d   Test rows: %d\" %\n",
    "  (len(pd_bc), len(np_bc[\"train\"]), len(np_bc[\"test\"])) )\n",
    "\n",
    "print()\n",
    "print(\"Train data:\")\n",
    "print(\"%s\" % (np_bc[\"train\"][0:5]))\n",
    "print()\n",
    "print(\"Test  data:\")\n",
    "print(\"%s\" % (np_bc[\"test\" ][0:5]))\n",
    "print()\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885ac6-db00-4fd0-9ef3-c7b5bd130542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Normalizing the data\n",
    "#\n",
    "\n",
    "def my_normalize(X, x_min, x_max):\n",
    "   nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "   denom = X.max(axis=0) - X.min(axis=0)\n",
    "   denom[denom==0] = 1\n",
    "   return x_min + nom/denom \n",
    "\n",
    "\n",
    "print(\"Number of columns in matrix: %d\" % (np_bc[\"train\"].shape[1]))\n",
    "      \n",
    "#  If we normalize the \"class\" column, we lose the categorical nature\n",
    "#  of that data. So, create a deep copy, then just normalize the non-\n",
    "#  class columns.\n",
    "#\n",
    "np_bc[\"train_norm\"] = np.copy(np_bc[\"train\"])\n",
    "np_bc[\"test_norm\" ] = np.copy(np_bc[\"test\" ])\n",
    "   #\n",
    "np_bc[\"train_norm\"][:, :30] = my_normalize(np_bc[\"train_norm\"][:, :30], 0, 1)\n",
    "np_bc[\"test_norm\" ][:, :30] = my_normalize(np_bc[\"test_norm\" ][:, :30], 0, 1)\n",
    "\n",
    "plt.boxplot(np_bc[\"train\"     ])\n",
    "plt.show()\n",
    "plt.boxplot(np_bc[\"train_norm\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36b4ec-23da-4af1-8cb4-fe5669cc5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "#  Our numpy array has many columns, with the last column being the class.\n",
    "#\n",
    "#  To review numpy array slicing,\n",
    "#\n",
    "#     To get the first 30 columns use,\n",
    "#        np_iris[\"train\"][:, :30]\n",
    "#     To get the last column use,\n",
    "#        np_iris[\"train\"][:, -1]\n",
    "#\n",
    "\n",
    "do_model(NearestCentroid(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Centroid\") \n",
    "#  do_model(NearestCentroid(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Centroid Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: kNN=3\") \n",
    "#  do_model(KNeighborsClassifier(n_neighbors = 3), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: kNN=3 Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: GaussianNB\") \n",
    "#  do_model(GaussianNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: GaussianNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: MultinomialNB\") \n",
    "#  do_model(MultinomialNB(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: MultinomialNB Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: DecisionTree\") \n",
    "#  do_model(DecisionTreeClassifier(), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: DecisionTree Normalized\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: Random Forest = 5\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: Random Forest = 5 Normalized\") \n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: SVC/Linear\") \n",
    "#  do_model(SVC(kernel = \"linear\", C = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: SVC/Linear Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 1.0), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF Normalized\") \n",
    "print()\n",
    "\n",
    "do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train\"][:, :30], np_bc[\"train\"][:, -1], np_bc[\"test\"][:, :30], np_bc[\"test\"][:, -1], \"Breast Cancer: RBF 2\") \n",
    "#  do_model(SVC(kernel = \"rbf\", C = 1.0, gamma = 0.001), np_bc[\"train_norm\"][:, :30], np_bc[\"train_norm\"][:, -1], np_bc[\"test_norm\"][:, :30], np_bc[\"test_norm\"][:, -1], \"Breast Cancer: RBF 2 Normalized\") \n",
    "print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb083d-60ba-4c42-b65c-f8f7c0864b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We will be using Keras, so pip install it inside the Jupyter NoteBook container ..\n",
    "#\n",
    "\n",
    "l_package1 = \"keras\"\n",
    "l_package2 = \"tensorflow\"\n",
    "    \n",
    "def my_func(arg1):\n",
    "    \n",
    "   import sys\n",
    "   import subprocess\n",
    "    \n",
    "   subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", arg1 ])\n",
    "      #\n",
    "   print(\"From each host ..\")\n",
    "      #\n",
    "   return\n",
    "\n",
    "\n",
    "   ##########################################\n",
    "    \n",
    "\n",
    "print(\"Install Python Pip packages on Jupyter container ..\")\n",
    "   #\n",
    "my_return = my_func(l_package1)\n",
    "my_return = my_func(l_package2)\n",
    "print()\n",
    "    \n",
    "\n",
    "#  Use this if installing o nthe KGIP worker nodes ..\n",
    "#\n",
    "#  print(\"Install Python Pip packages on KGIP worker node containers ..\")\n",
    "#     # \n",
    "#  my_return = my_graph.run(lambda g: my_func(l_package))\n",
    "#  print()\n",
    "    \n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a359-02b1-4bb0-aced-216eb7cad1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Intead of loading MNist from disk, we load it from the Keras library ..\n",
    "#\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "np_mnist = {}\n",
    "   #\n",
    "(np_mnist[\"train\"], np_mnist[\"train_label\"]), (np_mnist[\"test\"], np_mnist[\"test_label\"]) = mnist.load_data()\n",
    "\n",
    "\n",
    "#  train and test ccome in as an array [(n), 28, 28] where n == 60000 for train,\n",
    "#  and 100000 for test\n",
    "#\n",
    "#  We need that 28*28 as a vector, so ..\n",
    "#\n",
    "np_mnist[\"train_v\"] = np_mnist[\"train\"].reshape(-1, 28*28)\n",
    "np_mnist[\"test_v\"]  = np_mnist[\"test\" ].reshape(-1, 28*28)\n",
    "\n",
    "\n",
    "print(\"Train shape ................ %s\" % (str(np_mnist[\"train\"].shape)))\n",
    "print(\"Train label shape .......... %s\" % (str(np_mnist[\"train_label\"].shape)))\n",
    "   #\n",
    "print(\"Test  shape ................ %s\" % (str(np_mnist[\"test\"].shape)))\n",
    "print(\"Test  label shape .......... %s\" % (str(np_mnist[\"test_label\"].shape)))\n",
    "   #\n",
    "print(\"Train vector shape ......... %s\" % (str(np_mnist[\"train_v\"].shape)))\n",
    "print(\"Test  vector shape ......... %s\" % (str(np_mnist[\"test_v\" ].shape)))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "#  tabulate() displays poorly with this wide data. Straight up print() works well.\n",
    "#\n",
    "# print(tabulate(np_mnist[\"train\"][0:2], headers='keys', tablefmt='psql', showindex=False))\n",
    "print(np_mnist[\"train\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"train_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"train_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_label\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "    \n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c425b03-8d9c-4208-af6b-9f6115104b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     Train shape ................ (60000, 28, 28)\n",
    "#     Train label shape .......... (60000,)\n",
    "#     Test  shape ................ (10000, 28, 28)\n",
    "#     Test  label shape .......... (10000,)\n",
    "#     Train vector shape ......... (60000, 784)\n",
    "#     Test  vector shape ......... (10000, 784)\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252 253 122   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228  47  79 255 168   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0   0   0 253 252 165   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253 196   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135 253 186  12   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165 252 173   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167  56   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [5 0]\n",
    "#     Number of rows: 60000\n",
    "#     \n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [7 2]\n",
    "#     Number of rows: 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bcf95-6f46-448e-a618-4bf0fb15e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sometimes we want to clear history-\n",
    "#\n",
    "\n",
    "l_history.clear()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97564456-56d7-4f55-b4d8-94ec6ddde2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  All of our model libraries were imported above, but ..\n",
    "#\n",
    "\n",
    "#  Here we run given ML routines against the MNist data set\n",
    "#\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#  Adding these to the above\n",
    "#\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e883ec4-3c77-43cd-8d71-588f58f12503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Centroid\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=3\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: kNN=7\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: GaussianNB\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: DecisionTree\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   \") \n",
    "do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  \") \n",
    "do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 \") \n",
    "do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "#  Support Vector Machine\n",
    "#\n",
    "#  We run this one with a number of configurations ..\n",
    "#\n",
    "#     C      ==  margin constant\n",
    "#     gamma  ==  used by the Gaussian kernel\n",
    "#\n",
    "\n",
    "#  As configured, these throw warnings, never settle ..\n",
    "#\n",
    "\n",
    "#  do_model(LinearSVC(C = 0.01), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.01   \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 0.1 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=0.1    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 1.0 ), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=1.0    \") \n",
    "#  print()\n",
    "#  do_model(LinearSVC(C = 10.0), np_mnist[\"train_v\"], np_mnist[\"train_label\"], np_mnist[\"test_v\"], np_mnist[\"test_label\"], \"MNist: LinearSVC c=10.0   \") \n",
    "#  print()\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b1c44-a03b-4965-9f81-c838e23136ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     MNist: Centroid ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 2 9 0 2 9 0 1 5 9 7 3 4 7 6 4 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 0 6 6 0 1 8 8 4 5 6 7 8 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 82.0300 %\n",
    "#     \n",
    "#     MNist: kNN=3 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0500 %\n",
    "#     MNist: kNN=7 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.9400 %\n",
    "#     \n",
    "#     MNist: GaussianNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [9 2 1 0 9 1 8 9 4 9 0 6 9 0 1 0 9 7 2 9 9 6 6 8 9 0 7 9 0 1 ... 6 0 8 9 8 8 6 9 1 9 3 6 6 0 1 9 8 9 8 6 9 8 9 0 1 8 8 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 55.5800 %\n",
    "#     \n",
    "#     MNist: MultinomialNB ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 3 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 2 2 4 9 4 2 6 4 1 7 2 6 6 0 1 8 8 4 5 6 7 8 9 0 1 2 3 9 8 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6500 %\n",
    "#     \n",
    "#     MNist: DecisionTree ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 7 6 9 0 6 9 0 1 5 9 7 6 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 8 4 1 7 5 6 8 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.6700 %\n",
    "#     \n",
    "#     MNist: Random Forest = 5    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 8 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 91.9100 %\n",
    "#     MNist: Random Forest = 50   ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 3 6 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 96.7000 %\n",
    "#     MNist: Random Forest = 500  ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.0400 %\n",
    "#     MNist: Random Forest = 5000 ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 2 6 4 1 7 2 6 6 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 97.1800 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.01    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 87.1200 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=0.1     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 1 6 4 0 6 9 0 1 5 9 7 2 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 4 4 2 6 4 1 7 3 6 6 0 1 2 3 4 5 6 7 3 4 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 86.4700 %\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n",
    "#     \n",
    "#     MNist: LinearSVC c=1.0     ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 2 0 1 2 3 4 5 6 7 3 9 0 1 2 3 4 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.9900 %\n",
    "#     \n",
    "#     MNist: LinearSVC c=10.0    ...\n",
    "#        Actual    labels from test......... [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 5 2 4 9 4 3 6 4 1 7 2 6 5 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6]\n",
    "#        Predicted labels from test......... [7 2 1 0 4 1 8 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 ... 3 2 4 9 4 3 6 4 1 7 3 6 6 0 1 8 8 4 5 6 7 8 9 0 1 8 3 5 5 6]\n",
    "#        ###\n",
    "#        Accuracy: 83.6900 %\n",
    "#     \n",
    "#     \n",
    "#     +-----------------------------+------------+\n",
    "#     | Category                    | Accuracy   |\n",
    "#     |-----------------------------+------------|\n",
    "#     |                             |            |\n",
    "#     | MNist: Centroid             | 82.03      |\n",
    "#     | MNist: kNN=3                | 97.05      |\n",
    "#     | MNist: kNN=7                | 96.94      |\n",
    "#     | MNist: GaussianNB           | 55.58      |\n",
    "#     | MNist: MultinomialNB        | 83.65      |\n",
    "#     | MNist: DecisionTree         | 87.67      |\n",
    "#     | MNist: Random Forest = 5    | 91.91      |\n",
    "#     | MNist: Random Forest = 50   | 96.7       |\n",
    "#     | MNist: Random Forest = 500  | 97.04      |\n",
    "#     | MNist: Random Forest = 5000 | 97.18      |\n",
    "#     | MNist: LinearSVC c=0.01     | 87.12      |\n",
    "#     | MNist: LinearSVC c=0.1      | 86.47      |\n",
    "#     | MNist: LinearSVC c=1.0      | 83.99      |\n",
    "#     | MNist: LinearSVC c=10.0     | 83.69      |\n",
    "#     +-----------------------------+------------+\n",
    "#     \n",
    "#     --\n",
    "#     \n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#       warnings.warn(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612d30f-3774-4620-a843-7c04c7a6095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Regarding this,\n",
    "#\n",
    "#     /opt/conda/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning:\n",
    "#        Liblinear failed to converge, increase the number of iterations.\n",
    "#        warnings.warn(\n",
    "#\n",
    "#  From,\n",
    "#     https://stackoverflow.com/questions/52670012/convergencewarning-liblinear-failed-to-converge-increase-the-number-of-iterati\n",
    "#\n",
    "#      Normally when an optimization algorithm does not converge, it is usually because the problem is not well-conditioned,\n",
    "#      perhaps due to a poor scaling of the decision variables. There are a few things you can try.\n",
    "#      \n",
    "#          Normalize your training data so that the problem hopefully becomes more well conditioned, which in turn can speed up\n",
    "#          convergence. One possibility is to scale your data to 0 mean, unit standard deviation using Scikit-Learn's StandardScaler\n",
    "#          for an example.\n",
    "#\n",
    "#          Note that you have to apply the StandardScaler fitted on the training data to the test data. Also, if you have discrete\n",
    "#          features, make sure they are transformed properly so that scaling them makes sense.\n",
    "#\n",
    "#          Related to 1), make sure the other arguments such as regularization weight, C, is set appropriately. C has to be > 0.\n",
    "#          Typically one would try various values of C in a logarithmic scale (1e-5, 1e-4, 1e-3, ..., 1, 10, 100, ...) before\n",
    "#          finetuning it at finer granularity within a particular interval. These days, it probably make more sense to tune\n",
    "#          parameters using, for e.g., Bayesian Optimization using a package such as Scikit-Optimize.\n",
    "#\n",
    "#          Set max_iter to a larger value. The default is 1000. This should be your last resort. If the optimization process does\n",
    "#          not converge within the first 1000 iterations, having it converge by setting a larger max_iter typically masks other\n",
    "#          problems such as those described in 1) and 2). It might even indicate that you have some in appropriate features or\n",
    "#          strong correlations in the features. Debug those first before taking this easy way out.\n",
    "#\n",
    "#          Set dual = True if number of features > number of examples and vice versa. This solves the SVM optimization problem using\n",
    "#          the dual formulation. Thanks @Nino van Hooff for pointing this out, and @JamesKo for spotting my mistake.\n",
    "#\n",
    "#          Use a different solver, for e.g., the L-BFGS solver if you are using Logistic Regression. See @5ervant's answer.\n",
    "#      \n",
    "#      Note: One should not ignore this warning.\n",
    "#      \n",
    "#      This warning came about because\n",
    "#      \n",
    "#          Solving the linear SVM is just solving a quadratic optimization problem. The solver is typically an iterative algorithm\n",
    "#          that keeps a running estimate of the solution (i.e., the weight and bias for the SVM). It stops running when the solution\n",
    "#          corresponds to an objective value that is optimal for this convex optimization problem, or when it hits the maximum number\n",
    "#          of iterations set.\n",
    "#      \n",
    "#          If the algorithm does not converge, then the current estimate of the SVM's parameters are not guaranteed to be any good, \n",
    "#          hence the predictions can also be complete garbage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff57e71-9dc7-4e7c-9e6c-eb447e07867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Effect of randomness, moving the bits around inside each image.\n",
    "#\n",
    "#  Note; each row is randomzied by its own unique pattern.\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_mnist[\"train\"] \n",
    "#     np_mnist[\"train_label\"]\n",
    "#     np_mnist[\"test\"]\n",
    "#     np_mnist[\"test_label\"]\n",
    "#     np_mnist[\"train_v\"]           #  vectors of the two data sets above\n",
    "#     np_mnist[\"test_v\"] \n",
    "#\n",
    "\n",
    "#  Here we want to copy the two \"v\" arrays and randomize them\n",
    "#\n",
    "np_mnist[\"train_v_s\"] = np.copy(np_mnist[\"train_v\"])\n",
    "np_mnist[\"test_v_s\" ] = np.copy(np_mnist[\"test_v\" ])\n",
    "   #\n",
    "for i in range(np_mnist[\"train_v_s\"].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"train_v_s\"][i, :])\n",
    "for i in range(np_mnist[\"test_v_s\" ].shape[0]):\n",
    "   np.random.shuffle(np_mnist[\"test_v_s\" ][i, :])\n",
    "\n",
    "\n",
    "#  Looking at the non-scrambled, and yes-scrambled data\n",
    "#\n",
    "#  Currently the data lives as a vector. To look at it, copy\n",
    "#  it back to a 28*28 numpy array. We only need this for two\n",
    "#  rows we wish to view, and we choose to use test.\n",
    "#\n",
    "np_mnist[\"test_s\"] = np.zeros((2, np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2]), dtype = int)\n",
    "   #\n",
    "for i in range(np_mnist[\"test_s\"].shape[0]):\n",
    "   np_mnist[\"test_s\"][i,:,:] = np_mnist[\"test_v_s\"][i].reshape(28, 28)\n",
    "\n",
    "#  And the actual print\n",
    "#\n",
    "#  Non-randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "#  Problems with print formatting. These lines help\n",
    "#\n",
    "np.set_printoptions()\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000,  formatter = dict(int = lambda x: \"%3i\" % x))\n",
    "\n",
    "#  Randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test_s\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_s\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1983d12-36a3-42fd-83dc-3fb41fe464d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample results\n",
    "#\n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "#     \n",
    "#      [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
    "#       [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]]\n",
    "#     Number of rows: 10000\n",
    "#     \n",
    "#     [  7   2]\n",
    "#     [[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [ 61   0  38   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0 198 241   0   0   0]\n",
    "#       [  0   0   0   0   0   0 170   0 121   0 233 254   0   0   0 115   0 185 198   0   0   0   0   0 129   0   0   0]\n",
    "#       [  0   0 225   0   0   0   0   0   0   0   0   0   0 205   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [159   0   0  19   0   0   0   0   0  18   0   0   0   0  58   0  21 254   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 229   0   0   0   0 121   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0  60   0   0 238  67   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 151   0   0   0  59   0 254   0   0   0   0   0   0   0   0 207   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 209   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0  67   0   0   0   0   0 254   0   0   0   0   0   0   0   0  52]\n",
    "#       [  0  57 163  77   0   0   0   0   0   0  84   0   0   0   0   0   0   0   0   0   0   0  52   0   0   0   0 248]\n",
    "#       [  0   0   0   0   0   0   0   0 254   0   0   0 236   0   0   0 249   0   0   0   0   0   0   0  59   0   0   0]\n",
    "#       [  0   0   0   1   0   0   0   0 221   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 133   0   0   0   0   0   0 240   0   0   0 219   0   0   0   0]\n",
    "#       [  0 251   0   0   0   0   0  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  17]\n",
    "#       [  0   0   0  31   0   0   0 254   0 254   0   0   0   0   0   0   0 219   0  66   0   0   0   0   0   0   0   0]\n",
    "#       [166   0   0   0   0 254   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  62   0   0   3   0   0]\n",
    "#       [  0   0   0   0   0  18   0   0   0   0   0   0 254   0   0   0   0 254   0   0  83   0   0   0   0  40   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 250  75   0   0 198   0   0   0   0   0   0   0 203   0   0   0  67 114   0   0]\n",
    "#       [  0   0   0 140   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 106   0 227   0  52   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0 222]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0 182]\n",
    "#       [126   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0   0 242   0   0  44   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0 254 198 254   0   0   0 114   0   0   0   0 133   0   0 198   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254 253   5   0   0   0 187   0   0   0   0  67   0   0   0  72 198   0  83   0   0   0   0]\n",
    "#       [  0   0 254 198   0 254 254   0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0  35   0   0  22   0]\n",
    "#       [  0   0   0 255   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198   0 224]]\n",
    "#     \n",
    "#      [[  0   0 247   0   0 253  12 118  31   0 248   0   0   0   0   0 176 166   0   0   0   0   0  25   0   0   0   0]\n",
    "#       [  0   0 209   0  93   0   0   0   0   0   0   0   0   0   0 123   0   0   0   0 200   0  35  10   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 141   0 253 253   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0 253]\n",
    "#       [  0   0   0   0   0   0   0   0   0 117   0   0 206 122 253  10   0 150   0   0   0   0 253 253   0   0 253 253]\n",
    "#       [ 43   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0  32   0   0 253   0   0   0   0 253 155   0   0   0   0   0   0   0   0 198 140   0   0   0   0   0]\n",
    "#       [  0   0   0  12   0   0   0 141   0 255   0   0   0  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [249   0   0   0   0 123 166   0   0   0   0   0   0 253   0   0   0   0 210 248   0   0   0  20   0   0   0   0]\n",
    "#       [  0   0 123  18   0   0   0   0   0   0   0   0  20 253   0   0   0   0   0   0 198   0 253   0   0   0   0   0]\n",
    "#       [  0 255   0   0 253   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0  63   0   0 253   0]\n",
    "#       [  0   0   0   0 116   6   0   0   0   0  20   0   0   0 248   0   0  12 142   0   0   0   0   0 253   0 253   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0   0 150   0   0   0   0 253 234   0   0 253   0   0   0   0  78   0   0   0]\n",
    "#       [  0   0   0 253   0   0   0   0   0   0   0 169   0   0 218   0   0   0   0   0 253   0   0 253   0   0   5   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 213   0   0   0   0   0   0 253   0   0 253   0   0 231   0   0   0 253]\n",
    "#       [  0   0 253   0   0   0   0   0   0 134   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [174   0   0   0   0   0   0   0  19   0 123   0   0   0   0   0   0   0   0 171 168   0   0   0   0   0   0 128]\n",
    "#       [  0   0  20  41 253   0 253 144   0   0  76   0   0   0   0 253   0   0   0 176   0 159   0 253   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0 248   0  20   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [246   0   0   0   0   0   0   0   0   0   0   0  25   0   0   0   0 253   0 253   0   0 253   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 253 253   0   0   0   0   0   0   0   0 123   0   0   0 117   0   0   0   0   0 125   5]\n",
    "#       [  0   0   0   0   0   0 253   0   0   0   0   0   0   0 250   0 253   0   0  52   0 122 123   0   0   0   0   0]\n",
    "#       [  0 147   0 253   0   0 169   0   0   0   0   0 253   0 253   0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 253   0   0   0   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 150   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0 253   0   0   0   0  77   0 253   0   0   0   0]\n",
    "#       [248  37   0   0   0   0   0  65   0   0   0   0 173 233   0   0 253   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [150   0 169 247   0   0   0   0   0  12   0   0   0   0   0   0  25   0   0   0   0  65   0   0   0   0 189   0]\n",
    "#       [  0 253   0 251   0   0   0   0   0   0   0   0 253 253   0   0   0   0   0 253   0   0   0   0   0   0   0   0]\n",
    "#       [117   0 247   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253  20 210 253   0  57   0   0   0   0   0]]]\n",
    "#     Number of rows: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b208e4-2d65-4efa-9ed1-f4f51be6bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Creating a bar chart; Are these the same values ?\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image pre-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "l_hs = np.hstack(np_mnist[\"test_v_s\"][0])\n",
    "_ = plt.hist(l_hs, bins='auto') \n",
    "   #\n",
    "plt.title(\"784 possible values, range 0-256: Image post-randomization\")\n",
    "plt.xlabel('RGB Value')\n",
    "plt.ylabel('Count of Said Value')\n",
    "   #\n",
    "plt.show()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e165c-4d92-48cb-8ee2-85782fc4119d",
   "metadata": {},
   "source": [
    "<div> \n",
    "<img src=\"./01_Images/07_Results_BarChart.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6316f92-89a4-440c-9861-090b6f6e8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Rerun ML routines now on the scrambled images\n",
    "#\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: Centroid, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: kNN=3, Scramble\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: kNN=7, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: GaussianNB, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB, Scramble\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v_s\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s\"], np_mnist[\"test_label\"], \"MNist: DecisionTree, Scramble\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000, Scramble\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf646e34-43c1-48a0-b369-7aa59aed6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  The results below were on images that were not scrambled.\n",
    "#\n",
    "#     +-----------------------------+-------------------+\n",
    "#     | Category                    | Accuracy          |\n",
    "#     |-----------------------------+-------------------|\n",
    "#     | MNist: Centroid             | 82.03             |\n",
    "#     | MNist: kNN=3                | 97.05             |\n",
    "#     | MNist: kNN=7                | 96.94             |\n",
    "#     | MNist: GaussianNB           | 55.58             |\n",
    "#     | MNist: MultinomialNB        | 83.65             |\n",
    "#     | MNist: DecisionTree         | 87.72             |\n",
    "#     | MNist: Random Forest = 5    | 92.36999999999999 |\n",
    "#     | MNist: Random Forest = 50   | 96.67999999999999 |\n",
    "#     | MNist: Random Forest = 500  | 97.15             |\n",
    "#     | MNist: Random Forest = 5000 | 97.17             |\n",
    "#     |                             |                   |\n",
    "#     +-----------------------------+-------------------+\n",
    "#\n",
    "#  The results below on images when data is entirely randomized row by row ..\n",
    "#\n",
    "#     +--------------------------------+--------------------+\n",
    "#     | Category                       | Accuracy           |\n",
    "#     |--------------------------------+--------------------|\n",
    "#     | MNist: Centroid, Scramble      | 22.03              |\n",
    "#     | MNist: kNN=3, Scramble         | 11.540000000000001 |\n",
    "#     | MNist: kNN=7, Scramble         | 11.379999999999999 |\n",
    "#     | MNist: GaussianNB, Scramble    | 21.37              |\n",
    "#     | MNist: MultinomialNB, Scramble | 9.93               |\n",
    "#     | MNist: DecisionTree, Scramble  | 12.889999999999999 |\n",
    "#     |                                |                    |\n",
    "#     +--------------------------------+--------------------+\n",
    "#\n",
    "#  Takeaway,\n",
    "#\n",
    "#     .  Our data is 256 value bits * 2-dim array of (28 * 28).\n",
    "#        28 * 28 == 784\n",
    "#        Per each 28*28 image (784 bits), 650-700 of those bits are blank/zero.\n",
    "#\n",
    "#       So, to randomize the location of order bits itself is not bad, but it\n",
    "#       does not leave us with enough training data.\n",
    "#\n",
    "#       Meaning; a totally random \"7\" [ might ] be unique enough from a \"2\" or\n",
    "#       any other number, but we'd need a lot more data.\n",
    "#\n",
    "#     .  The approach now is to randomize the bits, but on a single consistent\n",
    "#        pattern applied to each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebe7e5-79b4-4e75-8ab9-8eb30b370e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Effect of randomness, moving the bits around inside each image.\n",
    "#\n",
    "#  Note; each row is randomized by one shared pattern.\n",
    "#\n",
    "\n",
    "#  The following variables are in scope ..\n",
    "#\n",
    "#     np_mnist[\"train\"] \n",
    "#     np_mnist[\"train_label\"]\n",
    "#     np_mnist[\"test\"]\n",
    "#     np_mnist[\"test_label\"]\n",
    "#     np_mnist[\"train_v\"]           #  vectors of the two data sets above\n",
    "#     np_mnist[\"test_v\"] \n",
    "#\n",
    "\n",
    "#  Here we want to copy the two \"v\" arrays \n",
    "#\n",
    "np_mnist[\"train_v_s2\"] = np.copy(np_mnist[\"train_v\"])\n",
    "np_mnist[\"test_v_s2\" ] = np.copy(np_mnist[\"test_v\" ])\n",
    "\n",
    "\n",
    "#  Make a new vector of values 0-n, randomize that, uses this as a map to\n",
    "#  consistently 'randomize' all remaining data\n",
    "#\n",
    "np_random = np.arange(0, np_mnist[\"train_v_s2\"].shape[1] -1, 1, dtype = int)\n",
    "np.random.shuffle(np_random)\n",
    "\n",
    "\n",
    "#  Apply the actual 'randomization'\n",
    "#\n",
    "for i in range(np_mnist[\"train_v_s2\"].shape[0]):\n",
    "   l_tmp = np.zeros(np_mnist[\"train_v_s2\"][i].shape[0], dtype = int)\n",
    "   for j in range(np_mnist[\"train_v_s2\"][i].shape[0] -1):\n",
    "      l_tmp[j] = np_mnist[\"train_v_s2\"][i][ np_random[j] ]\n",
    "   np_mnist[\"train_v_s2\"][i, :] = l_tmp[:]\n",
    "\n",
    "\n",
    "       #\n",
    "for i in range(np_mnist[\"test_v_s2\"].shape[0]):\n",
    "   l_tmp = np.zeros(np_mnist[\"test_v_s2\"][i].shape[0], dtype = int)\n",
    "   for j in range(np_mnist[\"test_v_s2\"][i].shape[0] - 1):\n",
    "      l_tmp[j] = np_mnist[\"test_v_s2\"][i][ np_random[j] ]\n",
    "   np_mnist[\"test_v_s2\"][i, :] = l_tmp[:]\n",
    "\n",
    "\n",
    "#  Looking at the yes-scrambled data\n",
    "#\n",
    "#  Currently the data lives as a vector. To look at it, copy\n",
    "#  it back to a 28*28 numpy array. We only need this for two\n",
    "#  rows we wish to view, and we choose to use test.\n",
    "#\n",
    "np_mnist[\"test_s\"] = np.zeros((2, np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2]), dtype = int)\n",
    "   #\n",
    "for i in range(np_mnist[\"test_s\"].shape[0]):\n",
    "   np_mnist[\"test_s\"][i,:,:] = np_mnist[\"test_v_s2\"][i].reshape(np_mnist[\"test\"].shape[1], np_mnist[\"test\"].shape[2])\n",
    "\n",
    "\n",
    "#  Problems with print formatting. These lines help\n",
    "#\n",
    "np.set_printoptions()\n",
    "np.set_printoptions(edgeitems = 30, linewidth = 100000,  formatter = dict(int = lambda x: \"%3i\" % x))\n",
    "\n",
    "#  Randomized bits\n",
    "#\n",
    "print(np_mnist[\"test_label\"][0:2])\n",
    "print(np_mnist[\"test_s\"][0:2])\n",
    "print(\"Number of rows: %d\" % (len(np_mnist[\"test_s\"])))\n",
    "   #\n",
    "print()\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02b6db-d527-4398-a4c9-782dc693ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     [  7   2]\n",
    "#     [[[  0   0 133 205   0   0   0   0   0   0   0   0  18 219   0   0 254   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 198   0   0 198   0   0   0 254   0   0   0   0   0   0  57   0   0   0   0 198   0   0   0   0]\n",
    "#       [  0 151   0   0   0   0 254   0   0   0   0   0   0   0   0  75   0   0   0   0   0  17   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198   0   0   0   0   0]\n",
    "#       [  0  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0 236   0   0   0   0 254   0   0 121   0   0   0]\n",
    "#       [  0   0 241   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0 255   0 254   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0   0   0   0   0 254   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   3   0   0   0 187   0  22   0 254   0 207   0   0   0  44   0   0   0  36   0   0   0  60   0 249   0]\n",
    "#       [  0   0   0   0   0 240  38   0 159   0   0   0   0 209   0 133   0   0   0   0   0   0   0  61 254   0   0   0]\n",
    "#       [  0   0   0 253   0   0 238   0 224   0   0   0   0   0   0  83   0  52   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254   0   0   0 229   0   0   0   0   0 254   0   0   0   0   0 114   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0 129   0   0   0   0   0 198   0   0   0   0   0 115   0   0   0   0  58   0   0   0 221]\n",
    "#       [  0 251   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 163   0   0   0]\n",
    "#       [  0  59   9   0   0  67   0   0   0   0   0   0   0 182   0   0   0   0 198   0   0   0   0   0   0   0  35   0]\n",
    "#       [  0   0 250   0   0  19   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0  52 254   0   0   5   0   0]\n",
    "#       [  0   0  66 198   0   0   0   0   0   0 126   0  52   0   0   0 140   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0 254   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  67   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254]\n",
    "#       [  0   0   0   0   0   0   0 254   0 254   0   0   0 185   0   0  67   0   0   0   0   0   0   0  40 121   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0 166   0   0   0   0   0   0  31   0   0   0   0 222 203   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0 254   0 254   0   0   0   0   0   0   0   0 227   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254   0 225   0  72   0   0   0  84   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0  18   0   0   0  59   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0 219   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0 254   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0  77   0 106   0   0   0   0   0   0   0   0   0  67   0 233   0 198]\n",
    "#       [  0  62   0   0   0   0   0   0  83 248   0 254   0   0   0   0   0   0   0 254   0   0   0   0   0   0   0 242]\n",
    "#       [  0   0   0   0   0 114   0   0   0   0   0   0   0   0   1   0   0   0   0   0 254   0   0   0 254   0   0   0]]\n",
    "#     \n",
    "#      [[ 43   0   0   0   0   0 255   0   0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   0  65   0  12   0]\n",
    "#       [  0   0   0   0 253   0 147 253 128   0   0 253   0   0   0  10   0   0   0   0   0   0   0   0   0 253   0   0]\n",
    "#       [  0 210   0   0 210  12   0 253   0 253   0 141 248 249   0   0 253   0   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0 144   0   0   0 253   0   0   0   0   0   0   0 253   0   0 142   0   0   0   0   0   0   0   0   0 253]\n",
    "#       [  0   0   0 253   0   0   0   0   0 246   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [169   0   0   0   0   0   0   5   0   0   0   0   0   0   0 253   0 198 248   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0 253   0 247   0 253   0 253   0 166   0 250 253   0 143   0   0]\n",
    "#       [  0   0 253   0   0   0   0   0   0   0   0   0  12   0   0   0  25 150   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [253   0 253  20 253   0   0 253   0 176   0   0   0   0   0 125   0   0 253   0   0 169   0   0  25   0   0   0]\n",
    "#       [118   0   0   0 140   0 253   0 251 174   0  93   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 206]\n",
    "#       [  0   0   0   0   0 234   0   0 123   0   0   0   0   0   0   0   0   0   0   0   0  35   0   0   0   0   0   0]\n",
    "#       [  0 253   0 150  30   0   0   0 176   0   0 253   0   0   0   0   0   0   0 166   0   0   0   0   0   0 248   0]\n",
    "#       [  0   0   0   0 122   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0 253   0   0   0  57   0  20  20]\n",
    "#       [  0   0   0   0 123   0   0   0   0   0   0   0   0   0  41 116   0   0   0   0   0 253 141 253   0   0   0 189]\n",
    "#       [  0   0   0   0   0  63   0   0   0   0   0   0 247   0   0   0   0 253 209   0   0 123   0   0   0   0 168 253]\n",
    "#       [ 25   0  10 150   0  20   0   0   0   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0  76   0   0   0 122   0   0 253   0 253   0   0   0   0   0   0 134   0   0   0   0   0   0   0   0   0]\n",
    "#       [ 37 213 253   0   0  18   0   0   0   0 253   0 253   0   0   0   0 253 253   0   0   0   0 117   0 248   0 247]\n",
    "#       [  0 255   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0]\n",
    "#       [  0 173   0   0   0   0   0  31   0   0   0   0   0  77  32   0 253   0 117 253   0   0   0   0   0   0   0   0]\n",
    "#       [  0   0   0   0 169   0   0   0   0   0   5   0   0   0   0   0   0 123   0   0   0   0   0 253 198   0   0   0]\n",
    "#       [  0 253   0   0   0   0   0 253   0   0 253   0  20   0   0   0   0 123   0   0   0   0   0 123   0   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0 155   0   0  78   0   0   0 253   0 117   0   0   0 200   0   0   0]\n",
    "#       [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253   0]\n",
    "#       [  0   0 253   0   0 253   0 159   0   0   0   0   0   0 247   0   0   0   0   0   0   0   0   0 233   0   0   0]\n",
    "#       [  0   0 248 218   0   0 171   0   0   0   0 253   0   0   0   0 150   0   0 253   0 253   0 231  52   0   0  65]\n",
    "#       [  0   0   0   0   0   0   0  12   0   0   0   0   0   0 253   0   0   0   0   0   0   0   0   0   0   0  19   0]\n",
    "#       [253   0   0   0   6   0   0   0 253   0   0   0   0   0 253   0   0   0 253   0   0   0   0   0 253   0   0   0]]]\n",
    "#     Number of rows: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346226c5-d1d2-4ee9-aa9b-192e950e22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Rerun ML routines now on the scrambled images, those randomized by one shared pattern\n",
    "#\n",
    "\n",
    "#  To add a blank line to history-\n",
    "#\n",
    "l_history.add(event = \"\", measure = \"\")\n",
    "\n",
    "\n",
    "do_model(NearestCentroid(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: Centroid, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(KNeighborsClassifier(n_neighbors =  3), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: kNN=3, Scramble-2\" ) \n",
    "do_model(KNeighborsClassifier(n_neighbors =  7), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: kNN=7, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(GaussianNB(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: GaussianNB, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(MultinomialNB(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: MultinomialNB, Scramble-2\") \n",
    "print()\n",
    "\n",
    "do_model(DecisionTreeClassifier(), np_mnist[\"train_v_s2\"], np_mnist[\"train_label\"], np_mnist[\"test_v_s2\"], np_mnist[\"test_label\"], \"MNist: DecisionTree, Scramble-2\") \n",
    "print()\n",
    "\n",
    "#  n_estimators, number of random trees created and trained\n",
    "#\n",
    "#  do_model(RandomForestClassifier(n_estimators = 5   ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5   , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 50  ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 50  , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 500 ), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 500 , Scramble\") \n",
    "#  do_model(RandomForestClassifier(n_estimators = 5000), np_mnist[\"train_scramble_v\"], np_mnist[\"train_label\"], np_mnist[\"test_scramble_v\"], np_mnist[\"test_label\"], \"MNist: Random Forest = 5000, Scramble\") \n",
    "\n",
    "print()\n",
    "\n",
    "   ###\n",
    "\n",
    "print()\n",
    "print(tabulate(l_history, headers=[\"Category\", \"Accuracy\"], tablefmt='psql', showindex=False))\n",
    "print()\n",
    "\n",
    "print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad074-e31f-44ff-844a-2c77217929f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Sample output,\n",
    "#\n",
    "#  The results below were on images that were not scrambled.\n",
    "#\n",
    "#     +-----------------------------+-------------------+\n",
    "#     | Category                    | Accuracy          |\n",
    "#     |-----------------------------+-------------------|\n",
    "#     | MNist: Centroid             | 82.03             |\n",
    "#     | MNist: kNN=3                | 97.05             |\n",
    "#     | MNist: kNN=7                | 96.94             |\n",
    "#     | MNist: GaussianNB           | 55.58             |\n",
    "#     | MNist: MultinomialNB        | 83.65             |\n",
    "#     | MNist: DecisionTree         | 87.72             |\n",
    "#     | MNist: Random Forest = 5    | 92.36999999999999 |\n",
    "#     | MNist: Random Forest = 50   | 96.67999999999999 |\n",
    "#     | MNist: Random Forest = 500  | 97.15             |\n",
    "#     | MNist: Random Forest = 5000 | 97.17             |\n",
    "#     |                             |                   |\n",
    "#     +-----------------------------+-------------------+\n",
    "#\n",
    "#  The results below on images when data is randomized by one shared pattern ..\n",
    "#\n",
    "#     +----------------------------------+------------+\n",
    "#     | Category                         | Accuracy   |\n",
    "#     |----------------------------------+------------|\n",
    "#     |                                  |            |\n",
    "#     | MNist: Centroid, Scramble-2      | 82.03      |\n",
    "#     | MNist: kNN=3, Scramble-2         | 97.05      |\n",
    "#     | MNist: kNN=7, Scramble-2         | 96.94      |\n",
    "#     | MNist: GaussianNB, Scramble-2    | 55.58      |\n",
    "#     | MNist: MultinomialNB, Scramble-2 | 83.65      |\n",
    "#     | MNist: DecisionTree, Scramble-2  | 87.7       |\n",
    "#     +----------------------------------+------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976e37-8702-4f53-bf97-e28a958675f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a397bde-64f0-4ec9-a728-d37e4c51ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
