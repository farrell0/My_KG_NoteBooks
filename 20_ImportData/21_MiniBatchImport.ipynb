{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54fd830-1317-4a52-b610-ef9716e5d744",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Setup: Display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38ebd7-d1d9-47a8-955c-a8270b024543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Setting display options \n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "pd.set_option(\"display.width\", 480)\n",
    "\n",
    "#  Sets horizontal scroll for wide outputs\n",
    "#\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"))\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7ce90-67cf-462c-94a6-3c8c9d0754b3",
   "metadata": {},
   "source": [
    "# Setup: Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b75ba-c072-4111-8cca-4b4f394a0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from katana import remote\n",
    "\n",
    "my_client = remote.Client()\n",
    "\n",
    "print(my_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a77f99-f11b-4105-ab43-17ce605b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_PARTITIONS  = 3\n",
    "   #\n",
    "DB_NAME         = \"my_db\"\n",
    "GRAPH_NAME      = \"my_graph\"\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f2292b8-7df0-49a0-b3da-523f56cfe4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  DELETE ALL GRAPHS\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   for l_graph in my_client.get_database(name=l_database.name).graphs_in_database():\n",
    "      l_handle=my_client.get_database(name=l_database.name).get_graph_by_id(id=l_graph.graph_id)\n",
    "      l_handle.delete()\n",
    "\n",
    "for l_graph in my_client.graphs():\n",
    "   print(\"GRAPH ID: \", l_graph.graph_id, \"      GRAPH Version: \", l_graph.version)\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f69a0e-451b-4679-b49c-5db1208d4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DELETE ALL DATABASES\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   if (l_database.name != \"default\"):\n",
    "      my_client.get_database(name=l_database.name).delete_database()\n",
    "      print(\"--\")\n",
    "\n",
    "for l_database in my_client.databases():\n",
    "   print(\"DB ID: \", l_database.database_id, \"     DB Name: \", l_database.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3bc00-fafb-481d-ba5a-8b52ae7d6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  CREATE DATABASE\n",
    "\n",
    "my_database = my_client.create_database(name=DB_NAME)\n",
    "\n",
    "print(my_database.database_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8ba088b-2ec5-4b2a-8171-3c87ddffb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_Graph my_graph, 9VvVqVxWw63HvniwHjudXiymnHNvjbAfQJW7ZafPY2Du, 0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  CREATE GRAPH\n",
    "#\n",
    "my_graph = my_client.get_database(name=DB_NAME).create_graph(name=GRAPH_NAME, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "print(my_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3685a36-d987-4ad8-a209-7115d726ac03",
   "metadata": {},
   "source": [
    "# Step 01: Support Methods to Create CSV files .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a50fd04c-9880-498e-978b-6a45da00f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  The overall goal of this NoteBook is to show incremental import. That is, importing\n",
    "#  into the graph many smaller pieces versus perhaps running one single import operation.\n",
    "#\n",
    "#  As such, we'll create (n) DataFrames with Nodes, (m) with Edges, and import those.\n",
    "#\n",
    "#     (n) and (m) are determined by how we invoke the method below.\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "   #\n",
    "import dask.dataframe as dd\n",
    "   #\n",
    "from dask.dataframe import from_pandas\n",
    "\n",
    "\n",
    "#  Generate a Dask DataFrame given a few column variables\n",
    "#\n",
    "def f_create_dataframe(i_node_or_edge, i_keyranges, i_label_or_type):\n",
    "\n",
    "   l_data_array = []\n",
    "\n",
    "   if (i_node_or_edge == \"node\"):\n",
    "      #\n",
    "      #  This is for nodes; we loop from i_keyranges[0] to i_keyranges[1]\n",
    "      #\n",
    "      for l_key in range(i_keyranges[0], i_keyranges[1] + 1):\n",
    "         l_key_str = str(i_label_or_type + \"_id\").lower()\n",
    "            #\n",
    "         l_data_dict = { l_key_str: l_key, \"col2\": \"222\", \"col3\": \"333\", \"col4\": 444, \"LABEL\": i_label_or_type}\n",
    "            #\n",
    "         l_data_array.append(l_data_dict)\n",
    "            #\n",
    "      l_dataframe =  pd.DataFrame(l_data_array, columns = [l_key_str, \"col2\", \"col3\", \"col4\", \"LABEL\"])\n",
    "   else:\n",
    "      #\n",
    "      #  This is for edges; here we expect five integers in i_keyranges[]\n",
    "      #\n",
    "      #     .  We (outer) loop from i_keyranges[0] to i_keyranges[1]\n",
    "      #        This is for the left edge, and form the key range for a given\n",
    "      #        set of nodes.\n",
    "      #     .  For each record above, we loop (n) times, where n is equal\n",
    "      #        to i_keyanges[2]. Call this the (inner) loop.\n",
    "      #     .  The values produced in the inner loop are sequential from\n",
    "      #        i_keyranges[3] to i_keyranges[4]\n",
    "      #\n",
    "      #     .  See examples in next cell\n",
    "      #\n",
    "      l_right_key = i_keyranges[3] - 1\n",
    "         #\n",
    "      for l_left_key in range(i_keyranges[0], i_keyranges[1] + 1):\n",
    "         for l_each in range(1, i_keyranges[2] + 1):\n",
    "            l_right_key +=1\n",
    "               #\n",
    "            if (l_right_key > i_keyranges[4]):\n",
    "               l_right_key = i_keyranges[3]\n",
    "                  #\n",
    "            l_data_dict1 = { \"start_id\": l_left_key,  \"end_id\": l_right_key, \"weight\": 444, \"uniq_col\": str(l_each), \"TYPE\": i_label_or_type}\n",
    "            l_data_dict2 = { \"end_id\": l_left_key,  \"start_id\": l_right_key, \"weight\": 444, \"uniq_col\": str(l_each), \"TYPE\": i_label_or_type}\n",
    "               #\n",
    "            l_data_array.append(l_data_dict1)\n",
    "            l_data_array.append(l_data_dict2)\n",
    "            #\n",
    "         l_dataframe =  pd.DataFrame(l_data_array, columns = [\"start_id\", \"end_id\", \"weight\", \"uniq_col\", \"TYPE\"])\n",
    "\n",
    "   l_dataframe_dd = from_pandas(l_dataframe, npartitions = NUM_PARTITIONS)\n",
    "\n",
    "\n",
    "   return l_dataframe_dd\n",
    "\n",
    "\n",
    "#  The name of the primary key column must be consistently named across\n",
    "#  all nodes in the graph. Easy code, but place it in a method regardless.\n",
    "#\n",
    "def f_copy_id_col(i_dataframe, i_colname):\n",
    "    \n",
    "   #  If we wanted a simple column rename\n",
    "   #\n",
    "   #  l_return = i_dataframe.rename(columns={i_colname: \"id\"})\n",
    "   #  return l_return\n",
    "     \n",
    "   i_dataframe[\"id\"] = i_dataframe[i_colname].map(lambda x: x )\n",
    "\n",
    "   return i_dataframe\n",
    "    \n",
    "\n",
    "print(\"--\")\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37711f-eb7d-4336-8d4b-8938a6d2ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Example demonstrating the above-\n",
    "#\n",
    "\n",
    "#  Create Person nodes in the range 100-103\n",
    "#\n",
    "df_nodes1 = f_create_dataframe(\"node\", [100, 103], \"Person\")\n",
    "   #                         \n",
    "#  print(tabulate(df_nodes1, headers='keys', tablefmt='psql'))\n",
    "print(df_nodes1.compute())\n",
    "\n",
    "\n",
    "#  Create Flight nodes in the range 400-410\n",
    "#\n",
    "df_nodes2 = f_create_dataframe(\"node\", [400, 410], \"Flight\")\n",
    "   #\n",
    "#  print(tabulate(df_nodes2, headers='keys', tablefmt='psql'))\n",
    "print(df_nodes2.compute())\n",
    "\n",
    "\n",
    "#  From this method invocation,\n",
    "#\n",
    "#     df_edges  = f_create_dataframe(\"edge\", [100, 103, 2, 400, 410], \"TAKES_FLIGHT\")\n",
    "#\n",
    "#  Create 2 TAKES_FLIGHT edges, for each left edge node in the\n",
    "#  range 100-103. Whatever this loop creates, assign right-edge\n",
    "#  key value sequentially from 400 to 410.\n",
    "#\n",
    "#  If we need more right-edge records, start over at 400.\n",
    "#\n",
    "#  If there are not enough left-edge records produced, not\n",
    "#  all right-edge nodes may recieve an edge.\n",
    "#\n",
    "#     If so, you may call this method again, say with these\n",
    "#     arguments,\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 404, 406, \"TAKES_FLIGHT\")\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 407, 408, \"TAKES_FLIGHT\")\n",
    "#        df_edges  = f_create_dataframe(\"edge\", [100, 103, 1, 409, 410, \"TAKES_FLIGHT\")\n",
    "#\n",
    "#     or whatever\n",
    "#\n",
    "#  Per a standard graph import, if you create edges for which there is no node,\n",
    "#  the record is discarded.\n",
    "#\n",
    "#  Edges are automaticallt created to be bi-directional.\n",
    "#\n",
    "\n",
    "\n",
    "df_edges  = f_create_dataframe(\"edge\", [100, 103, 2, 400, 410], \"TAKES_FLIGHT\")\n",
    "   #\n",
    "# print(tabulate(df_edges, headers='keys', tablefmt='psql'))\n",
    "print(df_edges.compute())\n",
    "\n",
    "\n",
    "del df_nodes1\n",
    "del df_nodes2\n",
    "del df_edges\n",
    "\n",
    "                               \n",
    "print(\"--\")\n",
    "\n",
    "#  Sample output\n",
    "#\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     |    |   person_id |   col2 |   col3 |   col4 | LABEL   |\n",
    "#     |----+-------------+--------+--------+--------+---------|\n",
    "#     |  0 |         100 |    222 |    333 |    444 | Person  |\n",
    "#     |  1 |         101 |    222 |    333 |    444 | Person  |\n",
    "#     |  2 |         102 |    222 |    333 |    444 | Person  |\n",
    "#     |  3 |         103 |    222 |    333 |    444 | Person  |\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     |    |   flight_id |   col2 |   col3 |   col4 | LABEL   |\n",
    "#     |----+-------------+--------+--------+--------+---------|\n",
    "#     |  0 |         400 |    222 |    333 |    444 | Flight  |\n",
    "#     |  1 |         401 |    222 |    333 |    444 | Flight  |\n",
    "#     |  2 |         402 |    222 |    333 |    444 | Flight  |\n",
    "#     |  3 |         403 |    222 |    333 |    444 | Flight  |\n",
    "#     |  4 |         404 |    222 |    333 |    444 | Flight  |\n",
    "#     |  5 |         405 |    222 |    333 |    444 | Flight  |\n",
    "#     |  6 |         406 |    222 |    333 |    444 | Flight  |\n",
    "#     |  7 |         407 |    222 |    333 |    444 | Flight  |\n",
    "#     |  8 |         408 |    222 |    333 |    444 | Flight  |\n",
    "#     |  9 |         409 |    222 |    333 |    444 | Flight  |\n",
    "#     | 10 |         410 |    222 |    333 |    444 | Flight  |\n",
    "#     +----+-------------+--------+--------+--------+---------+\n",
    "#     +----+------------+----------+----------+------------+--------------+\n",
    "#     |    |   start_id |   end_id |   weight |   uniq_col | TYPE         |\n",
    "#     |----+------------+----------+----------+------------+--------------|\n",
    "#     |  0 |        100 |      400 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  1 |        400 |      100 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  2 |        100 |      401 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  3 |        401 |      100 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  4 |        101 |      402 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  5 |        402 |      101 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  6 |        101 |      403 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  7 |        403 |      101 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     |  8 |        102 |      404 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     |  9 |        404 |      102 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 10 |        102 |      405 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 11 |        405 |      102 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 12 |        103 |      406 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 13 |        406 |      103 |      444 |          1 | TAKES_FLIGHT |\n",
    "#     | 14 |        103 |      407 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     | 15 |        407 |      103 |      444 |          2 | TAKES_FLIGHT |\n",
    "#     +----+------------+----------+----------+------------+--------------+\n",
    "\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e1596-03e6-450f-bcf0-144658f00701",
   "metadata": {},
   "source": [
    "#  Step 02:  Make Some Data, Import into Graph .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b337d260-8583-41fc-9300-e9994520cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  First, make some data\n",
    "#\n",
    "\n",
    "df_persons1 = f_create_dataframe(\"node\", [100, 199], \"Person\")\n",
    "df_persons2 = f_create_dataframe(\"node\", [300, 399], \"Person\")\n",
    "df_persons3 = f_create_dataframe(\"node\", [400, 499], \"Person\")\n",
    "\n",
    "df_flights0 = f_create_dataframe(\"node\", [800, 810], \"Flight\")                          #  800-810 is actually 11 rows, just fyi\n",
    " \n",
    "\n",
    "#  Since there are so many more People then Flights, it's easier to\n",
    "#  invoke the Edge creation from (Small --> Large)\n",
    "#\n",
    "#  Edges are automatically created to be bi-directional\n",
    "#\n",
    "\n",
    "df_edges1  = f_create_dataframe(\"edge\", [800, 810, 5, 400, 410], \"TAKES_FLIGHT\")\n",
    "df_edges2  = f_create_dataframe(\"edge\", [800, 810, 1, 411, 499], \"TAKES_FLIGHT\")\n",
    "   #\n",
    "df_edges3  = f_create_dataframe(\"edge\", [800, 810, 2, 100, 199], \"TAKES_FLIGHT\")\n",
    "df_edges4  = f_create_dataframe(\"edge\", [800, 810, 2, 300, 399], \"TAKES_FLIGHT\")\n",
    "\n",
    "\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d607abb-6e9b-4dfd-9b10-302c237556d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789b791b06104e9f9815df1bbea91b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1279e38f5194a6893fa1461b0b892ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d30184bf78d4b6eb5245330e694ead1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f2d8fc9a048bc9217e553c9fa61c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f42de2204f491abb7e16a9a61577c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9baaf533c94620954a11971211d76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9293907cfd4b3487f65c50fe239a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6593f8865e7c4c78b0e08e44b7d0bde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54da2575a9e148ed933c2ed94bea8460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b18d63a494b496397aeab59def0458b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "          0/? [?op/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  At this point (from above), we have an empty graph\n",
    "#\n",
    "\n",
    "from katana.remote import import_data\n",
    "\n",
    "\n",
    "for l_each in [df_persons1, df_persons2, df_persons3]:\n",
    "      #\n",
    "   l_each2 = f_copy_id_col(l_each, \"person_id\")\n",
    "      #\n",
    "   with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "      df_importer.nodes_dataframe(\n",
    "         l_each2,\n",
    "         id_column             = \"id\",\n",
    "         id_space              = \"Person\",  \n",
    "         label                 = \"Person\",  \n",
    "         ) \n",
    "            #\n",
    "      df_importer.insert()\n",
    "    \n",
    "    \n",
    "for l_each in [df_flights0]:\n",
    "      #\n",
    "   l_each2 = f_copy_id_col(l_each, \"flight_id\")\n",
    "      #\n",
    "   with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "      df_importer.nodes_dataframe(\n",
    "         l_each,\n",
    "         id_column             = \"id\",\n",
    "         id_space              = \"Flight\",  \n",
    "         label                 = \"Flight\",  \n",
    "         ) \n",
    "            #\n",
    "      df_importer.insert()\n",
    "    \n",
    "\n",
    "display(my_graph.num_nodes())\n",
    "display(my_graph.num_edges())\n",
    "   #\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01349649-f0e7-4bbf-826f-f2898258b4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824bef64-f316-4bfc-997e-8356bac89745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee5d4d-b870-4d43-ada0-f2f351ab4390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c9687-c5d2-42bb-9774-39c6a880307f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cb6ca-f75e-4d88-9718-4b0515d31575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5981d-8279-438e-af53-6c496e79de33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80d72f-6a08-4f2c-803e-1f2ace83817c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40134cd6-ed20-4f7e-a8b9-3541a485ea60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c0049-2cf2-43d3-8eca-56e147ce1438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0009eb-ba83-4f7e-ad0d-21b72107b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with import_data.DataFrameImporter(my_graph) as df_importer:   \n",
    "    \n",
    "   df_importer.nodes_dataframe(df_airports,                    #  Aiport set of Nodes\n",
    "      id_column             = \"airport_code\",\n",
    "      id_space              = \"Airport\",  \n",
    "      label                 = \"Airport\",  \n",
    "      )\n",
    "   \n",
    "   df_importer.edges_dataframe(df_flights,                     #  Our Edge, specifying the relationship between Airport --> FLIES_TO --> Airport\n",
    "      source_id_space       = \"Airport\", \n",
    "      destination_id_space  = \"Airport\",   \n",
    "      source_column         = \"START_ID\",\n",
    "      destination_column    = \"END_ID\",\n",
    "      type                  = \"FLIES_TO\"\n",
    "      )\n",
    "\n",
    "   df_importer.insert()\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4052a-1be7-4ef9-b81a-fd409f61fe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b5813-5d3f-40cc-8421-5fcfe7310f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c463d2f-9134-4d8d-9545-1e8514b9d785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
